/**
 * Created: 22 Aug 2014
 */
package mapreduce.guardedfragment.executor.hadoop.reducers;

import java.io.IOException;
import java.io.Serializable;
import java.util.HashSet;
import java.util.Set;

import mapreduce.guardedfragment.planner.structures.operations.GFOperationInitException;
import mapreduce.guardedfragment.planner.structures.operations.GFReducer;
import mapreduce.guardedfragment.structure.gfexpressions.GFExistentialExpression;
import mapreduce.guardedfragment.structure.gfexpressions.GFExpression;
import mapreduce.guardedfragment.structure.gfexpressions.io.GFPrefixSerializer;
import mapreduce.guardedfragment.structure.gfexpressions.io.Pair;
import mapreduce.guardedfragment.structure.gfexpressions.operations.ExpressionSetOperations;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.Mapper.Context;
import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;

/**
 * Uses atom data generated by the corresponding mapper.
 * 
 * @author Jonny Daenen
 * 
 */
public class GFReducer1 extends Reducer<Text,Text,Text,Text> {

	private static final long serialVersionUID = 1L;
	private final static String FILENAME = "tmp_round1_red.txt";

	Text out1 = new Text();
	Text out2 = new Text();
	private ExpressionSetOperations eso;
	private MultipleOutputs<Text, Text> mos;

	private static final Log LOG = LogFactory.getLog(GFReducer1.class);


	/**
	 * @see org.apache.hadoop.mapreduce.Mapper#setup(org.apache.hadoop.mapreduce.Mapper.Context)
	 */
	@Override
	protected void setup(Context context) throws IOException, InterruptedException {
		// load context
		super.setup(context);
		Configuration conf = context.getConfiguration();

		mos = new MultipleOutputs<>(context);
		
	


		GFPrefixSerializer serializer = new GFPrefixSerializer();

		// load guard
		try {
			HashSet<GFExistentialExpression> formulaSet = new HashSet<GFExistentialExpression>();
			String formulaString = conf.get("formulaset");
			Set<GFExpression> deserSet = serializer.deserializeSet(formulaString);

			// check whether the type is existential
			// FUTURE allow other types?
			for (GFExpression exp : deserSet) {
				if (exp instanceof GFExistentialExpression) {
					formulaSet.add((GFExistentialExpression) exp);
				}
			}
			
			eso = new ExpressionSetOperations();
			eso.setExpressionSet(formulaSet);

		} catch (Exception e) {
			throw new InterruptedException("Reducer initialisation error: " + e.getMessage());
		}
	}
	
	@Override
	protected void cleanup(Context context) throws IOException, InterruptedException {
		mos.close();
	}
	
	
	
	/**
	 * @see org.apache.hadoop.mapreduce.Reducer#reduce(java.lang.Object, java.lang.Iterable, org.apache.hadoop.mapreduce.Reducer.Context)
	 */
	@Override
	protected void reduce(Text key, Iterable<Text> values, Context context)
			throws IOException, InterruptedException {
		

		Set<Pair<String, String>> buffer = new HashSet<>();

		try {
			// LOG.warn(key + ": ");

			boolean keyFound = false;
			for (Object v : values) {

				// WARNING Text object will be reused by Hadoop!
				Text t = (Text) v;
				// LOG.warn("\t" + t);
				String[] split = split(t);

				// is this a guard
				if (split != null) {
					int id = Integer.parseInt(split[1]);
					String atom = eso.getAtom(id).toString();

					// if the key has already been found, we can just output
					if (keyFound) {
						out1.set(split[0]);
						out2.set(atom);
						mos.write(out1, out2, FILENAME);
					}
					// else we collect the data
					else {
						// create new object because Text object will be reduce
						// by Hadoop
						buffer.add(new Pair<>(split[0], atom));
					}

					// if this is the key, we mark it
				} else if (!keyFound) {
					keyFound = true;
				}
			}

			// output the remaining data
			if (keyFound) {
				for (Pair<String, String> p : buffer) {
					out1.set(p.fst);
					out2.set(p.snd);
					mos.write(out1, out2, FILENAME);
				}
			}

		} catch (GFOperationInitException e) {
			// should not happen
			LOG.error(e.getMessage());
			throw new InterruptedException(e.getMessage());
		}

	}

	/**
	 * @param t
	 * @param c
	 */
	private String[] split(Text t) {
		int length = t.getLength();
		StringBuilder sb = new StringBuilder(length);
		String[] output = null;

		byte[] b = t.getBytes();
		for (int i = 0; i < length; i++) { // FUTURE for unicode this doesn't
											// work i guess..

			// if we find the semicolon
			if ((char) b[i] == ';') {
				output = new String[2];
				output[0] = sb.toString();
				sb.setLength(0);

			} else {
				sb.append((char) b[i]);
			}
		}
		if (output != null)
			output[1] = sb.toString();

		return output;

	}

}
