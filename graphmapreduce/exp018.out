gumbo.engine.guardAddressOptimizationOn=true
gumbo.engine.proofsymbol=#
gumbo.engine.mapOutputGroupingPolicy=ALLGROUP
gumbo.engine.valeval.enabled=true
gumbo.engine.simulator.classname=gumbo.engine.hadoop2.estimation.MapSimulator
gumbo.engine.guardedCombinerOptimizationOn=false
gumbo.engine.assertConstantOptimizationOn=true
gumbo.compiler.partitioner=gumbo.compiler.partitioner.HeightPartitioner
gumbo.engine.valeval.projection.prepack=true
gumbo.engine.round1FiniteMemoryOptimizationOn=false
gumbo.engine.hadoop.reducersize_mb=1024
gumbo.engine.val.projection.prepack=true
gumbo.engine.reduceOutputGroupingOptimizationOn=true
gumbo.engine.mapOutputGroupingOptimizationOn=true
gumbo.engine.eval.output.merge=false
gumbo.compiler.unnest=false
gumbo.engine.grouper.beststopindicator=0
gumbo.engine.requestAtomIdOptimizationOn=true
gumbo.engine.guardKeepAliveOptimizationOn=true
[INFO] 15/12/11 16:04:23 gumbo.Gumbo: Input: 
R(x0,x1,x2,x3);input/experiments/EXP_029/4/R;csv;'S(x0);input/experiments/EXP_029/4/S;csv;'T(x0);input/experiments/EXP_029/4/T;csv;'U(x0);input/experiments/EXP_029/4/U;csv;'V(x0);input/experiments/EXP_029/4/V;csv;
Output: output/EXP_029
Scratch: scratch/EXP_029
Queries: 
[(Out1(x) : R(x,y,z,w) & (S(x) & (T(y) & (U(z) & V(w)))))]

[INFO] 15/12/11 16:04:23 compiler.GFCompiler: Adding suffix to scratch and output paths: /20151211_160423
[INFO] 15/12/11 16:04:23 compiler.GFCompiler: Decomposing GFEs into basic GFEs (BGFEs)...
[INFO] 15/12/11 16:04:23 compiler.GFCompiler: Number of BGFEs: 1
[INFO] 15/12/11 16:04:23 compiler.GFCompiler: Converting BGFEs into CalculationUnits (CUs)...
[INFO] 15/12/11 16:04:23 compiler.GFCompiler: Number of CUs: 1
[INFO] 15/12/11 16:04:23 compiler.GFCompiler: Linking Calculation Units (CUs)...
[INFO] 15/12/11 16:04:23 compiler.GFCompiler: Creating initial file mapping...
[INFO] 15/12/11 16:04:23 compiler.GFCompiler: file mapping:
Out root: output/EXP_029/20151211_160423
Scratch root: scratch/EXP_029/20151211_160423
Temp root: scratch/EXP_029/20151211_160423/tmp
R(x0,x1,x2,x3) <- [input/experiments/EXP_029/4/R]
S(x0) <- [input/experiments/EXP_029/4/S]
T(x0) <- [input/experiments/EXP_029/4/T]
U(x0) <- [input/experiments/EXP_029/4/U]
V(x0) <- [input/experiments/EXP_029/4/V]
Out1(x0) -> [output/EXP_029/20151211_160423/OUT_0_Out1]
Temp dirs: 

[INFO] 15/12/11 16:04:23 compiler.GFCompiler: Partitioning...
[INFO] 15/12/11 16:04:23 compiler.GFCompiler: Number of partitions: 1

Query:
query1.gumbo

Partitions:
-----------
Calculation Unit Partitions: {
{id : 0 Depends on: None. - (Out1(x) : R(x,y,z,w) & (S(x) & (T(y) & (U(z) & V(w)))))}
}
Folders:
-------
Out root: output/EXP_029/20151211_160423
Scratch root: scratch/EXP_029/20151211_160423
Temp root: scratch/EXP_029/20151211_160423/tmp
R(x0,x1,x2,x3) <- [input/experiments/EXP_029/4/R]
S(x0) <- [input/experiments/EXP_029/4/S]
T(x0) <- [input/experiments/EXP_029/4/T]
U(x0) <- [input/experiments/EXP_029/4/U]
V(x0) <- [input/experiments/EXP_029/4/V]
Out1(x0) -> [output/EXP_029/20151211_160423/OUT_0_Out1]
Temp dirs: 

[INFO] 15/12/11 16:04:23 hadoop2.HadoopEngine2: Creating Job Control for: query1.gumbo
[INFO] 15/12/11 16:04:23 hadoop2.HadoopEngine2: Starting Job-control thread: Gumbo-Workflow-Thread_query1.gumbo
[WARN] 15/12/11 16:04:23 util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 15/12/11 16:04:23 hadoop2.HadoopEngine2: Using 2-round evaluation for Calculation Unit Partitions: {
{id : 0 Depends on: None. - (Out1(x) : R(x,y,z,w) & (S(x) & (T(y) & (U(z) & V(w)))))}
}
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/_SUCCESS
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00001
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/_SUCCESS
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00001
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/_SUCCESS
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00001
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/_SUCCESS
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00001
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/_SUCCESS
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00001
[INFO] 15/12/11 16:04:23 sample.RelationSampler: Fetching samples for relation R(x0,x1,x2,x3)
[INFO] 15/12/11 16:04:23 sample.RelationSampler: Fetching samples for relation S(x0)
[INFO] 15/12/11 16:04:23 sample.RelationSampler: Fetching samples for relation T(x0)
[INFO] 15/12/11 16:04:23 sample.RelationSampler: Fetching samples for relation U(x0)
[INFO] 15/12/11 16:04:23 sample.RelationSampler: Fetching samples for relation V(x0)
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Parsing samples for relation R(x0,x1,x2,x3)
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Small tuples: 512
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Big tuples: 4605
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Parsing samples for relation S(x0)
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Small tuples: 2048
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Big tuples: 17546
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Parsing samples for relation T(x0)
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Small tuples: 2047
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Big tuples: 17004
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Parsing samples for relation U(x0)
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Small tuples: 2048
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Big tuples: 16557
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Parsing samples for relation V(x0)
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Small tuples: 2048
[INFO] 15/12/11 16:04:23 reporter.RelationTupleSampleContainer: Big tuples: 16390
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/_SUCCESS
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00001
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/_SUCCESS
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00001
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/_SUCCESS
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00001
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/_SUCCESS
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00001
[INFO] 15/12/11 16:04:23 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/_SUCCESS
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00001
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/_SUCCESS
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00001
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/_SUCCESS
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00001
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/_SUCCESS
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00001
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/_SUCCESS
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00001
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/_SUCCESS
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00001
[INFO] 15/12/11 16:04:24 grouper.GrouperFactory: Creating a grouper with policy ALLGROUP
[INFO] 15/12/11 16:04:24 grouper.Grouper: Decomposition complete: 	R(x,y,z,w) |X V(w)
	R(x,y,z,w) |X U(z)
	R(x,y,z,w) |X T(y)
	R(x,y,z,w) |X S(x)
	Guard In Bytes0
	Guarded In Bytes0
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:0.0

[INFO] 15/12/11 16:04:24 grouper.Grouper: Grouping complete: 1 group(s)
[INFO] 15/12/11 16:04:24 grouper.Grouper: Grouping: [	R(x,y,z,w) |X V(w)
	R(x,y,z,w) |X U(z)
	R(x,y,z,w) |X T(y)
	R(x,y,z,w) |X S(x)
	Guard In Bytes0
	Guarded In Bytes0
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:0.0
]
[INFO] 15/12/11 16:04:24 hadoop2.HadoopEngine2: Starting round 1 (VAL)
[INFO] 15/12/11 16:04:24 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/4/R to mapper
[INFO] 15/12/11 16:04:24 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/4/S to mapper
[INFO] 15/12/11 16:04:24 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/4/T to mapper
[INFO] 15/12/11 16:04:24 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/4/U to mapper
[INFO] 15/12/11 16:04:24 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/4/V to mapper
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/_SUCCESS
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00001
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/_SUCCESS
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00001
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/_SUCCESS
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00001
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/_SUCCESS
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00001
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/_SUCCESS
[INFO] 15/12/11 16:04:24 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00001
[INFO] 15/12/11 16:04:24 converter.MultiRoundConverter: Missing size estimates, sampling data.
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Simulating relation R(x0,x1,x2,x3)
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [R:3:0,1,2,3:4, R:0:0,1,2,3:0, R:2:0,1,2,3:1, R:1:0,1,2,3:2]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [R:3:0,1,2,3:4, R:0:0,1,2,3:0, R:2:0,1,2,3:1, R:1:0,1,2,3:2]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [R:0:0,1,2,3:0, R:3:0,1,2,3:4, R:1:0,1,2,3:2, R:2:0,1,2,3:1]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [R:0:0,1,2,3:0, R:3:0,1,2,3:4, R:1:0,1,2,3:2, R:2:0,1,2,3:1]
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Map Input bytes:400000
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Est. Map Output bytes: 896080
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Simulating relation S(x0)
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [S:0:0:0]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [S:0:0:0]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [S:0:0:0]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [S:0:0:0]
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Map Input bytes:20000
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Est. Map Output bytes: 50006
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Simulating relation T(x0)
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [T:0:0:2]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [T:0:0:2]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [T:0:0:2]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [T:0:0:2]
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Map Input bytes:20000
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Est. Map Output bytes: 50007
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Simulating relation U(x0)
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [U:0:0:1]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [U:0:0:1]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [U:0:0:1]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [U:0:0:1]
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Map Input bytes:20000
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Est. Map Output bytes: 50007
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Simulating relation V(x0)
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [V:0:0:4]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [V:0:0:4]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [V:0:0:4]
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:24 tupleops.TupleOpFactory: [V:0:0:4]
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Map Input bytes:20000
[INFO] 15/12/11 16:04:24 estimation.MapSimulator: Est. Map Output bytes: 50008
[INFO] 15/12/11 16:04:24 converter.MultiRoundConverter: Map output est.: 1096108, setting VAL Reduce tasks to 1
[INFO] 15/12/11 16:04:24 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/11 16:04:28 Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO] 15/12/11 16:04:28 jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN] 15/12/11 16:04:28 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/11 16:04:28 input.FileInputFormat: Total input paths to process : 10
[INFO] 15/12/11 16:04:28 mapreduce.JobSubmitter: number of splits:10
[INFO] 15/12/11 16:04:28 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/11 16:04:28 mapreduce.JobSubmitter: Submitting tokens for job: job_local778124726_0001
[WARN] 15/12/11 16:04:28 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny778124726/.staging/job_local778124726_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/11 16:04:28 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny778124726/.staging/job_local778124726_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/11 16:04:28 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local778124726_0001/job_local778124726_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/11 16:04:28 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local778124726_0001/job_local778124726_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/11 16:04:28 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/11 16:04:28 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/11 16:04:28 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/11 16:04:28 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/11 16:04:28 mapred.LocalJobRunner: Starting task: attempt_local778124726_0001_m_000000_0
[INFO] 15/12/11 16:04:28 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:28 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:28 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00000:0+400000
[INFO] 15/12/11 16:04:28 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:28 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:28 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:28 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:28 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:28 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:28 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:28 tupleops.TupleOpFactory: [R:2:0,1,2,3:1, R:3:0,1,2,3:4, R:0:0,1,2,3:0, R:1:0,1,2,3:2]
[INFO] 15/12/11 16:04:28 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:28 tupleops.TupleOpFactory: [R:2:0,1,2,3:1, R:3:0,1,2,3:4, R:0:0,1,2,3:0, R:1:0,1,2,3:2]
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:29 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:29 mapred.MapTask: Spilling map output
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufend = 911760; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396(104857584); kvend = 25894400(103577600); length = 319997/6553600
[INFO] 15/12/11 16:04:29 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 16:04:29 mapred.Task: Task:attempt_local778124726_0001_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:29 mapred.Task: Task 'attempt_local778124726_0001_m_000000_0' done.
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Finishing task: attempt_local778124726_0001_m_000000_0
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Starting task: attempt_local778124726_0001_m_000001_0
[INFO] 15/12/11 16:04:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00000:0+20000
[INFO] 15/12/11 16:04:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: [S:0:0:0]
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: [S:0:0:0]
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:29 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:29 mapred.MapTask: Spilling map output
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufend = 50000; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/12/11 16:04:29 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 16:04:29 mapred.Task: Task:attempt_local778124726_0001_m_000001_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:29 mapred.Task: Task 'attempt_local778124726_0001_m_000001_0' done.
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Finishing task: attempt_local778124726_0001_m_000001_0
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Starting task: attempt_local778124726_0001_m_000002_0
[INFO] 15/12/11 16:04:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00000:0+20000
[INFO] 15/12/11 16:04:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: [T:0:0:2]
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: [T:0:0:2]
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:29 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:29 mapred.MapTask: Spilling map output
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufend = 50000; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/12/11 16:04:29 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 16:04:29 mapred.Task: Task:attempt_local778124726_0001_m_000002_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:29 mapred.Task: Task 'attempt_local778124726_0001_m_000002_0' done.
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Finishing task: attempt_local778124726_0001_m_000002_0
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Starting task: attempt_local778124726_0001_m_000003_0
[INFO] 15/12/11 16:04:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00000:0+20000
[INFO] 15/12/11 16:04:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: [U:0:0:1]
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: [U:0:0:1]
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:29 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:29 mapred.MapTask: Spilling map output
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufend = 50000; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/12/11 16:04:29 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 16:04:29 mapred.Task: Task:attempt_local778124726_0001_m_000003_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:29 mapred.Task: Task 'attempt_local778124726_0001_m_000003_0' done.
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Finishing task: attempt_local778124726_0001_m_000003_0
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Starting task: attempt_local778124726_0001_m_000004_0
[INFO] 15/12/11 16:04:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00000:0+20000
[INFO] 15/12/11 16:04:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: [V:0:0:4]
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: [V:0:0:4]
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:29 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:29 mapred.MapTask: Spilling map output
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufend = 50000; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/12/11 16:04:29 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 16:04:29 mapred.Task: Task:attempt_local778124726_0001_m_000004_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:29 mapred.Task: Task 'attempt_local778124726_0001_m_000004_0' done.
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Finishing task: attempt_local778124726_0001_m_000004_0
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Starting task: attempt_local778124726_0001_m_000005_0
[INFO] 15/12/11 16:04:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00001:0+0
[INFO] 15/12/11 16:04:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: []
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: []
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:29 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:29 mapred.Task: Task:attempt_local778124726_0001_m_000005_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:29 mapred.Task: Task 'attempt_local778124726_0001_m_000005_0' done.
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Finishing task: attempt_local778124726_0001_m_000005_0
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Starting task: attempt_local778124726_0001_m_000006_0
[INFO] 15/12/11 16:04:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00001:0+0
[INFO] 15/12/11 16:04:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: []
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: []
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:29 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:29 mapred.Task: Task:attempt_local778124726_0001_m_000006_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:29 mapred.Task: Task 'attempt_local778124726_0001_m_000006_0' done.
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Finishing task: attempt_local778124726_0001_m_000006_0
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Starting task: attempt_local778124726_0001_m_000007_0
[INFO] 15/12/11 16:04:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00001:0+0
[INFO] 15/12/11 16:04:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: []
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: []
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:29 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:29 mapred.Task: Task:attempt_local778124726_0001_m_000007_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:29 mapred.Task: Task 'attempt_local778124726_0001_m_000007_0' done.
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Finishing task: attempt_local778124726_0001_m_000007_0
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Starting task: attempt_local778124726_0001_m_000008_0
[INFO] 15/12/11 16:04:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00001:0+0
[INFO] 15/12/11 16:04:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: []
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: []
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:29 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:29 mapred.Task: Task:attempt_local778124726_0001_m_000008_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:29 mapred.Task: Task 'attempt_local778124726_0001_m_000008_0' done.
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Finishing task: attempt_local778124726_0001_m_000008_0
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Starting task: attempt_local778124726_0001_m_000009_0
[INFO] 15/12/11 16:04:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00001:0+0
[INFO] 15/12/11 16:04:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: []
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 16:04:29 tupleops.TupleOpFactory: []
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:29 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:29 mapred.Task: Task:attempt_local778124726_0001_m_000009_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:29 mapred.Task: Task 'attempt_local778124726_0001_m_000009_0' done.
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Finishing task: attempt_local778124726_0001_m_000009_0
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: Starting task: attempt_local778124726_0001_r_000000_0
[INFO] 15/12/11 16:04:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:29 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7b348d1f
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/11 16:04:29 reduce.EventFetcher: attempt_local778124726_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/11 16:04:29 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local778124726_0001_m_000001_0 decomp: 70002 len: 70006 to MEMORY
[INFO] 15/12/11 16:04:29 reduce.InMemoryMapOutput: Read 70002 bytes from map-output for attempt_local778124726_0001_m_000001_0
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 70002, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->70002
[INFO] 15/12/11 16:04:29 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local778124726_0001_m_000007_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/11 16:04:29 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local778124726_0001_m_000007_0
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 70002, usedMemory ->70004
[INFO] 15/12/11 16:04:29 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local778124726_0001_m_000004_0 decomp: 70002 len: 70006 to MEMORY
[INFO] 15/12/11 16:04:29 reduce.InMemoryMapOutput: Read 70002 bytes from map-output for attempt_local778124726_0001_m_000004_0
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 70002, inMemoryMapOutputs.size() -> 3, commitMemory -> 70004, usedMemory ->140006
[INFO] 15/12/11 16:04:29 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local778124726_0001_m_000005_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/11 16:04:29 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local778124726_0001_m_000005_0
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 140006, usedMemory ->140008
[INFO] 15/12/11 16:04:29 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local778124726_0001_m_000002_0 decomp: 70002 len: 70006 to MEMORY
[INFO] 15/12/11 16:04:29 reduce.InMemoryMapOutput: Read 70002 bytes from map-output for attempt_local778124726_0001_m_000002_0
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 70002, inMemoryMapOutputs.size() -> 5, commitMemory -> 140008, usedMemory ->210010
[INFO] 15/12/11 16:04:29 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local778124726_0001_m_000008_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/11 16:04:29 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local778124726_0001_m_000008_0
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 210010, usedMemory ->210012
[INFO] 15/12/11 16:04:29 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local778124726_0001_m_000009_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/11 16:04:29 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local778124726_0001_m_000009_0
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 7, commitMemory -> 210012, usedMemory ->210014
[INFO] 15/12/11 16:04:29 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local778124726_0001_m_000006_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/11 16:04:29 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local778124726_0001_m_000006_0
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 8, commitMemory -> 210014, usedMemory ->210016
[INFO] 15/12/11 16:04:29 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local778124726_0001_m_000003_0 decomp: 70002 len: 70006 to MEMORY
[INFO] 15/12/11 16:04:29 reduce.InMemoryMapOutput: Read 70002 bytes from map-output for attempt_local778124726_0001_m_000003_0
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 70002, inMemoryMapOutputs.size() -> 9, commitMemory -> 210016, usedMemory ->280018
[INFO] 15/12/11 16:04:29 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local778124726_0001_m_000000_0 decomp: 1071762 len: 1071766 to MEMORY
[INFO] 15/12/11 16:04:29 reduce.InMemoryMapOutput: Read 1071762 bytes from map-output for attempt_local778124726_0001_m_000000_0
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1071762, inMemoryMapOutputs.size() -> 10, commitMemory -> 280018, usedMemory ->1351780
[INFO] 15/12/11 16:04:29 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: 10 / 10 copied.
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/11 16:04:29 mapred.Merger: Merging 10 sorted segments
[INFO] 15/12/11 16:04:29 mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 1351750 bytes
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: Merged 10 segments, 1351780 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: Merging 1 files, 1351766 bytes from disk
[INFO] 15/12/11 16:04:29 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/11 16:04:29 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/11 16:04:29 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1351758 bytes
[INFO] 15/12/11 16:04:29 mapred.LocalJobRunner: 10 / 10 copied.
[INFO] 15/12/11 16:04:29 Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[INFO] 15/12/11 16:04:30 mapred.Task: Task:attempt_local778124726_0001_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:30 mapred.LocalJobRunner: 10 / 10 copied.
[INFO] 15/12/11 16:04:30 mapred.Task: Task attempt_local778124726_0001_r_000000_0 is allowed to commit now
[INFO] 15/12/11 16:04:30 output.FileOutputCommitter: Saved output of task 'attempt_local778124726_0001_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_029/20151211_160423/tmp/TMP_1_R4V1-R4U1-R4T1-R4S1-/_temporary/0/task_local778124726_0001_r_000000
[INFO] 15/12/11 16:04:30 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/11 16:04:30 mapred.Task: Task 'attempt_local778124726_0001_r_000000_0' done.
[INFO] 15/12/11 16:04:30 mapred.LocalJobRunner: Finishing task: attempt_local778124726_0001_r_000000_0
[INFO] 15/12/11 16:04:30 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/11 16:04:34 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/11 16:04:34 hadoop2.HadoopEngine2: Starting round 2 (EVAL)
[INFO] 15/12/11 16:04:34 converter.MultiRoundConverter: Adding guard path:input/experiments/EXP_029/4/R
[INFO] 15/12/11 16:04:34 converter.MultiRoundConverter: Adding intermediate path:scratch/EXP_029/20151211_160423/tmp/TMP_1_R4V1-R4U1-R4T1-R4S1-
[INFO] 15/12/11 16:04:34 converter.MultiRoundConverter: Adding intermediate path:scratch/EXP_029/20151211_160423/tmp/TMP_1_R4V1-R4U1-R4T1-R4S1-
[INFO] 15/12/11 16:04:34 converter.MultiRoundConverter: Adding intermediate path:scratch/EXP_029/20151211_160423/tmp/TMP_1_R4V1-R4U1-R4T1-R4S1-
[INFO] 15/12/11 16:04:34 converter.MultiRoundConverter: Adding intermediate path:scratch/EXP_029/20151211_160423/tmp/TMP_1_R4V1-R4U1-R4T1-R4S1-
[INFO] 15/12/11 16:04:34 converter.MultiRoundConverter: Setting EVAL Reduce tasks to 1
[INFO] 15/12/11 16:04:34 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/_SUCCESS
[INFO] 15/12/11 16:04:34 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00001
[INFO] 15/12/11 16:04:34 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/_SUCCESS
[INFO] 15/12/11 16:04:34 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00001
[INFO] 15/12/11 16:04:34 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/_SUCCESS
[INFO] 15/12/11 16:04:34 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00001
[INFO] 15/12/11 16:04:34 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/_SUCCESS
[INFO] 15/12/11 16:04:34 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00001
[INFO] 15/12/11 16:04:34 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/_SUCCESS
[INFO] 15/12/11 16:04:34 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00001
[INFO] 15/12/11 16:04:34 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/11 16:04:38 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/12/11 16:04:38 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/11 16:04:38 input.FileInputFormat: Total input paths to process : 2
[INFO] 15/12/11 16:04:38 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/12/11 16:04:38 mapreduce.JobSubmitter: number of splits:3
[INFO] 15/12/11 16:04:38 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/11 16:04:38 mapreduce.JobSubmitter: Submitting tokens for job: job_local805744186_0002
[WARN] 15/12/11 16:04:38 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny805744186/.staging/job_local805744186_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/11 16:04:38 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny805744186/.staging/job_local805744186_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/11 16:04:38 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local805744186_0002/job_local805744186_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/11 16:04:38 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local805744186_0002/job_local805744186_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/11 16:04:38 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/11 16:04:38 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/11 16:04:38 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/11 16:04:38 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/11 16:04:38 mapred.LocalJobRunner: Starting task: attempt_local805744186_0002_m_000000_0
[INFO] 15/12/11 16:04:38 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:38 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:38 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_029/20151211_160423/tmp/TMP_1_R4V1-R4U1-R4T1-R4S1-/part-r-00000:0+1365344
[INFO] 15/12/11 16:04:38 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:38 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:38 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:38 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:38 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:38 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:39 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:39 mapred.MapTask: Spilling map output
[INFO] 15/12/11 16:04:39 mapred.MapTask: bufstart = 0; bufend = 711760; bufvoid = 104857600
[INFO] 15/12/11 16:04:39 mapred.MapTask: kvstart = 26214396(104857584); kvend = 25894400(103577600); length = 319997/6553600
[INFO] 15/12/11 16:04:39 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 16:04:39 mapred.Task: Task:attempt_local805744186_0002_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:39 mapred.Task: Task 'attempt_local805744186_0002_m_000000_0' done.
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: Finishing task: attempt_local805744186_0002_m_000000_0
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: Starting task: attempt_local805744186_0002_m_000001_0
[INFO] 15/12/11 16:04:39 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:39 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:39 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00000:0+400000
[INFO] 15/12/11 16:04:39 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:39 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:39 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:39 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:39 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:39 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:39 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:39 mapred.MapTask: Spilling map output
[INFO] 15/12/11 16:04:39 mapred.MapTask: bufstart = 0; bufend = 741760; bufvoid = 104857600
[INFO] 15/12/11 16:04:39 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26014400(104057600); length = 199997/6553600
[INFO] 15/12/11 16:04:39 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 16:04:39 mapred.Task: Task:attempt_local805744186_0002_m_000001_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:39 mapred.Task: Task 'attempt_local805744186_0002_m_000001_0' done.
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: Finishing task: attempt_local805744186_0002_m_000001_0
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: Starting task: attempt_local805744186_0002_m_000002_0
[INFO] 15/12/11 16:04:39 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:39 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:39 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00001:0+0
[INFO] 15/12/11 16:04:39 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 16:04:39 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 16:04:39 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 16:04:39 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 16:04:39 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 16:04:39 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: 
[INFO] 15/12/11 16:04:39 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 16:04:39 mapred.Task: Task:attempt_local805744186_0002_m_000002_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: map
[INFO] 15/12/11 16:04:39 mapred.Task: Task 'attempt_local805744186_0002_m_000002_0' done.
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: Finishing task: attempt_local805744186_0002_m_000002_0
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: Starting task: attempt_local805744186_0002_r_000000_0
[INFO] 15/12/11 16:04:39 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 16:04:39 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 16:04:39 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4015bbf0
[INFO] 15/12/11 16:04:39 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/11 16:04:39 reduce.EventFetcher: attempt_local805744186_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/11 16:04:39 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local805744186_0002_m_000001_0 decomp: 841762 len: 841766 to MEMORY
[INFO] 15/12/11 16:04:39 reduce.InMemoryMapOutput: Read 841762 bytes from map-output for attempt_local805744186_0002_m_000001_0
[INFO] 15/12/11 16:04:39 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 841762, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->841762
[INFO] 15/12/11 16:04:39 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local805744186_0002_m_000000_0 decomp: 871762 len: 871766 to MEMORY
[INFO] 15/12/11 16:04:39 reduce.InMemoryMapOutput: Read 871762 bytes from map-output for attempt_local805744186_0002_m_000000_0
[INFO] 15/12/11 16:04:39 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 871762, inMemoryMapOutputs.size() -> 2, commitMemory -> 841762, usedMemory ->1713524
[INFO] 15/12/11 16:04:39 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local805744186_0002_m_000002_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/11 16:04:39 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local805744186_0002_m_000002_0
[INFO] 15/12/11 16:04:39 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 1713524, usedMemory ->1713526
[INFO] 15/12/11 16:04:39 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/11 16:04:39 reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/11 16:04:39 mapred.Merger: Merging 3 sorted segments
[INFO] 15/12/11 16:04:39 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 1713514 bytes
[INFO] 15/12/11 16:04:39 reduce.MergeManagerImpl: Merged 3 segments, 1713526 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/11 16:04:39 reduce.MergeManagerImpl: Merging 1 files, 1713526 bytes from disk
[INFO] 15/12/11 16:04:39 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/11 16:04:39 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/11 16:04:39 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1713517 bytes
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/11 16:04:39 mapred.Task: Task:attempt_local805744186_0002_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/11 16:04:39 mapred.Task: Task attempt_local805744186_0002_r_000000_0 is allowed to commit now
[INFO] 15/12/11 16:04:39 output.FileOutputCommitter: Saved output of task 'attempt_local805744186_0002_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151211_160423/Out1(x0)/_temporary/0/task_local805744186_0002_r_000000
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/11 16:04:39 mapred.Task: Task 'attempt_local805744186_0002_r_000000_0' done.
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: Finishing task: attempt_local805744186_0002_r_000000_0
[INFO] 15/12/11 16:04:39 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/11 16:04:44 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/11 16:04:44 converter.MultiRoundConverter: Moving files: output/EXP_029/20151211_160423/Out1(x0)/Out1-r-* output/EXP_029/20151211_160423/OUT_0_Out1
[INFO] 15/12/11 16:04:44 hadoop2.HadoopEngine2: Running time: 20945ms
[INFO] 15/12/11 16:04:44 hadoop2.HadoopEngine2: SUCCESS: all jobs (2) completed!
[INFO] 15/12/11 16:04:44 hadoop2.HadoopEngine2: Stopping job control
Counters for job: query1.gumbo_VAL_R4V1-R4U1-R4T1-R4S1-
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=10059058
	FILE: Number of bytes written=19632423
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=90000
	Map output records=120000
	Map output bytes=1111760
	Map output materialized bytes=1351820
	Input split bytes=3210
	Combine input records=0
	Combine output records=0
	Reduce input groups=4
	Reduce shuffle bytes=1351820
	Reduce input records=120000
	Reduce output records=80000
	Spilled Records=240000
	Shuffled Maps =10
	Failed Shuffles=0
	Merged Map outputs=10
	GC time elapsed (ms)=17
	Total committed heap usage (bytes)=8589410304
gumbo.engine.hadoop2.mapreduce.GumboCounters
gumbo.engine.hadoop2.mapreduce.GumboCounters
	ASSERT_IN=40000
	ASSERT_OUT=40000
	RECORDS_IN=90000
	RECORDS_OUT=80000
	REQUEST_IN=80000
	REQUEST_OUT=200000
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=1376020
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=90000
	Map output records=120000
	Map output bytes=1111760
	Map output materialized bytes=1351820
	Input split bytes=3210
	Combine input records=0
	Combine output records=0
	Reduce input groups=4
	Reduce shuffle bytes=1351820
	Reduce input records=120000
	Reduce output records=80000
	Spilled Records=240000
	Shuffled Maps =10
	Failed Shuffles=0
	Merged Map outputs=10
	GC time elapsed (ms)=17
	Total committed heap usage (bytes)=8589410304
Counters for job: query1.gumbo_EVAL_Out1(x0)
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=23725986
	FILE: Number of bytes written=26042776
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=130000
	Map output records=130000
	Map output bytes=1453520
	Map output materialized bytes=1713538
	Input split bytes=971
	Combine input records=0
	Combine output records=0
	Reduce input groups=50000
	Reduce shuffle bytes=1713538
	Reduce input records=130000
	Reduce output records=0
	Spilled Records=260000
	Shuffled Maps =3
	Failed Shuffles=0
	Merged Map outputs=3
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=6040322048
gumbo.engine.hadoop2.mapreduce.GumboCounters
gumbo.engine.hadoop2.mapreduce.GumboCounters
	CONFIRM_IN=80000
	DATA_IN=50000
	DATA_OUT=50000
	RECORDS_IN=50002
	RECORDS_OUT=10000
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=130000
	Map output records=130000
	Map output bytes=1453520
	Map output materialized bytes=1713538
	Input split bytes=971
	Combine input records=0
	Combine output records=0
	Reduce input groups=50000
	Reduce shuffle bytes=1713538
	Reduce input records=130000
	Reduce output records=0
	Spilled Records=260000
	Shuffled Maps =3
	Failed Shuffles=0
	Merged Map outputs=3
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=6040322048

Overall Counters
--------------------------------------------------------------------------------
File System Counters
	FILE: Number of bytes read=33785044
	FILE: Number of bytes written=45675199
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
	Map input records=440000
	Map output records=500000
	Map output bytes=5130560
	Map output materialized bytes=6130716
	Input split bytes=8362
	Combine input records=0
	Combine output records=0
	Reduce input groups=100008
	Reduce shuffle bytes=6130716
	Reduce input records=500000
	Reduce output records=160000
	Spilled Records=1000000
	Shuffled Maps =26
	Failed Shuffles=0
	Merged Map outputs=26
	GC time elapsed (ms)=34
	Total committed heap usage (bytes)=29259464704
File Input Format Counters 
	Bytes Read=0
File Output Format Counters 
	Bytes Written=1376028

