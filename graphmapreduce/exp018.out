gumbo.engine.guardAddressOptimizationOn=true
gumbo.engine.proofsymbol=#
gumbo.engine.mapOutputGroupingPolicy=ALLGROUP
gumbo.engine.simulator.classname=gumbo.engine.hadoop2.estimation.MapSimulator
gumbo.engine.guardedCombinerOptimizationOn=false
gumbo.engine.assertConstantOptimizationOn=true
gumbo.compiler.partitioner=gumbo.compiler.partitioner.HeightPartitioner
gumbo.engine.valeval.projection.prepack=true
gumbo.engine.round1FiniteMemoryOptimizationOn=false
gumbo.engine.hadoop.reducersize_mb=1024
gumbo.engine.val.projection.prepack=true
gumbo.engine.reduceOutputGroupingOptimizationOn=true
gumbo.engine.mapOutputGroupingOptimizationOn=true
gumbo.engine.eval.output.merge=false
gumbo.compiler.unnest=true
gumbo.engine.grouper.beststopindicator=0
gumbo.engine.requestAtomIdOptimizationOn=true
gumbo.engine.guardKeepAliveOptimizationOn=true
[INFO] 15/12/07 17:34:36 gumbo.Gumbo: Input: 
R(x0,x1,x2,x3);input/experiments/EXP_029/4/R;csv;'S(x0);input/experiments/EXP_029/4/S;csv;'T(x0);input/experiments/EXP_029/4/T;csv;'U(x0);input/experiments/EXP_029/4/U;csv;'V(x0);input/experiments/EXP_029/4/V;csv;
Output: output/EXP_029
Scratch: scratch/EXP_029
Queries: 
[(Out1(x,y,z,w) : R(x,y,z,w) & (S(x) & (T(y) & (U(z) & V(w)))))]

[INFO] 15/12/07 17:34:36 compiler.GFCompiler: Adding suffix to scratch and output paths: /20151207_173436
[INFO] 15/12/07 17:34:36 compiler.GFCompiler: Decomposing GFEs into basic GFEs (BGFEs)...
[INFO] 15/12/07 17:34:36 compiler.GFCompiler: Number of BGFEs: 1
[INFO] 15/12/07 17:34:36 compiler.GFCompiler: Unnesting BGFEs...
[(gumbohelpOut12(x,y,z,w) : gumbohelpOut11(x,y,z,w) & T(y)), (Out1(x,y,z,w) : gumbohelpOut12(x,y,z,w) & V(w)), (gumbohelpOut10(x,y,z,w) : R(x,y,z,w) & S(x)), (gumbohelpOut11(x,y,z,w) : gumbohelpOut10(x,y,z,w) & U(z))]
[INFO] 15/12/07 17:34:36 compiler.GFCompiler: New number of BGFEs: 4
[INFO] 15/12/07 17:34:36 compiler.GFCompiler: Converting BGFEs into CalculationUnits (CUs)...
[INFO] 15/12/07 17:34:36 compiler.GFCompiler: Number of CUs: 4
[INFO] 15/12/07 17:34:36 compiler.GFCompiler: Linking Calculation Units (CUs)...
[INFO] 15/12/07 17:34:36 compiler.GFCompiler: Creating initial file mapping...
[INFO] 15/12/07 17:34:36 compiler.GFCompiler: file mapping:
Out root: output/EXP_029/20151207_173436
Scratch root: scratch/EXP_029/20151207_173436
Temp root: scratch/EXP_029/20151207_173436/tmp
R(x0,x1,x2,x3) <- [input/experiments/EXP_029/4/R]
S(x0) <- [input/experiments/EXP_029/4/S]
T(x0) <- [input/experiments/EXP_029/4/T]
U(x0) <- [input/experiments/EXP_029/4/U]
V(x0) <- [input/experiments/EXP_029/4/V]
Out1(x0,x1,x2,x3) -> [output/EXP_029/20151207_173436/OUT_3_Out1]
gumbohelpOut11(x0,x1,x2,x3) -> [output/EXP_029/20151207_173436/OUT_0_gumbohelpOut11]
gumbohelpOut10(x0,x1,x2,x3) -> [output/EXP_029/20151207_173436/OUT_1_gumbohelpOut10]
gumbohelpOut12(x0,x1,x2,x3) -> [output/EXP_029/20151207_173436/OUT_2_gumbohelpOut12]
Temp dirs: 

[INFO] 15/12/07 17:34:36 compiler.GFCompiler: Partitioning...
[INFO] 15/12/07 17:34:36 compiler.GFCompiler: Number of partitions: 4

Query:
query1.gumbo

Partitions:
-----------
Calculation Unit Partitions: {
{id : 2 Depends on: None. - (gumbohelpOut10(x,y,z,w) : R(x,y,z,w) & S(x))}
{id : 3 Depends on: 2, - (gumbohelpOut11(x,y,z,w) : gumbohelpOut10(x,y,z,w) & U(z))}
{id : 0 Depends on: 3, - (gumbohelpOut12(x,y,z,w) : gumbohelpOut11(x,y,z,w) & T(y))}
{id : 1 Depends on: 0, - (Out1(x,y,z,w) : gumbohelpOut12(x,y,z,w) & V(w))}
}
Folders:
-------
Out root: output/EXP_029/20151207_173436
Scratch root: scratch/EXP_029/20151207_173436
Temp root: scratch/EXP_029/20151207_173436/tmp
R(x0,x1,x2,x3) <- [input/experiments/EXP_029/4/R]
S(x0) <- [input/experiments/EXP_029/4/S]
T(x0) <- [input/experiments/EXP_029/4/T]
U(x0) <- [input/experiments/EXP_029/4/U]
V(x0) <- [input/experiments/EXP_029/4/V]
Out1(x0,x1,x2,x3) -> [output/EXP_029/20151207_173436/OUT_3_Out1]
gumbohelpOut11(x0,x1,x2,x3) -> [output/EXP_029/20151207_173436/OUT_0_gumbohelpOut11]
gumbohelpOut10(x0,x1,x2,x3) -> [output/EXP_029/20151207_173436/OUT_1_gumbohelpOut10]
gumbohelpOut12(x0,x1,x2,x3) -> [output/EXP_029/20151207_173436/OUT_2_gumbohelpOut12]
Temp dirs: 

[INFO] 15/12/07 17:34:36 hadoop2.HadoopEngine2: Creating Job Control for: query1.gumbo
[INFO] 15/12/07 17:34:36 hadoop2.HadoopEngine2: Starting Job-control thread: Gumbo-Workflow-Thread_query1.gumbo
[WARN] 15/12/07 17:34:37 util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 15/12/07 17:34:37 hadoop2.HadoopEngine2: Using 1-round evaluation for Calculation Unit Partitions: {
{id : 2 Depends on: None. - (gumbohelpOut10(x,y,z,w) : R(x,y,z,w) & S(x))}
{id : 3 Depends on: 2, - (gumbohelpOut11(x,y,z,w) : gumbohelpOut10(x,y,z,w) & U(z))}
{id : 0 Depends on: 3, - (gumbohelpOut12(x,y,z,w) : gumbohelpOut11(x,y,z,w) & T(y))}
{id : 1 Depends on: 0, - (Out1(x,y,z,w) : gumbohelpOut12(x,y,z,w) & V(w))}
}
[INFO] 15/12/07 17:34:37 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/4/R to mapper
[INFO] 15/12/07 17:34:37 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/4/S to mapper
[INFO] 15/12/07 17:34:37 converter.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
[INFO] 15/12/07 17:34:37 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/_SUCCESS
[INFO] 15/12/07 17:34:37 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00001
[INFO] 15/12/07 17:34:37 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/_SUCCESS
[INFO] 15/12/07 17:34:37 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00001
[INFO] 15/12/07 17:34:37 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/_SUCCESS
[INFO] 15/12/07 17:34:37 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00001
[INFO] 15/12/07 17:34:37 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/_SUCCESS
[INFO] 15/12/07 17:34:37 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00001
[INFO] 15/12/07 17:34:37 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/_SUCCESS
[INFO] 15/12/07 17:34:37 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00001
[INFO] 15/12/07 17:34:37 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/07 17:34:41 Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO] 15/12/07 17:34:41 jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN] 15/12/07 17:34:41 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/07 17:34:41 input.FileInputFormat: Total input paths to process : 4
[INFO] 15/12/07 17:34:41 mapreduce.JobSubmitter: number of splits:4
[INFO] 15/12/07 17:34:41 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/07 17:34:41 mapreduce.JobSubmitter: Submitting tokens for job: job_local2136419326_0001
[WARN] 15/12/07 17:34:41 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny2136419326/.staging/job_local2136419326_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/07 17:34:41 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny2136419326/.staging/job_local2136419326_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/07 17:34:41 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local2136419326_0001/job_local2136419326_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/07 17:34:41 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local2136419326_0001/job_local2136419326_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/07 17:34:41 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/07 17:34:41 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/07 17:34:41 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/07 17:34:41 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/07 17:34:41 mapred.LocalJobRunner: Starting task: attempt_local2136419326_0001_m_000000_0
[INFO] 15/12/07 17:34:42 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:34:42 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:34:42 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00000:0+400000
[INFO] 15/12/07 17:34:42 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:34:42 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:34:42 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:34:42 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:34:42 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:34:42 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: [R:0:0,1,2,3]
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: [R:0:0,1,2,3]
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:34:42 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:34:42 mapred.MapTask: Spilling map output
[INFO] 15/12/07 17:34:42 mapred.MapTask: bufstart = 0; bufend = 550000; bufvoid = 104857600
[INFO] 15/12/07 17:34:42 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26014400(104057600); length = 199997/6553600
[INFO] 15/12/07 17:34:42 mapred.MapTask: Finished spill 0
[INFO] 15/12/07 17:34:42 mapred.Task: Task:attempt_local2136419326_0001_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:34:42 mapred.Task: Task 'attempt_local2136419326_0001_m_000000_0' done.
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: Finishing task: attempt_local2136419326_0001_m_000000_0
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: Starting task: attempt_local2136419326_0001_m_000001_0
[INFO] 15/12/07 17:34:42 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:34:42 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:34:42 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00000:0+20000
[INFO] 15/12/07 17:34:42 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:34:42 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:34:42 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:34:42 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:34:42 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:34:42 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: [S:0:0:4]
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: [S:0:0:4]
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:34:42 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:34:42 mapred.MapTask: Spilling map output
[INFO] 15/12/07 17:34:42 mapred.MapTask: bufstart = 0; bufend = 50000; bufvoid = 104857600
[INFO] 15/12/07 17:34:42 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/12/07 17:34:42 mapred.MapTask: Finished spill 0
[INFO] 15/12/07 17:34:42 mapred.Task: Task:attempt_local2136419326_0001_m_000001_0 is done. And is in the process of committing
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:34:42 mapred.Task: Task 'attempt_local2136419326_0001_m_000001_0' done.
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: Finishing task: attempt_local2136419326_0001_m_000001_0
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: Starting task: attempt_local2136419326_0001_m_000002_0
[INFO] 15/12/07 17:34:42 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:34:42 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:34:42 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00001:0+0
[INFO] 15/12/07 17:34:42 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:34:42 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:34:42 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:34:42 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:34:42 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:34:42 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: []
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: []
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:34:42 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:34:42 mapred.Task: Task:attempt_local2136419326_0001_m_000002_0 is done. And is in the process of committing
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:34:42 mapred.Task: Task 'attempt_local2136419326_0001_m_000002_0' done.
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: Finishing task: attempt_local2136419326_0001_m_000002_0
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: Starting task: attempt_local2136419326_0001_m_000003_0
[INFO] 15/12/07 17:34:42 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:34:42 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:34:42 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00001:0+0
[INFO] 15/12/07 17:34:42 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:34:42 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:34:42 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:34:42 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:34:42 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:34:42 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: []
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:34:42 tupleops.TupleOpFactory: []
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:34:42 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:34:42 mapred.Task: Task:attempt_local2136419326_0001_m_000003_0 is done. And is in the process of committing
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:34:42 mapred.Task: Task 'attempt_local2136419326_0001_m_000003_0' done.
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: Finishing task: attempt_local2136419326_0001_m_000003_0
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: Starting task: attempt_local2136419326_0001_r_000000_0
[INFO] 15/12/07 17:34:42 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:34:42 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:34:42 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@75c8ae8b
[INFO] 15/12/07 17:34:42 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/07 17:34:42 reduce.EventFetcher: attempt_local2136419326_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/07 17:34:42 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2136419326_0001_m_000000_0 decomp: 650002 len: 650006 to MEMORY
[INFO] 15/12/07 17:34:42 reduce.InMemoryMapOutput: Read 650002 bytes from map-output for attempt_local2136419326_0001_m_000000_0
[INFO] 15/12/07 17:34:42 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 650002, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->650002
[INFO] 15/12/07 17:34:42 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2136419326_0001_m_000001_0 decomp: 70002 len: 70006 to MEMORY
[INFO] 15/12/07 17:34:42 reduce.InMemoryMapOutput: Read 70002 bytes from map-output for attempt_local2136419326_0001_m_000001_0
[INFO] 15/12/07 17:34:42 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 70002, inMemoryMapOutputs.size() -> 2, commitMemory -> 650002, usedMemory ->720004
[INFO] 15/12/07 17:34:42 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2136419326_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/07 17:34:42 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2136419326_0001_m_000002_0
[INFO] 15/12/07 17:34:42 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 720004, usedMemory ->720006
[INFO] 15/12/07 17:34:42 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2136419326_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/07 17:34:42 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2136419326_0001_m_000003_0
[INFO] 15/12/07 17:34:42 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 720006, usedMemory ->720008
[INFO] 15/12/07 17:34:42 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/12/07 17:34:42 reduce.MergeManagerImpl: finalMerge called with 4 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/07 17:34:42 mapred.Merger: Merging 4 sorted segments
[INFO] 15/12/07 17:34:42 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 719996 bytes
[INFO] 15/12/07 17:34:42 reduce.MergeManagerImpl: Merged 4 segments, 720008 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/07 17:34:42 reduce.MergeManagerImpl: Merging 1 files, 720006 bytes from disk
[INFO] 15/12/07 17:34:42 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/07 17:34:42 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/07 17:34:42 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 719998 bytes
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/12/07 17:34:42 Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[INFO] 15/12/07 17:34:42 mapred.Task: Task:attempt_local2136419326_0001_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/12/07 17:34:42 mapred.Task: Task attempt_local2136419326_0001_r_000000_0 is allowed to commit now
[INFO] 15/12/07 17:34:42 output.FileOutputCommitter: Saved output of task 'attempt_local2136419326_0001_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151207_173436/gumbohelpOut10(x0,x1,x2,x3)/_temporary/0/task_local2136419326_0001_r_000000
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/07 17:34:42 mapred.Task: Task 'attempt_local2136419326_0001_r_000000_0' done.
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: Finishing task: attempt_local2136419326_0001_r_000000_0
[INFO] 15/12/07 17:34:42 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/07 17:34:46 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/07 17:34:46 converter.MultiRoundConverter: Moving files: output/EXP_029/20151207_173436/gumbohelpOut10(x0,x1,x2,x3)/gumbohelpOut10-r-* output/EXP_029/20151207_173436/OUT_1_gumbohelpOut10
[INFO] 15/12/07 17:34:46 hadoop2.HadoopEngine2: Using 1-round evaluation for Calculation Unit Partitions: {
{id : 2 Depends on: None. - (gumbohelpOut10(x,y,z,w) : R(x,y,z,w) & S(x))}
{id : 3 Depends on: 2, - (gumbohelpOut11(x,y,z,w) : gumbohelpOut10(x,y,z,w) & U(z))}
{id : 0 Depends on: 3, - (gumbohelpOut12(x,y,z,w) : gumbohelpOut11(x,y,z,w) & T(y))}
{id : 1 Depends on: 0, - (Out1(x,y,z,w) : gumbohelpOut12(x,y,z,w) & V(w))}
}
[INFO] 15/12/07 17:34:46 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/4/U to mapper
[INFO] 15/12/07 17:34:46 converter.MultiRoundConverter: Adding path output/EXP_029/20151207_173436/OUT_1_gumbohelpOut10 to mapper
[INFO] 15/12/07 17:34:46 converter.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
[INFO] 15/12/07 17:34:46 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/_SUCCESS
[INFO] 15/12/07 17:34:46 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00001
[INFO] 15/12/07 17:34:46 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/_SUCCESS
[INFO] 15/12/07 17:34:46 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00001
[INFO] 15/12/07 17:34:46 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/_SUCCESS
[INFO] 15/12/07 17:34:46 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00001
[INFO] 15/12/07 17:34:46 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/_SUCCESS
[INFO] 15/12/07 17:34:46 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00001
[INFO] 15/12/07 17:34:46 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/_SUCCESS
[INFO] 15/12/07 17:34:46 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00001
[INFO] 15/12/07 17:34:46 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/07 17:34:51 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/12/07 17:34:51 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/07 17:34:52 input.FileInputFormat: Total input paths to process : 3
[INFO] 15/12/07 17:34:52 mapreduce.JobSubmitter: number of splits:3
[INFO] 15/12/07 17:34:52 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/07 17:34:52 mapreduce.JobSubmitter: Submitting tokens for job: job_local1274213928_0002
[WARN] 15/12/07 17:34:52 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1274213928/.staging/job_local1274213928_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/07 17:34:52 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1274213928/.staging/job_local1274213928_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/07 17:34:52 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1274213928_0002/job_local1274213928_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/07 17:34:52 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1274213928_0002/job_local1274213928_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/07 17:34:52 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: Starting task: attempt_local1274213928_0002_m_000000_0
[INFO] 15/12/07 17:34:52 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:34:52 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:34:52 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151207_173436/OUT_1_gumbohelpOut10/gumbohelpOut10-r-00000:0+160000
[INFO] 15/12/07 17:34:52 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:34:52 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:34:52 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:34:52 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:34:52 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:34:52 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:34:52 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:34:52 tupleops.TupleOpFactory: [gumbohelpOut10:2:0,1,2,3]
[INFO] 15/12/07 17:34:52 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:34:52 tupleops.TupleOpFactory: [gumbohelpOut10:2:0,1,2,3]
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:34:52 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:34:52 mapred.MapTask: Spilling map output
[INFO] 15/12/07 17:34:52 mapred.MapTask: bufstart = 0; bufend = 220000; bufvoid = 104857600
[INFO] 15/12/07 17:34:52 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26134400(104537600); length = 79997/6553600
[INFO] 15/12/07 17:34:52 mapred.MapTask: Finished spill 0
[INFO] 15/12/07 17:34:52 mapred.Task: Task:attempt_local1274213928_0002_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:34:52 mapred.Task: Task 'attempt_local1274213928_0002_m_000000_0' done.
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: Finishing task: attempt_local1274213928_0002_m_000000_0
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: Starting task: attempt_local1274213928_0002_m_000001_0
[INFO] 15/12/07 17:34:52 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:34:52 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:34:52 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00000:0+20000
[INFO] 15/12/07 17:34:52 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:34:52 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:34:52 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:34:52 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:34:52 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:34:52 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:34:52 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:34:52 tupleops.TupleOpFactory: [U:0:0:6]
[INFO] 15/12/07 17:34:52 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:34:52 tupleops.TupleOpFactory: [U:0:0:6]
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:34:52 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:34:52 mapred.MapTask: Spilling map output
[INFO] 15/12/07 17:34:52 mapred.MapTask: bufstart = 0; bufend = 50000; bufvoid = 104857600
[INFO] 15/12/07 17:34:52 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/12/07 17:34:52 mapred.MapTask: Finished spill 0
[INFO] 15/12/07 17:34:52 mapred.Task: Task:attempt_local1274213928_0002_m_000001_0 is done. And is in the process of committing
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:34:52 mapred.Task: Task 'attempt_local1274213928_0002_m_000001_0' done.
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: Finishing task: attempt_local1274213928_0002_m_000001_0
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: Starting task: attempt_local1274213928_0002_m_000002_0
[INFO] 15/12/07 17:34:52 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:34:52 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:34:52 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00001:0+0
[INFO] 15/12/07 17:34:52 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:34:52 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:34:52 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:34:52 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:34:52 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:34:52 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:34:52 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:34:52 tupleops.TupleOpFactory: []
[INFO] 15/12/07 17:34:52 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:34:52 tupleops.TupleOpFactory: []
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:34:52 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:34:52 mapred.Task: Task:attempt_local1274213928_0002_m_000002_0 is done. And is in the process of committing
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:34:52 mapred.Task: Task 'attempt_local1274213928_0002_m_000002_0' done.
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: Finishing task: attempt_local1274213928_0002_m_000002_0
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: Starting task: attempt_local1274213928_0002_r_000000_0
[INFO] 15/12/07 17:34:52 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:34:52 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:34:52 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1891bdf
[INFO] 15/12/07 17:34:52 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/07 17:34:52 reduce.EventFetcher: attempt_local1274213928_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/07 17:34:52 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1274213928_0002_m_000002_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/07 17:34:52 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1274213928_0002_m_000002_0
[INFO] 15/12/07 17:34:52 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
[INFO] 15/12/07 17:34:52 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1274213928_0002_m_000000_0 decomp: 260002 len: 260006 to MEMORY
[INFO] 15/12/07 17:34:52 reduce.InMemoryMapOutput: Read 260002 bytes from map-output for attempt_local1274213928_0002_m_000000_0
[INFO] 15/12/07 17:34:52 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 260002, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->260004
[INFO] 15/12/07 17:34:52 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1274213928_0002_m_000001_0 decomp: 70002 len: 70006 to MEMORY
[INFO] 15/12/07 17:34:52 reduce.InMemoryMapOutput: Read 70002 bytes from map-output for attempt_local1274213928_0002_m_000001_0
[INFO] 15/12/07 17:34:52 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 70002, inMemoryMapOutputs.size() -> 3, commitMemory -> 260004, usedMemory ->330006
[INFO] 15/12/07 17:34:52 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/07 17:34:52 reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/07 17:34:52 mapred.Merger: Merging 3 sorted segments
[INFO] 15/12/07 17:34:52 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 329996 bytes
[INFO] 15/12/07 17:34:52 reduce.MergeManagerImpl: Merged 3 segments, 330006 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/07 17:34:52 reduce.MergeManagerImpl: Merging 1 files, 330006 bytes from disk
[INFO] 15/12/07 17:34:52 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/07 17:34:52 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/07 17:34:52 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 329998 bytes
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/07 17:34:52 mapred.Task: Task:attempt_local1274213928_0002_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/07 17:34:52 mapred.Task: Task attempt_local1274213928_0002_r_000000_0 is allowed to commit now
[INFO] 15/12/07 17:34:52 output.FileOutputCommitter: Saved output of task 'attempt_local1274213928_0002_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151207_173436/gumbohelpOut11(x0,x1,x2,x3)/_temporary/0/task_local1274213928_0002_r_000000
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/07 17:34:52 mapred.Task: Task 'attempt_local1274213928_0002_r_000000_0' done.
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: Finishing task: attempt_local1274213928_0002_r_000000_0
[INFO] 15/12/07 17:34:52 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/07 17:34:57 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/07 17:34:57 converter.MultiRoundConverter: Moving files: output/EXP_029/20151207_173436/gumbohelpOut11(x0,x1,x2,x3)/gumbohelpOut11-r-* output/EXP_029/20151207_173436/OUT_0_gumbohelpOut11
[INFO] 15/12/07 17:34:57 hadoop2.HadoopEngine2: Using 1-round evaluation for Calculation Unit Partitions: {
{id : 2 Depends on: None. - (gumbohelpOut10(x,y,z,w) : R(x,y,z,w) & S(x))}
{id : 3 Depends on: 2, - (gumbohelpOut11(x,y,z,w) : gumbohelpOut10(x,y,z,w) & U(z))}
{id : 0 Depends on: 3, - (gumbohelpOut12(x,y,z,w) : gumbohelpOut11(x,y,z,w) & T(y))}
{id : 1 Depends on: 0, - (Out1(x,y,z,w) : gumbohelpOut12(x,y,z,w) & V(w))}
}
[INFO] 15/12/07 17:34:57 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/4/T to mapper
[INFO] 15/12/07 17:34:57 converter.MultiRoundConverter: Adding path output/EXP_029/20151207_173436/OUT_0_gumbohelpOut11 to mapper
[INFO] 15/12/07 17:34:57 converter.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
[INFO] 15/12/07 17:34:57 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/_SUCCESS
[INFO] 15/12/07 17:34:57 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00001
[INFO] 15/12/07 17:34:57 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/_SUCCESS
[INFO] 15/12/07 17:34:57 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00001
[INFO] 15/12/07 17:34:57 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/_SUCCESS
[INFO] 15/12/07 17:34:57 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00001
[INFO] 15/12/07 17:34:57 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/_SUCCESS
[INFO] 15/12/07 17:34:57 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00001
[INFO] 15/12/07 17:34:57 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/_SUCCESS
[INFO] 15/12/07 17:34:57 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00001
[INFO] 15/12/07 17:34:57 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/07 17:35:02 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/12/07 17:35:02 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/07 17:35:02 input.FileInputFormat: Total input paths to process : 3
[INFO] 15/12/07 17:35:02 mapreduce.JobSubmitter: number of splits:3
[INFO] 15/12/07 17:35:02 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/07 17:35:02 mapreduce.JobSubmitter: Submitting tokens for job: job_local251229861_0003
[WARN] 15/12/07 17:35:02 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny251229861/.staging/job_local251229861_0003/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/07 17:35:02 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny251229861/.staging/job_local251229861_0003/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/07 17:35:02 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local251229861_0003/job_local251229861_0003.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/07 17:35:02 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local251229861_0003/job_local251229861_0003.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/07 17:35:02 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: Starting task: attempt_local251229861_0003_m_000000_0
[INFO] 15/12/07 17:35:02 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:35:02 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:35:02 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151207_173436/OUT_0_gumbohelpOut11/gumbohelpOut11-r-00000:0+80000
[INFO] 15/12/07 17:35:02 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:35:02 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:35:02 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:35:02 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:35:02 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:35:02 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:35:02 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:35:02 tupleops.TupleOpFactory: [gumbohelpOut11:1:0,1,2,3]
[INFO] 15/12/07 17:35:02 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:35:02 tupleops.TupleOpFactory: [gumbohelpOut11:1:0,1,2,3]
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:35:02 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:35:02 mapred.MapTask: Spilling map output
[INFO] 15/12/07 17:35:02 mapred.MapTask: bufstart = 0; bufend = 110000; bufvoid = 104857600
[INFO] 15/12/07 17:35:02 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/12/07 17:35:02 mapred.MapTask: Finished spill 0
[INFO] 15/12/07 17:35:02 mapred.Task: Task:attempt_local251229861_0003_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:35:02 mapred.Task: Task 'attempt_local251229861_0003_m_000000_0' done.
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: Finishing task: attempt_local251229861_0003_m_000000_0
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: Starting task: attempt_local251229861_0003_m_000001_0
[INFO] 15/12/07 17:35:02 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:35:02 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:35:02 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00000:0+20000
[INFO] 15/12/07 17:35:02 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:35:02 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:35:02 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:35:02 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:35:02 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:35:02 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:35:02 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:35:02 tupleops.TupleOpFactory: [T:0:0:0]
[INFO] 15/12/07 17:35:02 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:35:02 tupleops.TupleOpFactory: [T:0:0:0]
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:35:02 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:35:02 mapred.MapTask: Spilling map output
[INFO] 15/12/07 17:35:02 mapred.MapTask: bufstart = 0; bufend = 50000; bufvoid = 104857600
[INFO] 15/12/07 17:35:02 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/12/07 17:35:02 mapred.MapTask: Finished spill 0
[INFO] 15/12/07 17:35:02 mapred.Task: Task:attempt_local251229861_0003_m_000001_0 is done. And is in the process of committing
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:35:02 mapred.Task: Task 'attempt_local251229861_0003_m_000001_0' done.
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: Finishing task: attempt_local251229861_0003_m_000001_0
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: Starting task: attempt_local251229861_0003_m_000002_0
[INFO] 15/12/07 17:35:02 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:35:02 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:35:02 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00001:0+0
[INFO] 15/12/07 17:35:02 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:35:02 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:35:02 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:35:02 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:35:02 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:35:02 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:35:02 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:35:02 tupleops.TupleOpFactory: []
[INFO] 15/12/07 17:35:02 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:35:02 tupleops.TupleOpFactory: []
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:35:02 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:35:02 mapred.Task: Task:attempt_local251229861_0003_m_000002_0 is done. And is in the process of committing
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:35:02 mapred.Task: Task 'attempt_local251229861_0003_m_000002_0' done.
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: Finishing task: attempt_local251229861_0003_m_000002_0
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: Starting task: attempt_local251229861_0003_r_000000_0
[INFO] 15/12/07 17:35:02 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:35:02 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:35:02 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5dec6311
[INFO] 15/12/07 17:35:02 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/07 17:35:02 reduce.EventFetcher: attempt_local251229861_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/07 17:35:02 reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local251229861_0003_m_000001_0 decomp: 70002 len: 70006 to MEMORY
[INFO] 15/12/07 17:35:02 reduce.InMemoryMapOutput: Read 70002 bytes from map-output for attempt_local251229861_0003_m_000001_0
[INFO] 15/12/07 17:35:02 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 70002, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->70002
[INFO] 15/12/07 17:35:02 reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local251229861_0003_m_000002_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/07 17:35:02 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local251229861_0003_m_000002_0
[INFO] 15/12/07 17:35:02 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 70002, usedMemory ->70004
[INFO] 15/12/07 17:35:02 reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local251229861_0003_m_000000_0 decomp: 130002 len: 130006 to MEMORY
[INFO] 15/12/07 17:35:02 reduce.InMemoryMapOutput: Read 130002 bytes from map-output for attempt_local251229861_0003_m_000000_0
[INFO] 15/12/07 17:35:02 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 130002, inMemoryMapOutputs.size() -> 3, commitMemory -> 70004, usedMemory ->200006
[INFO] 15/12/07 17:35:02 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/07 17:35:02 reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/07 17:35:02 mapred.Merger: Merging 3 sorted segments
[INFO] 15/12/07 17:35:02 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 199996 bytes
[INFO] 15/12/07 17:35:02 reduce.MergeManagerImpl: Merged 3 segments, 200006 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/07 17:35:02 reduce.MergeManagerImpl: Merging 1 files, 200006 bytes from disk
[INFO] 15/12/07 17:35:02 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/07 17:35:02 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/07 17:35:02 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 199998 bytes
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/07 17:35:02 mapred.Task: Task:attempt_local251229861_0003_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/07 17:35:02 mapred.Task: Task attempt_local251229861_0003_r_000000_0 is allowed to commit now
[INFO] 15/12/07 17:35:02 output.FileOutputCommitter: Saved output of task 'attempt_local251229861_0003_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151207_173436/gumbohelpOut12(x0,x1,x2,x3)/_temporary/0/task_local251229861_0003_r_000000
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/07 17:35:02 mapred.Task: Task 'attempt_local251229861_0003_r_000000_0' done.
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: Finishing task: attempt_local251229861_0003_r_000000_0
[INFO] 15/12/07 17:35:02 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/07 17:35:07 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/07 17:35:07 converter.MultiRoundConverter: Moving files: output/EXP_029/20151207_173436/gumbohelpOut12(x0,x1,x2,x3)/gumbohelpOut12-r-* output/EXP_029/20151207_173436/OUT_2_gumbohelpOut12
[INFO] 15/12/07 17:35:07 hadoop2.HadoopEngine2: Using 1-round evaluation for Calculation Unit Partitions: {
{id : 2 Depends on: None. - (gumbohelpOut10(x,y,z,w) : R(x,y,z,w) & S(x))}
{id : 3 Depends on: 2, - (gumbohelpOut11(x,y,z,w) : gumbohelpOut10(x,y,z,w) & U(z))}
{id : 0 Depends on: 3, - (gumbohelpOut12(x,y,z,w) : gumbohelpOut11(x,y,z,w) & T(y))}
{id : 1 Depends on: 0, - (Out1(x,y,z,w) : gumbohelpOut12(x,y,z,w) & V(w))}
}
[INFO] 15/12/07 17:35:07 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/4/V to mapper
[INFO] 15/12/07 17:35:07 converter.MultiRoundConverter: Adding path output/EXP_029/20151207_173436/OUT_2_gumbohelpOut12 to mapper
[INFO] 15/12/07 17:35:07 converter.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
[INFO] 15/12/07 17:35:07 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/_SUCCESS
[INFO] 15/12/07 17:35:07 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/R/part-00001
[INFO] 15/12/07 17:35:07 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/_SUCCESS
[INFO] 15/12/07 17:35:07 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/S/part-00001
[INFO] 15/12/07 17:35:07 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/_SUCCESS
[INFO] 15/12/07 17:35:07 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/T/part-00001
[INFO] 15/12/07 17:35:07 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/_SUCCESS
[INFO] 15/12/07 17:35:07 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/U/part-00001
[INFO] 15/12/07 17:35:07 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/_SUCCESS
[INFO] 15/12/07 17:35:07 utils.InputPathExpander: Skipping input file: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00001
[INFO] 15/12/07 17:35:07 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/07 17:35:12 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/12/07 17:35:12 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/07 17:35:12 input.FileInputFormat: Total input paths to process : 3
[INFO] 15/12/07 17:35:12 mapreduce.JobSubmitter: number of splits:3
[INFO] 15/12/07 17:35:12 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/07 17:35:12 mapreduce.JobSubmitter: Submitting tokens for job: job_local1366901988_0004
[WARN] 15/12/07 17:35:12 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1366901988/.staging/job_local1366901988_0004/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/07 17:35:12 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1366901988/.staging/job_local1366901988_0004/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/07 17:35:12 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1366901988_0004/job_local1366901988_0004.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/07 17:35:12 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1366901988_0004/job_local1366901988_0004.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/07 17:35:12 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: Starting task: attempt_local1366901988_0004_m_000000_0
[INFO] 15/12/07 17:35:12 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:35:12 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:35:12 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151207_173436/OUT_2_gumbohelpOut12/gumbohelpOut12-r-00000:0+80000
[INFO] 15/12/07 17:35:12 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:35:12 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:35:12 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:35:12 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:35:12 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:35:12 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:35:12 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:35:12 tupleops.TupleOpFactory: [gumbohelpOut12:3:0,1,2,3]
[INFO] 15/12/07 17:35:12 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:35:12 tupleops.TupleOpFactory: [gumbohelpOut12:3:0,1,2,3]
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:35:12 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:35:12 mapred.MapTask: Spilling map output
[INFO] 15/12/07 17:35:12 mapred.MapTask: bufstart = 0; bufend = 110000; bufvoid = 104857600
[INFO] 15/12/07 17:35:12 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/12/07 17:35:12 mapred.MapTask: Finished spill 0
[INFO] 15/12/07 17:35:12 mapred.Task: Task:attempt_local1366901988_0004_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:35:12 mapred.Task: Task 'attempt_local1366901988_0004_m_000000_0' done.
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: Finishing task: attempt_local1366901988_0004_m_000000_0
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: Starting task: attempt_local1366901988_0004_m_000001_0
[INFO] 15/12/07 17:35:12 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:35:12 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:35:12 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00000:0+20000
[INFO] 15/12/07 17:35:12 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:35:12 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:35:12 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:35:12 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:35:12 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:35:12 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:35:12 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:35:12 tupleops.TupleOpFactory: [V:0:0:2]
[INFO] 15/12/07 17:35:12 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:35:12 tupleops.TupleOpFactory: [V:0:0:2]
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:35:12 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:35:12 mapred.MapTask: Spilling map output
[INFO] 15/12/07 17:35:12 mapred.MapTask: bufstart = 0; bufend = 50000; bufvoid = 104857600
[INFO] 15/12/07 17:35:12 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/12/07 17:35:12 mapred.MapTask: Finished spill 0
[INFO] 15/12/07 17:35:12 mapred.Task: Task:attempt_local1366901988_0004_m_000001_0 is done. And is in the process of committing
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:35:12 mapred.Task: Task 'attempt_local1366901988_0004_m_000001_0' done.
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: Finishing task: attempt_local1366901988_0004_m_000001_0
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: Starting task: attempt_local1366901988_0004_m_000002_0
[INFO] 15/12/07 17:35:12 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:35:12 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:35:12 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/4/V/part-00001:0+0
[INFO] 15/12/07 17:35:12 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/07 17:35:12 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/07 17:35:12 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/07 17:35:12 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/07 17:35:12 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/07 17:35:12 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/07 17:35:12 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/07 17:35:12 tupleops.TupleOpFactory: []
[INFO] 15/12/07 17:35:12 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/07 17:35:12 tupleops.TupleOpFactory: []
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: 
[INFO] 15/12/07 17:35:12 mapred.MapTask: Starting flush of map output
[INFO] 15/12/07 17:35:12 mapred.Task: Task:attempt_local1366901988_0004_m_000002_0 is done. And is in the process of committing
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: map
[INFO] 15/12/07 17:35:12 mapred.Task: Task 'attempt_local1366901988_0004_m_000002_0' done.
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: Finishing task: attempt_local1366901988_0004_m_000002_0
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: Starting task: attempt_local1366901988_0004_r_000000_0
[INFO] 15/12/07 17:35:12 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/07 17:35:12 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/07 17:35:12 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12e1846d
[INFO] 15/12/07 17:35:12 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/07 17:35:12 reduce.EventFetcher: attempt_local1366901988_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/07 17:35:12 reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1366901988_0004_m_000000_0 decomp: 130002 len: 130006 to MEMORY
[INFO] 15/12/07 17:35:12 reduce.InMemoryMapOutput: Read 130002 bytes from map-output for attempt_local1366901988_0004_m_000000_0
[INFO] 15/12/07 17:35:12 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 130002, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->130002
[INFO] 15/12/07 17:35:12 reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1366901988_0004_m_000001_0 decomp: 70002 len: 70006 to MEMORY
[INFO] 15/12/07 17:35:12 reduce.InMemoryMapOutput: Read 70002 bytes from map-output for attempt_local1366901988_0004_m_000001_0
[INFO] 15/12/07 17:35:12 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 70002, inMemoryMapOutputs.size() -> 2, commitMemory -> 130002, usedMemory ->200004
[INFO] 15/12/07 17:35:12 reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1366901988_0004_m_000002_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/07 17:35:12 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1366901988_0004_m_000002_0
[INFO] 15/12/07 17:35:12 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 200004, usedMemory ->200006
[INFO] 15/12/07 17:35:12 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/07 17:35:12 reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/07 17:35:12 mapred.Merger: Merging 3 sorted segments
[INFO] 15/12/07 17:35:12 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 199996 bytes
[INFO] 15/12/07 17:35:12 reduce.MergeManagerImpl: Merged 3 segments, 200006 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/07 17:35:12 reduce.MergeManagerImpl: Merging 1 files, 200006 bytes from disk
[INFO] 15/12/07 17:35:12 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/07 17:35:12 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/07 17:35:12 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 199998 bytes
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/07 17:35:12 mapred.Task: Task:attempt_local1366901988_0004_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/07 17:35:12 mapred.Task: Task attempt_local1366901988_0004_r_000000_0 is allowed to commit now
[INFO] 15/12/07 17:35:12 output.FileOutputCommitter: Saved output of task 'attempt_local1366901988_0004_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151207_173436/Out1(x0,x1,x2,x3)/_temporary/0/task_local1366901988_0004_r_000000
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/07 17:35:12 mapred.Task: Task 'attempt_local1366901988_0004_r_000000_0' done.
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: Finishing task: attempt_local1366901988_0004_r_000000_0
[INFO] 15/12/07 17:35:12 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/07 17:35:17 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/07 17:35:17 converter.MultiRoundConverter: Moving files: output/EXP_029/20151207_173436/Out1(x0,x1,x2,x3)/Out1-r-* output/EXP_029/20151207_173436/OUT_3_Out1
[INFO] 15/12/07 17:35:17 hadoop2.HadoopEngine2: Running time: 40758ms
[INFO] 15/12/07 17:35:17 hadoop2.HadoopEngine2: SUCCESS: all jobs (4) completed!
[INFO] 15/12/07 17:35:17 hadoop2.HadoopEngine2: Stopping job control
