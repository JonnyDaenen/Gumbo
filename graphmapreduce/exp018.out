gumbo.engine.guardAddressOptimizationOn=true
gumbo.engine.proofsymbol=#
gumbo.engine.mapOutputGroupingPolicy=ALLGROUP
gumbo.engine.simulator.classname=gumbo.engine.hadoop2.estimation.MapSimulator
gumbo.engine.guardedCombinerOptimizationOn=false
gumbo.engine.assertConstantOptimizationOn=true
gumbo.compiler.partitioner=gumbo.compiler.partitioner.HeightPartitioner
gumbo.engine.valeval.projection.prepack=true
gumbo.engine.round1FiniteMemoryOptimizationOn=false
gumbo.engine.hadoop.reducersize_mb=1024
gumbo.engine.val.projection.prepack=true
gumbo.engine.reduceOutputGroupingOptimizationOn=true
gumbo.engine.mapOutputGroupingOptimizationOn=true
gumbo.engine.eval.output.merge=false
gumbo.compiler.unnest=true
gumbo.engine.grouper.beststopindicator=0
gumbo.engine.requestAtomIdOptimizationOn=true
gumbo.engine.guardKeepAliveOptimizationOn=true
[INFO] 15/12/08 11:15:44 gumbo.Gumbo: Input: 
R(x0,x1,x2,x3);input/experiments/EXP_029/1/R;csv;'S(x0);input/experiments/EXP_029/1/S;csv;'T(x0);input/experiments/EXP_029/1/T;csv;'U(x0);input/experiments/EXP_029/1/U;csv;'V(x0);input/experiments/EXP_029/1/V;csv;
Output: output/EXP_029
Scratch: scratch/EXP_029
Queries: 
[(Out1(x) : R(x,y,z,w) & ((S(x) & (T(x) & (U(x) & V(x)))) | ((S(y) & (T(y) & (U(y) & V(y)))) | ((S(z) & (T(z) & (U(z) & V(z)))) | (S(w) & (T(w) & (U(w) & V(w))))))))]

[INFO] 15/12/08 11:15:44 compiler.GFCompiler: Adding suffix to scratch and output paths: /20151208_111544
[INFO] 15/12/08 11:15:44 compiler.GFCompiler: Decomposing GFEs into basic GFEs (BGFEs)...
[INFO] 15/12/08 11:15:44 compiler.GFCompiler: Number of BGFEs: 1
[INFO] 15/12/08 11:15:44 compiler.GFCompiler: Unnesting BGFEs...
[(gumbohelpR11(x,y,z,w) : gumbohelpR10(x,y,z,w) & V(x)), (gumbohelpR1(x,y,z,w) : gumbohelpR0(x,y,z,w) & U(y)), (gumbohelpR13(x,y,z,w) : gumbohelpR12(x,y,z,w) & U(w)), (gumbohelpR14(x,y,z,w) : gumbohelpR13(x,y,z,w) & T(w)), (gumbohelpR8(x,y,z,w) : R(x,y,z,w) & S(x)), (gumbohelpR7(x,y,z,w) : gumbohelpR6(x,y,z,w) & V(z)), (gumbohelpR2(x,y,z,w) : gumbohelpR1(x,y,z,w) & T(y)), (gumbohelpR9(x,y,z,w) : gumbohelpR8(x,y,z,w) & U(x)), (Out1(x) : R(x,y,z,w) & (((gumbohelpR3(x,y,z,w) | gumbohelpR7(x,y,z,w)) | gumbohelpR11(x,y,z,w)) | gumbohelpR15(x,y,z,w))), (gumbohelpR4(x,y,z,w) : R(x,y,z,w) & S(z)), (gumbohelpR5(x,y,z,w) : gumbohelpR4(x,y,z,w) & U(z)), (gumbohelpR12(x,y,z,w) : R(x,y,z,w) & S(w)), (gumbohelpR10(x,y,z,w) : gumbohelpR9(x,y,z,w) & T(x)), (gumbohelpR3(x,y,z,w) : gumbohelpR2(x,y,z,w) & V(y)), (gumbohelpR0(x,y,z,w) : R(x,y,z,w) & S(y)), (gumbohelpR15(x,y,z,w) : gumbohelpR14(x,y,z,w) & V(w)), (gumbohelpR6(x,y,z,w) : gumbohelpR5(x,y,z,w) & T(z))]
[INFO] 15/12/08 11:15:44 compiler.GFCompiler: New number of BGFEs: 17
[INFO] 15/12/08 11:15:44 compiler.GFCompiler: Converting BGFEs into CalculationUnits (CUs)...
[INFO] 15/12/08 11:15:44 compiler.GFCompiler: Number of CUs: 17
[INFO] 15/12/08 11:15:44 compiler.GFCompiler: Linking Calculation Units (CUs)...
[INFO] 15/12/08 11:15:44 compiler.GFCompiler: Creating initial file mapping...
[INFO] 15/12/08 11:15:44 compiler.GFCompiler: file mapping:
Out root: output/EXP_029/20151208_111544
Scratch root: scratch/EXP_029/20151208_111544
Temp root: scratch/EXP_029/20151208_111544/tmp
R(x0,x1,x2,x3) <- [input/experiments/EXP_029/1/R]
S(x0) <- [input/experiments/EXP_029/1/S]
T(x0) <- [input/experiments/EXP_029/1/T]
U(x0) <- [input/experiments/EXP_029/1/U]
V(x0) <- [input/experiments/EXP_029/1/V]
gumbohelpR10(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_0_gumbohelpR10]
gumbohelpR11(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_1_gumbohelpR11]
gumbohelpR12(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_2_gumbohelpR12]
Out1(x0) -> [output/EXP_029/20151208_111544/OUT_16_Out1]
gumbohelpR13(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_3_gumbohelpR13]
gumbohelpR14(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_4_gumbohelpR14]
gumbohelpR5(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_5_gumbohelpR5]
gumbohelpR6(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_6_gumbohelpR6]
gumbohelpR15(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_7_gumbohelpR15]
gumbohelpR7(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_8_gumbohelpR7]
gumbohelpR8(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_9_gumbohelpR8]
gumbohelpR9(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_10_gumbohelpR9]
gumbohelpR0(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_11_gumbohelpR0]
gumbohelpR1(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_12_gumbohelpR1]
gumbohelpR2(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_13_gumbohelpR2]
gumbohelpR3(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_14_gumbohelpR3]
gumbohelpR4(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_15_gumbohelpR4]
Temp dirs: 

[INFO] 15/12/08 11:15:44 compiler.GFCompiler: Partitioning...
[INFO] 15/12/08 11:15:44 compiler.GFCompiler: Number of partitions: 5

Query:
query4.gumbo

Partitions:
-----------
Calculation Unit Partitions: {
{id : 4 Depends on: None. - (gumbohelpR8(x,y,z,w) : R(x,y,z,w) & S(x))id : 9 Depends on: None. - (gumbohelpR4(x,y,z,w) : R(x,y,z,w) & S(z))id : 11 Depends on: None. - (gumbohelpR12(x,y,z,w) : R(x,y,z,w) & S(w))id : 14 Depends on: None. - (gumbohelpR0(x,y,z,w) : R(x,y,z,w) & S(y))}
{id : 1 Depends on: 14, - (gumbohelpR1(x,y,z,w) : gumbohelpR0(x,y,z,w) & U(y))id : 2 Depends on: 11, - (gumbohelpR13(x,y,z,w) : gumbohelpR12(x,y,z,w) & U(w))id : 7 Depends on: 4, - (gumbohelpR9(x,y,z,w) : gumbohelpR8(x,y,z,w) & U(x))id : 10 Depends on: 9, - (gumbohelpR5(x,y,z,w) : gumbohelpR4(x,y,z,w) & U(z))}
{id : 3 Depends on: 2, - (gumbohelpR14(x,y,z,w) : gumbohelpR13(x,y,z,w) & T(w))id : 6 Depends on: 1, - (gumbohelpR2(x,y,z,w) : gumbohelpR1(x,y,z,w) & T(y))id : 12 Depends on: 7, - (gumbohelpR10(x,y,z,w) : gumbohelpR9(x,y,z,w) & T(x))id : 16 Depends on: 10, - (gumbohelpR6(x,y,z,w) : gumbohelpR5(x,y,z,w) & T(z))}
{id : 0 Depends on: 12, - (gumbohelpR11(x,y,z,w) : gumbohelpR10(x,y,z,w) & V(x))id : 5 Depends on: 16, - (gumbohelpR7(x,y,z,w) : gumbohelpR6(x,y,z,w) & V(z))id : 13 Depends on: 6, - (gumbohelpR3(x,y,z,w) : gumbohelpR2(x,y,z,w) & V(y))id : 15 Depends on: 3, - (gumbohelpR15(x,y,z,w) : gumbohelpR14(x,y,z,w) & V(w))}
{id : 8 Depends on: 0,13,15,5, - (Out1(x) : R(x,y,z,w) & (((gumbohelpR3(x,y,z,w) | gumbohelpR7(x,y,z,w)) | gumbohelpR11(x,y,z,w)) | gumbohelpR15(x,y,z,w)))}
}
Folders:
-------
Out root: output/EXP_029/20151208_111544
Scratch root: scratch/EXP_029/20151208_111544
Temp root: scratch/EXP_029/20151208_111544/tmp
R(x0,x1,x2,x3) <- [input/experiments/EXP_029/1/R]
S(x0) <- [input/experiments/EXP_029/1/S]
T(x0) <- [input/experiments/EXP_029/1/T]
U(x0) <- [input/experiments/EXP_029/1/U]
V(x0) <- [input/experiments/EXP_029/1/V]
gumbohelpR10(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_0_gumbohelpR10]
gumbohelpR11(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_1_gumbohelpR11]
gumbohelpR12(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_2_gumbohelpR12]
Out1(x0) -> [output/EXP_029/20151208_111544/OUT_16_Out1]
gumbohelpR13(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_3_gumbohelpR13]
gumbohelpR14(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_4_gumbohelpR14]
gumbohelpR5(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_5_gumbohelpR5]
gumbohelpR6(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_6_gumbohelpR6]
gumbohelpR15(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_7_gumbohelpR15]
gumbohelpR7(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_8_gumbohelpR7]
gumbohelpR8(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_9_gumbohelpR8]
gumbohelpR9(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_10_gumbohelpR9]
gumbohelpR0(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_11_gumbohelpR0]
gumbohelpR1(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_12_gumbohelpR1]
gumbohelpR2(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_13_gumbohelpR2]
gumbohelpR3(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_14_gumbohelpR3]
gumbohelpR4(x0,x1,x2,x3) -> [output/EXP_029/20151208_111544/OUT_15_gumbohelpR4]
Temp dirs: 

[INFO] 15/12/08 11:15:44 hadoop2.HadoopEngine2: Creating Job Control for: query4.gumbo
[INFO] 15/12/08 11:15:44 hadoop2.HadoopEngine2: Starting Job-control thread: Gumbo-Workflow-Thread_query4.gumbo
[WARN] 15/12/08 11:15:44 util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 15/12/08 11:15:44 hadoop2.HadoopEngine2: Using 1-round evaluation for Calculation Unit Partitions: {
{id : 4 Depends on: None. - (gumbohelpR8(x,y,z,w) : R(x,y,z,w) & S(x))id : 9 Depends on: None. - (gumbohelpR4(x,y,z,w) : R(x,y,z,w) & S(z))id : 11 Depends on: None. - (gumbohelpR12(x,y,z,w) : R(x,y,z,w) & S(w))id : 14 Depends on: None. - (gumbohelpR0(x,y,z,w) : R(x,y,z,w) & S(y))}
{id : 1 Depends on: 14, - (gumbohelpR1(x,y,z,w) : gumbohelpR0(x,y,z,w) & U(y))id : 2 Depends on: 11, - (gumbohelpR13(x,y,z,w) : gumbohelpR12(x,y,z,w) & U(w))id : 7 Depends on: 4, - (gumbohelpR9(x,y,z,w) : gumbohelpR8(x,y,z,w) & U(x))id : 10 Depends on: 9, - (gumbohelpR5(x,y,z,w) : gumbohelpR4(x,y,z,w) & U(z))}
{id : 3 Depends on: 2, - (gumbohelpR14(x,y,z,w) : gumbohelpR13(x,y,z,w) & T(w))id : 6 Depends on: 1, - (gumbohelpR2(x,y,z,w) : gumbohelpR1(x,y,z,w) & T(y))id : 12 Depends on: 7, - (gumbohelpR10(x,y,z,w) : gumbohelpR9(x,y,z,w) & T(x))id : 16 Depends on: 10, - (gumbohelpR6(x,y,z,w) : gumbohelpR5(x,y,z,w) & T(z))}
{id : 0 Depends on: 12, - (gumbohelpR11(x,y,z,w) : gumbohelpR10(x,y,z,w) & V(x))id : 5 Depends on: 16, - (gumbohelpR7(x,y,z,w) : gumbohelpR6(x,y,z,w) & V(z))id : 13 Depends on: 6, - (gumbohelpR3(x,y,z,w) : gumbohelpR2(x,y,z,w) & V(y))id : 15 Depends on: 3, - (gumbohelpR15(x,y,z,w) : gumbohelpR14(x,y,z,w) & V(w))}
{id : 8 Depends on: 0,13,15,5, - (Out1(x) : R(x,y,z,w) & (((gumbohelpR3(x,y,z,w) | gumbohelpR7(x,y,z,w)) | gumbohelpR11(x,y,z,w)) | gumbohelpR15(x,y,z,w)))}
}
[INFO] 15/12/08 11:15:44 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/1/R to mapper
[INFO] 15/12/08 11:15:44 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/1/S to mapper
[INFO] 15/12/08 11:15:44 converter.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
[INFO] 15/12/08 11:15:44 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/08 11:15:49 Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO] 15/12/08 11:15:49 jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN] 15/12/08 11:15:49 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/08 11:15:49 input.FileInputFormat: Total input paths to process : 2
[INFO] 15/12/08 11:15:49 mapreduce.JobSubmitter: number of splits:2
[INFO] 15/12/08 11:15:49 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/08 11:15:49 mapreduce.JobSubmitter: Submitting tokens for job: job_local1207493359_0001
[WARN] 15/12/08 11:15:49 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1207493359/.staging/job_local1207493359_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/08 11:15:49 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1207493359/.staging/job_local1207493359_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/08 11:15:49 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1207493359_0001/job_local1207493359_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/08 11:15:49 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1207493359_0001/job_local1207493359_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/08 11:15:49 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: Starting task: attempt_local1207493359_0001_m_000000_0
[INFO] 15/12/08 11:15:49 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/08 11:15:49 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/08 11:15:49 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/1/R/R.txt:0+1166
[INFO] 15/12/08 11:15:49 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/08 11:15:49 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/08 11:15:49 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/08 11:15:49 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/08 11:15:49 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/08 11:15:49 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/08 11:15:49 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/08 11:15:49 tupleops.TupleOpFactory: [R:3:0,1,2,3, R:1:0,1,2,3, R:0:0,1,2,3, R:2:0,1,2,3]
[INFO] 15/12/08 11:15:49 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/08 11:15:49 tupleops.TupleOpFactory: [R:3:0,1,2,3, R:1:0,1,2,3, R:0:0,1,2,3, R:2:0,1,2,3]
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: 
[INFO] 15/12/08 11:15:49 mapred.MapTask: Starting flush of map output
[INFO] 15/12/08 11:15:49 mapred.MapTask: Spilling map output
[INFO] 15/12/08 11:15:49 mapred.MapTask: bufstart = 0; bufend = 6230; bufvoid = 104857600
[INFO] 15/12/08 11:15:49 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26212800(104851200); length = 1597/6553600
[INFO] 15/12/08 11:15:49 mapred.MapTask: Finished spill 0
[INFO] 15/12/08 11:15:49 mapred.Task: Task:attempt_local1207493359_0001_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: map
[INFO] 15/12/08 11:15:49 mapred.Task: Task 'attempt_local1207493359_0001_m_000000_0' done.
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: Finishing task: attempt_local1207493359_0001_m_000000_0
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: Starting task: attempt_local1207493359_0001_m_000001_0
[INFO] 15/12/08 11:15:49 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/08 11:15:49 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/08 11:15:49 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/1/S/S.txt:0+289
[INFO] 15/12/08 11:15:49 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/08 11:15:49 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/08 11:15:49 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/08 11:15:49 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/08 11:15:49 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/08 11:15:49 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/08 11:15:49 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/08 11:15:49 tupleops.TupleOpFactory: [S:0:0:23, S:0:0:28, S:0:0:20, S:0:0:8]
[INFO] 15/12/08 11:15:49 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/08 11:15:49 tupleops.TupleOpFactory: [S:0:0:23,28,20,8]
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: 
[INFO] 15/12/08 11:15:49 mapred.MapTask: Starting flush of map output
[INFO] 15/12/08 11:15:49 mapred.MapTask: Spilling map output
[INFO] 15/12/08 11:15:49 mapred.MapTask: bufstart = 0; bufend = 1157; bufvoid = 104857600
[INFO] 15/12/08 11:15:49 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
[INFO] 15/12/08 11:15:49 mapred.MapTask: Finished spill 0
[INFO] 15/12/08 11:15:49 mapred.Task: Task:attempt_local1207493359_0001_m_000001_0 is done. And is in the process of committing
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: map
[INFO] 15/12/08 11:15:49 mapred.Task: Task 'attempt_local1207493359_0001_m_000001_0' done.
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: Finishing task: attempt_local1207493359_0001_m_000001_0
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: Starting task: attempt_local1207493359_0001_r_000000_0
[INFO] 15/12/08 11:15:49 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/08 11:15:49 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/08 11:15:49 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4623aa
[INFO] 15/12/08 11:15:49 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/08 11:15:49 reduce.EventFetcher: attempt_local1207493359_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/08 11:15:49 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1207493359_0001_m_000000_0 decomp: 7032 len: 7036 to MEMORY
[INFO] 15/12/08 11:15:49 reduce.InMemoryMapOutput: Read 7032 bytes from map-output for attempt_local1207493359_0001_m_000000_0
[INFO] 15/12/08 11:15:49 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 7032, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7032
[INFO] 15/12/08 11:15:49 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1207493359_0001_m_000001_0 decomp: 1359 len: 1363 to MEMORY
[INFO] 15/12/08 11:15:49 reduce.InMemoryMapOutput: Read 1359 bytes from map-output for attempt_local1207493359_0001_m_000001_0
[INFO] 15/12/08 11:15:49 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1359, inMemoryMapOutputs.size() -> 2, commitMemory -> 7032, usedMemory ->8391
[INFO] 15/12/08 11:15:49 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/08 11:15:49 reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/08 11:15:49 mapred.Merger: Merging 2 sorted segments
[INFO] 15/12/08 11:15:49 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8383 bytes
[INFO] 15/12/08 11:15:49 reduce.MergeManagerImpl: Merged 2 segments, 8391 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/08 11:15:49 reduce.MergeManagerImpl: Merging 1 files, 8393 bytes from disk
[INFO] 15/12/08 11:15:49 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/08 11:15:49 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/08 11:15:49 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8385 bytes
[INFO] 15/12/08 11:15:49 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/08 11:15:50 Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[INFO] 15/12/08 11:15:50 mapred.Task: Task:attempt_local1207493359_0001_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/08 11:15:50 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/08 11:15:50 mapred.Task: Task attempt_local1207493359_0001_r_000000_0 is allowed to commit now
[INFO] 15/12/08 11:15:50 output.FileOutputCommitter: Saved output of task 'attempt_local1207493359_0001_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151208_111544/gumbohelpR8(x0,x1,x2,x3)gumbohelpR4(x0,x1,x2,x3)gumbohelpR12(x0,x1,x2,x3)gumbohelpR0(x0,x1,x2,x3)/_temporary/0/task_local1207493359_0001_r_000000
[INFO] 15/12/08 11:15:50 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/08 11:15:50 mapred.Task: Task 'attempt_local1207493359_0001_r_000000_0' done.
[INFO] 15/12/08 11:15:50 mapred.LocalJobRunner: Finishing task: attempt_local1207493359_0001_r_000000_0
[INFO] 15/12/08 11:15:50 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/08 11:15:54 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/08 11:15:54 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR8(x0,x1,x2,x3)gumbohelpR4(x0,x1,x2,x3)gumbohelpR12(x0,x1,x2,x3)gumbohelpR0(x0,x1,x2,x3)/gumbohelpR0-r-* output/EXP_029/20151208_111544/OUT_11_gumbohelpR0
[INFO] 15/12/08 11:15:54 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR8(x0,x1,x2,x3)gumbohelpR4(x0,x1,x2,x3)gumbohelpR12(x0,x1,x2,x3)gumbohelpR0(x0,x1,x2,x3)/gumbohelpR12-r-* output/EXP_029/20151208_111544/OUT_2_gumbohelpR12
[INFO] 15/12/08 11:15:54 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR8(x0,x1,x2,x3)gumbohelpR4(x0,x1,x2,x3)gumbohelpR12(x0,x1,x2,x3)gumbohelpR0(x0,x1,x2,x3)/gumbohelpR4-r-* output/EXP_029/20151208_111544/OUT_15_gumbohelpR4
[INFO] 15/12/08 11:15:54 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR8(x0,x1,x2,x3)gumbohelpR4(x0,x1,x2,x3)gumbohelpR12(x0,x1,x2,x3)gumbohelpR0(x0,x1,x2,x3)/gumbohelpR8-r-* output/EXP_029/20151208_111544/OUT_9_gumbohelpR8
[INFO] 15/12/08 11:15:54 hadoop2.HadoopEngine2: Using 1-round evaluation for Calculation Unit Partitions: {
{id : 4 Depends on: None. - (gumbohelpR8(x,y,z,w) : R(x,y,z,w) & S(x))id : 9 Depends on: None. - (gumbohelpR4(x,y,z,w) : R(x,y,z,w) & S(z))id : 11 Depends on: None. - (gumbohelpR12(x,y,z,w) : R(x,y,z,w) & S(w))id : 14 Depends on: None. - (gumbohelpR0(x,y,z,w) : R(x,y,z,w) & S(y))}
{id : 1 Depends on: 14, - (gumbohelpR1(x,y,z,w) : gumbohelpR0(x,y,z,w) & U(y))id : 2 Depends on: 11, - (gumbohelpR13(x,y,z,w) : gumbohelpR12(x,y,z,w) & U(w))id : 7 Depends on: 4, - (gumbohelpR9(x,y,z,w) : gumbohelpR8(x,y,z,w) & U(x))id : 10 Depends on: 9, - (gumbohelpR5(x,y,z,w) : gumbohelpR4(x,y,z,w) & U(z))}
{id : 3 Depends on: 2, - (gumbohelpR14(x,y,z,w) : gumbohelpR13(x,y,z,w) & T(w))id : 6 Depends on: 1, - (gumbohelpR2(x,y,z,w) : gumbohelpR1(x,y,z,w) & T(y))id : 12 Depends on: 7, - (gumbohelpR10(x,y,z,w) : gumbohelpR9(x,y,z,w) & T(x))id : 16 Depends on: 10, - (gumbohelpR6(x,y,z,w) : gumbohelpR5(x,y,z,w) & T(z))}
{id : 0 Depends on: 12, - (gumbohelpR11(x,y,z,w) : gumbohelpR10(x,y,z,w) & V(x))id : 5 Depends on: 16, - (gumbohelpR7(x,y,z,w) : gumbohelpR6(x,y,z,w) & V(z))id : 13 Depends on: 6, - (gumbohelpR3(x,y,z,w) : gumbohelpR2(x,y,z,w) & V(y))id : 15 Depends on: 3, - (gumbohelpR15(x,y,z,w) : gumbohelpR14(x,y,z,w) & V(w))}
{id : 8 Depends on: 0,13,15,5, - (Out1(x) : R(x,y,z,w) & (((gumbohelpR3(x,y,z,w) | gumbohelpR7(x,y,z,w)) | gumbohelpR11(x,y,z,w)) | gumbohelpR15(x,y,z,w)))}
}
[INFO] 15/12/08 11:15:54 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_11_gumbohelpR0 to mapper
[INFO] 15/12/08 11:15:54 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/1/U to mapper
[INFO] 15/12/08 11:15:54 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_2_gumbohelpR12 to mapper
[INFO] 15/12/08 11:15:54 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_15_gumbohelpR4 to mapper
[INFO] 15/12/08 11:15:54 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_9_gumbohelpR8 to mapper
[INFO] 15/12/08 11:15:54 converter.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
[INFO] 15/12/08 11:15:54 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/08 11:15:59 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/12/08 11:15:59 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/08 11:15:59 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/12/08 11:15:59 mapreduce.JobSubmitter: number of splits:1
[INFO] 15/12/08 11:15:59 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/08 11:15:59 mapreduce.JobSubmitter: Submitting tokens for job: job_local356625692_0002
[WARN] 15/12/08 11:15:59 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny356625692/.staging/job_local356625692_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/08 11:15:59 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny356625692/.staging/job_local356625692_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/08 11:15:59 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local356625692_0002/job_local356625692_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/08 11:15:59 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local356625692_0002/job_local356625692_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/08 11:15:59 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: Starting task: attempt_local356625692_0002_m_000000_0
[INFO] 15/12/08 11:15:59 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/08 11:15:59 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/08 11:15:59 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/1/U/U.txt:0+293
[INFO] 15/12/08 11:15:59 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/08 11:15:59 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/08 11:15:59 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/08 11:15:59 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/08 11:15:59 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/08 11:15:59 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/08 11:15:59 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/08 11:15:59 tupleops.TupleOpFactory: [U:0:0:14, U:0:0:22, U:0:0:5, U:0:0:2]
[INFO] 15/12/08 11:15:59 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/08 11:15:59 tupleops.TupleOpFactory: [U:0:0:14,22,5,2]
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: 
[INFO] 15/12/08 11:15:59 mapred.MapTask: Starting flush of map output
[INFO] 15/12/08 11:15:59 mapred.MapTask: Spilling map output
[INFO] 15/12/08 11:15:59 mapred.MapTask: bufstart = 0; bufend = 1161; bufvoid = 104857600
[INFO] 15/12/08 11:15:59 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
[INFO] 15/12/08 11:15:59 mapred.MapTask: Finished spill 0
[INFO] 15/12/08 11:15:59 mapred.Task: Task:attempt_local356625692_0002_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: map
[INFO] 15/12/08 11:15:59 mapred.Task: Task 'attempt_local356625692_0002_m_000000_0' done.
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: Finishing task: attempt_local356625692_0002_m_000000_0
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: Starting task: attempt_local356625692_0002_r_000000_0
[INFO] 15/12/08 11:15:59 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/08 11:15:59 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/08 11:15:59 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3b5ba33a
[INFO] 15/12/08 11:15:59 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/08 11:15:59 reduce.EventFetcher: attempt_local356625692_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/08 11:15:59 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local356625692_0002_m_000000_0 decomp: 1363 len: 1367 to MEMORY
[INFO] 15/12/08 11:15:59 reduce.InMemoryMapOutput: Read 1363 bytes from map-output for attempt_local356625692_0002_m_000000_0
[INFO] 15/12/08 11:15:59 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1363, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1363
[INFO] 15/12/08 11:15:59 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: 1 / 1 copied.
[INFO] 15/12/08 11:15:59 reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/08 11:15:59 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/08 11:15:59 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1359 bytes
[INFO] 15/12/08 11:15:59 reduce.MergeManagerImpl: Merged 1 segments, 1363 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/08 11:15:59 reduce.MergeManagerImpl: Merging 1 files, 1367 bytes from disk
[INFO] 15/12/08 11:15:59 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/08 11:15:59 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/08 11:15:59 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1359 bytes
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: 1 / 1 copied.
[INFO] 15/12/08 11:15:59 mapred.Task: Task:attempt_local356625692_0002_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: 1 / 1 copied.
[INFO] 15/12/08 11:15:59 mapred.Task: Task attempt_local356625692_0002_r_000000_0 is allowed to commit now
[INFO] 15/12/08 11:15:59 output.FileOutputCommitter: Saved output of task 'attempt_local356625692_0002_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151208_111544/gumbohelpR1(x0,x1,x2,x3)gumbohelpR13(x0,x1,x2,x3)gumbohelpR9(x0,x1,x2,x3)gumbohelpR5(x0,x1,x2,x3)/_temporary/0/task_local356625692_0002_r_000000
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/08 11:15:59 mapred.Task: Task 'attempt_local356625692_0002_r_000000_0' done.
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: Finishing task: attempt_local356625692_0002_r_000000_0
[INFO] 15/12/08 11:15:59 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/08 11:16:04 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/08 11:16:04 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR1(x0,x1,x2,x3)gumbohelpR13(x0,x1,x2,x3)gumbohelpR9(x0,x1,x2,x3)gumbohelpR5(x0,x1,x2,x3)/gumbohelpR1-r-* output/EXP_029/20151208_111544/OUT_12_gumbohelpR1
[INFO] 15/12/08 11:16:04 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR1(x0,x1,x2,x3)gumbohelpR13(x0,x1,x2,x3)gumbohelpR9(x0,x1,x2,x3)gumbohelpR5(x0,x1,x2,x3)/gumbohelpR13-r-* output/EXP_029/20151208_111544/OUT_3_gumbohelpR13
[INFO] 15/12/08 11:16:04 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR1(x0,x1,x2,x3)gumbohelpR13(x0,x1,x2,x3)gumbohelpR9(x0,x1,x2,x3)gumbohelpR5(x0,x1,x2,x3)/gumbohelpR5-r-* output/EXP_029/20151208_111544/OUT_5_gumbohelpR5
[INFO] 15/12/08 11:16:04 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR1(x0,x1,x2,x3)gumbohelpR13(x0,x1,x2,x3)gumbohelpR9(x0,x1,x2,x3)gumbohelpR5(x0,x1,x2,x3)/gumbohelpR9-r-* output/EXP_029/20151208_111544/OUT_10_gumbohelpR9
[INFO] 15/12/08 11:16:04 hadoop2.HadoopEngine2: Using 1-round evaluation for Calculation Unit Partitions: {
{id : 4 Depends on: None. - (gumbohelpR8(x,y,z,w) : R(x,y,z,w) & S(x))id : 9 Depends on: None. - (gumbohelpR4(x,y,z,w) : R(x,y,z,w) & S(z))id : 11 Depends on: None. - (gumbohelpR12(x,y,z,w) : R(x,y,z,w) & S(w))id : 14 Depends on: None. - (gumbohelpR0(x,y,z,w) : R(x,y,z,w) & S(y))}
{id : 1 Depends on: 14, - (gumbohelpR1(x,y,z,w) : gumbohelpR0(x,y,z,w) & U(y))id : 2 Depends on: 11, - (gumbohelpR13(x,y,z,w) : gumbohelpR12(x,y,z,w) & U(w))id : 7 Depends on: 4, - (gumbohelpR9(x,y,z,w) : gumbohelpR8(x,y,z,w) & U(x))id : 10 Depends on: 9, - (gumbohelpR5(x,y,z,w) : gumbohelpR4(x,y,z,w) & U(z))}
{id : 3 Depends on: 2, - (gumbohelpR14(x,y,z,w) : gumbohelpR13(x,y,z,w) & T(w))id : 6 Depends on: 1, - (gumbohelpR2(x,y,z,w) : gumbohelpR1(x,y,z,w) & T(y))id : 12 Depends on: 7, - (gumbohelpR10(x,y,z,w) : gumbohelpR9(x,y,z,w) & T(x))id : 16 Depends on: 10, - (gumbohelpR6(x,y,z,w) : gumbohelpR5(x,y,z,w) & T(z))}
{id : 0 Depends on: 12, - (gumbohelpR11(x,y,z,w) : gumbohelpR10(x,y,z,w) & V(x))id : 5 Depends on: 16, - (gumbohelpR7(x,y,z,w) : gumbohelpR6(x,y,z,w) & V(z))id : 13 Depends on: 6, - (gumbohelpR3(x,y,z,w) : gumbohelpR2(x,y,z,w) & V(y))id : 15 Depends on: 3, - (gumbohelpR15(x,y,z,w) : gumbohelpR14(x,y,z,w) & V(w))}
{id : 8 Depends on: 0,13,15,5, - (Out1(x) : R(x,y,z,w) & (((gumbohelpR3(x,y,z,w) | gumbohelpR7(x,y,z,w)) | gumbohelpR11(x,y,z,w)) | gumbohelpR15(x,y,z,w)))}
}
[INFO] 15/12/08 11:16:04 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/1/T to mapper
[INFO] 15/12/08 11:16:04 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_12_gumbohelpR1 to mapper
[INFO] 15/12/08 11:16:04 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_3_gumbohelpR13 to mapper
[INFO] 15/12/08 11:16:04 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_5_gumbohelpR5 to mapper
[INFO] 15/12/08 11:16:04 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_10_gumbohelpR9 to mapper
[INFO] 15/12/08 11:16:04 converter.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
[INFO] 15/12/08 11:16:04 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/08 11:16:09 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/12/08 11:16:09 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/08 11:16:09 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/12/08 11:16:09 mapreduce.JobSubmitter: number of splits:1
[INFO] 15/12/08 11:16:09 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/08 11:16:09 mapreduce.JobSubmitter: Submitting tokens for job: job_local1098271957_0003
[WARN] 15/12/08 11:16:09 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1098271957/.staging/job_local1098271957_0003/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/08 11:16:09 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1098271957/.staging/job_local1098271957_0003/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/08 11:16:09 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1098271957_0003/job_local1098271957_0003.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/08 11:16:09 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1098271957_0003/job_local1098271957_0003.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/08 11:16:09 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: Starting task: attempt_local1098271957_0003_m_000000_0
[INFO] 15/12/08 11:16:09 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/08 11:16:09 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/08 11:16:09 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/1/T/T.txt:0+292
[INFO] 15/12/08 11:16:09 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/08 11:16:09 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/08 11:16:09 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/08 11:16:09 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/08 11:16:09 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/08 11:16:09 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/08 11:16:09 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/08 11:16:09 tupleops.TupleOpFactory: [T:0:0:31, T:0:0:13, T:0:0:7, T:0:0:24]
[INFO] 15/12/08 11:16:09 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/08 11:16:09 tupleops.TupleOpFactory: [T:0:0:31,13,7,24]
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: 
[INFO] 15/12/08 11:16:09 mapred.MapTask: Starting flush of map output
[INFO] 15/12/08 11:16:09 mapred.MapTask: Spilling map output
[INFO] 15/12/08 11:16:09 mapred.MapTask: bufstart = 0; bufend = 1159; bufvoid = 104857600
[INFO] 15/12/08 11:16:09 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
[INFO] 15/12/08 11:16:09 mapred.MapTask: Finished spill 0
[INFO] 15/12/08 11:16:09 mapred.Task: Task:attempt_local1098271957_0003_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: map
[INFO] 15/12/08 11:16:09 mapred.Task: Task 'attempt_local1098271957_0003_m_000000_0' done.
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: Finishing task: attempt_local1098271957_0003_m_000000_0
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: Starting task: attempt_local1098271957_0003_r_000000_0
[INFO] 15/12/08 11:16:09 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/08 11:16:09 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/08 11:16:09 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22266922
[INFO] 15/12/08 11:16:09 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/08 11:16:09 reduce.EventFetcher: attempt_local1098271957_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/08 11:16:09 reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1098271957_0003_m_000000_0 decomp: 1361 len: 1365 to MEMORY
[INFO] 15/12/08 11:16:09 reduce.InMemoryMapOutput: Read 1361 bytes from map-output for attempt_local1098271957_0003_m_000000_0
[INFO] 15/12/08 11:16:09 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1361, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1361
[INFO] 15/12/08 11:16:09 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: 1 / 1 copied.
[INFO] 15/12/08 11:16:09 reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/08 11:16:09 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/08 11:16:09 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1357 bytes
[INFO] 15/12/08 11:16:09 reduce.MergeManagerImpl: Merged 1 segments, 1361 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/08 11:16:09 reduce.MergeManagerImpl: Merging 1 files, 1365 bytes from disk
[INFO] 15/12/08 11:16:09 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/08 11:16:09 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/08 11:16:09 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1357 bytes
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: 1 / 1 copied.
[INFO] 15/12/08 11:16:09 mapred.Task: Task:attempt_local1098271957_0003_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: 1 / 1 copied.
[INFO] 15/12/08 11:16:09 mapred.Task: Task attempt_local1098271957_0003_r_000000_0 is allowed to commit now
[INFO] 15/12/08 11:16:09 output.FileOutputCommitter: Saved output of task 'attempt_local1098271957_0003_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151208_111544/gumbohelpR6(x0,x1,x2,x3)gumbohelpR14(x0,x1,x2,x3)gumbohelpR2(x0,x1,x2,x3)gumbohelpR10(x0,x1,x2,x3)/_temporary/0/task_local1098271957_0003_r_000000
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/08 11:16:09 mapred.Task: Task 'attempt_local1098271957_0003_r_000000_0' done.
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: Finishing task: attempt_local1098271957_0003_r_000000_0
[INFO] 15/12/08 11:16:09 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/08 11:16:14 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/08 11:16:14 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR6(x0,x1,x2,x3)gumbohelpR14(x0,x1,x2,x3)gumbohelpR2(x0,x1,x2,x3)gumbohelpR10(x0,x1,x2,x3)/gumbohelpR10-r-* output/EXP_029/20151208_111544/OUT_0_gumbohelpR10
[INFO] 15/12/08 11:16:14 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR6(x0,x1,x2,x3)gumbohelpR14(x0,x1,x2,x3)gumbohelpR2(x0,x1,x2,x3)gumbohelpR10(x0,x1,x2,x3)/gumbohelpR2-r-* output/EXP_029/20151208_111544/OUT_13_gumbohelpR2
[INFO] 15/12/08 11:16:14 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR6(x0,x1,x2,x3)gumbohelpR14(x0,x1,x2,x3)gumbohelpR2(x0,x1,x2,x3)gumbohelpR10(x0,x1,x2,x3)/gumbohelpR14-r-* output/EXP_029/20151208_111544/OUT_4_gumbohelpR14
[INFO] 15/12/08 11:16:14 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR6(x0,x1,x2,x3)gumbohelpR14(x0,x1,x2,x3)gumbohelpR2(x0,x1,x2,x3)gumbohelpR10(x0,x1,x2,x3)/gumbohelpR6-r-* output/EXP_029/20151208_111544/OUT_6_gumbohelpR6
[INFO] 15/12/08 11:16:14 hadoop2.HadoopEngine2: Using 1-round evaluation for Calculation Unit Partitions: {
{id : 4 Depends on: None. - (gumbohelpR8(x,y,z,w) : R(x,y,z,w) & S(x))id : 9 Depends on: None. - (gumbohelpR4(x,y,z,w) : R(x,y,z,w) & S(z))id : 11 Depends on: None. - (gumbohelpR12(x,y,z,w) : R(x,y,z,w) & S(w))id : 14 Depends on: None. - (gumbohelpR0(x,y,z,w) : R(x,y,z,w) & S(y))}
{id : 1 Depends on: 14, - (gumbohelpR1(x,y,z,w) : gumbohelpR0(x,y,z,w) & U(y))id : 2 Depends on: 11, - (gumbohelpR13(x,y,z,w) : gumbohelpR12(x,y,z,w) & U(w))id : 7 Depends on: 4, - (gumbohelpR9(x,y,z,w) : gumbohelpR8(x,y,z,w) & U(x))id : 10 Depends on: 9, - (gumbohelpR5(x,y,z,w) : gumbohelpR4(x,y,z,w) & U(z))}
{id : 3 Depends on: 2, - (gumbohelpR14(x,y,z,w) : gumbohelpR13(x,y,z,w) & T(w))id : 6 Depends on: 1, - (gumbohelpR2(x,y,z,w) : gumbohelpR1(x,y,z,w) & T(y))id : 12 Depends on: 7, - (gumbohelpR10(x,y,z,w) : gumbohelpR9(x,y,z,w) & T(x))id : 16 Depends on: 10, - (gumbohelpR6(x,y,z,w) : gumbohelpR5(x,y,z,w) & T(z))}
{id : 0 Depends on: 12, - (gumbohelpR11(x,y,z,w) : gumbohelpR10(x,y,z,w) & V(x))id : 5 Depends on: 16, - (gumbohelpR7(x,y,z,w) : gumbohelpR6(x,y,z,w) & V(z))id : 13 Depends on: 6, - (gumbohelpR3(x,y,z,w) : gumbohelpR2(x,y,z,w) & V(y))id : 15 Depends on: 3, - (gumbohelpR15(x,y,z,w) : gumbohelpR14(x,y,z,w) & V(w))}
{id : 8 Depends on: 0,13,15,5, - (Out1(x) : R(x,y,z,w) & (((gumbohelpR3(x,y,z,w) | gumbohelpR7(x,y,z,w)) | gumbohelpR11(x,y,z,w)) | gumbohelpR15(x,y,z,w)))}
}
[INFO] 15/12/08 11:16:14 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_0_gumbohelpR10 to mapper
[INFO] 15/12/08 11:16:14 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_13_gumbohelpR2 to mapper
[INFO] 15/12/08 11:16:14 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/1/V to mapper
[INFO] 15/12/08 11:16:14 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_4_gumbohelpR14 to mapper
[INFO] 15/12/08 11:16:14 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_6_gumbohelpR6 to mapper
[INFO] 15/12/08 11:16:14 converter.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
[INFO] 15/12/08 11:16:14 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/08 11:16:19 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/12/08 11:16:19 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/08 11:16:19 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/12/08 11:16:19 mapreduce.JobSubmitter: number of splits:1
[INFO] 15/12/08 11:16:19 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/08 11:16:19 mapreduce.JobSubmitter: Submitting tokens for job: job_local691833700_0004
[WARN] 15/12/08 11:16:19 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny691833700/.staging/job_local691833700_0004/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/08 11:16:19 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny691833700/.staging/job_local691833700_0004/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/08 11:16:20 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local691833700_0004/job_local691833700_0004.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/08 11:16:20 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local691833700_0004/job_local691833700_0004.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/08 11:16:20 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: Starting task: attempt_local691833700_0004_m_000000_0
[INFO] 15/12/08 11:16:20 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/08 11:16:20 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/08 11:16:20 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/1/V/V.txt:0+291
[INFO] 15/12/08 11:16:20 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/08 11:16:20 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/08 11:16:20 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/08 11:16:20 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/08 11:16:20 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/08 11:16:20 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/08 11:16:20 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/08 11:16:20 tupleops.TupleOpFactory: [V:0:0:1, V:0:0:10, V:0:0:29, V:0:0:27]
[INFO] 15/12/08 11:16:20 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/08 11:16:20 tupleops.TupleOpFactory: [V:0:0:1,10,29,27]
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: 
[INFO] 15/12/08 11:16:20 mapred.MapTask: Starting flush of map output
[INFO] 15/12/08 11:16:20 mapred.MapTask: Spilling map output
[INFO] 15/12/08 11:16:20 mapred.MapTask: bufstart = 0; bufend = 1159; bufvoid = 104857600
[INFO] 15/12/08 11:16:20 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
[INFO] 15/12/08 11:16:20 mapred.MapTask: Finished spill 0
[INFO] 15/12/08 11:16:20 mapred.Task: Task:attempt_local691833700_0004_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: map
[INFO] 15/12/08 11:16:20 mapred.Task: Task 'attempt_local691833700_0004_m_000000_0' done.
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: Finishing task: attempt_local691833700_0004_m_000000_0
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: Starting task: attempt_local691833700_0004_r_000000_0
[INFO] 15/12/08 11:16:20 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/08 11:16:20 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/08 11:16:20 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4df7e542
[INFO] 15/12/08 11:16:20 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/08 11:16:20 reduce.EventFetcher: attempt_local691833700_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/08 11:16:20 reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local691833700_0004_m_000000_0 decomp: 1361 len: 1365 to MEMORY
[INFO] 15/12/08 11:16:20 reduce.InMemoryMapOutput: Read 1361 bytes from map-output for attempt_local691833700_0004_m_000000_0
[INFO] 15/12/08 11:16:20 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1361, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1361
[INFO] 15/12/08 11:16:20 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: 1 / 1 copied.
[INFO] 15/12/08 11:16:20 reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/08 11:16:20 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/08 11:16:20 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1357 bytes
[INFO] 15/12/08 11:16:20 reduce.MergeManagerImpl: Merged 1 segments, 1361 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/08 11:16:20 reduce.MergeManagerImpl: Merging 1 files, 1365 bytes from disk
[INFO] 15/12/08 11:16:20 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/08 11:16:20 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/08 11:16:20 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1357 bytes
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: 1 / 1 copied.
[INFO] 15/12/08 11:16:20 mapred.Task: Task:attempt_local691833700_0004_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: 1 / 1 copied.
[INFO] 15/12/08 11:16:20 mapred.Task: Task attempt_local691833700_0004_r_000000_0 is allowed to commit now
[INFO] 15/12/08 11:16:20 output.FileOutputCommitter: Saved output of task 'attempt_local691833700_0004_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151208_111544/gumbohelpR11(x0,x1,x2,x3)gumbohelpR7(x0,x1,x2,x3)gumbohelpR3(x0,x1,x2,x3)gumbohelpR15(x0,x1,x2,x3)/_temporary/0/task_local691833700_0004_r_000000
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/08 11:16:20 mapred.Task: Task 'attempt_local691833700_0004_r_000000_0' done.
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: Finishing task: attempt_local691833700_0004_r_000000_0
[INFO] 15/12/08 11:16:20 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/08 11:16:25 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/08 11:16:25 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR11(x0,x1,x2,x3)gumbohelpR7(x0,x1,x2,x3)gumbohelpR3(x0,x1,x2,x3)gumbohelpR15(x0,x1,x2,x3)/gumbohelpR11-r-* output/EXP_029/20151208_111544/OUT_1_gumbohelpR11
[INFO] 15/12/08 11:16:25 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR11(x0,x1,x2,x3)gumbohelpR7(x0,x1,x2,x3)gumbohelpR3(x0,x1,x2,x3)gumbohelpR15(x0,x1,x2,x3)/gumbohelpR3-r-* output/EXP_029/20151208_111544/OUT_14_gumbohelpR3
[INFO] 15/12/08 11:16:25 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR11(x0,x1,x2,x3)gumbohelpR7(x0,x1,x2,x3)gumbohelpR3(x0,x1,x2,x3)gumbohelpR15(x0,x1,x2,x3)/gumbohelpR15-r-* output/EXP_029/20151208_111544/OUT_7_gumbohelpR15
[INFO] 15/12/08 11:16:25 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/gumbohelpR11(x0,x1,x2,x3)gumbohelpR7(x0,x1,x2,x3)gumbohelpR3(x0,x1,x2,x3)gumbohelpR15(x0,x1,x2,x3)/gumbohelpR7-r-* output/EXP_029/20151208_111544/OUT_8_gumbohelpR7
[INFO] 15/12/08 11:16:25 hadoop2.HadoopEngine2: Using 1-round evaluation for Calculation Unit Partitions: {
{id : 4 Depends on: None. - (gumbohelpR8(x,y,z,w) : R(x,y,z,w) & S(x))id : 9 Depends on: None. - (gumbohelpR4(x,y,z,w) : R(x,y,z,w) & S(z))id : 11 Depends on: None. - (gumbohelpR12(x,y,z,w) : R(x,y,z,w) & S(w))id : 14 Depends on: None. - (gumbohelpR0(x,y,z,w) : R(x,y,z,w) & S(y))}
{id : 1 Depends on: 14, - (gumbohelpR1(x,y,z,w) : gumbohelpR0(x,y,z,w) & U(y))id : 2 Depends on: 11, - (gumbohelpR13(x,y,z,w) : gumbohelpR12(x,y,z,w) & U(w))id : 7 Depends on: 4, - (gumbohelpR9(x,y,z,w) : gumbohelpR8(x,y,z,w) & U(x))id : 10 Depends on: 9, - (gumbohelpR5(x,y,z,w) : gumbohelpR4(x,y,z,w) & U(z))}
{id : 3 Depends on: 2, - (gumbohelpR14(x,y,z,w) : gumbohelpR13(x,y,z,w) & T(w))id : 6 Depends on: 1, - (gumbohelpR2(x,y,z,w) : gumbohelpR1(x,y,z,w) & T(y))id : 12 Depends on: 7, - (gumbohelpR10(x,y,z,w) : gumbohelpR9(x,y,z,w) & T(x))id : 16 Depends on: 10, - (gumbohelpR6(x,y,z,w) : gumbohelpR5(x,y,z,w) & T(z))}
{id : 0 Depends on: 12, - (gumbohelpR11(x,y,z,w) : gumbohelpR10(x,y,z,w) & V(x))id : 5 Depends on: 16, - (gumbohelpR7(x,y,z,w) : gumbohelpR6(x,y,z,w) & V(z))id : 13 Depends on: 6, - (gumbohelpR3(x,y,z,w) : gumbohelpR2(x,y,z,w) & V(y))id : 15 Depends on: 3, - (gumbohelpR15(x,y,z,w) : gumbohelpR14(x,y,z,w) & V(w))}
{id : 8 Depends on: 0,13,15,5, - (Out1(x) : R(x,y,z,w) & (((gumbohelpR3(x,y,z,w) | gumbohelpR7(x,y,z,w)) | gumbohelpR11(x,y,z,w)) | gumbohelpR15(x,y,z,w)))}
}
[INFO] 15/12/08 11:16:25 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/1/R to mapper
[INFO] 15/12/08 11:16:25 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_1_gumbohelpR11 to mapper
[INFO] 15/12/08 11:16:25 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_14_gumbohelpR3 to mapper
[INFO] 15/12/08 11:16:25 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_7_gumbohelpR15 to mapper
[INFO] 15/12/08 11:16:25 converter.MultiRoundConverter: Adding path output/EXP_029/20151208_111544/OUT_8_gumbohelpR7 to mapper
[INFO] 15/12/08 11:16:25 converter.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
[INFO] 15/12/08 11:16:25 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/08 11:16:30 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/12/08 11:16:30 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/08 11:16:30 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/12/08 11:16:30 mapreduce.JobSubmitter: number of splits:1
[INFO] 15/12/08 11:16:30 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/08 11:16:30 mapreduce.JobSubmitter: Submitting tokens for job: job_local1409108429_0005
[WARN] 15/12/08 11:16:30 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1409108429/.staging/job_local1409108429_0005/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/08 11:16:30 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1409108429/.staging/job_local1409108429_0005/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/08 11:16:30 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1409108429_0005/job_local1409108429_0005.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/08 11:16:30 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1409108429_0005/job_local1409108429_0005.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/08 11:16:30 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: Starting task: attempt_local1409108429_0005_m_000000_0
[INFO] 15/12/08 11:16:30 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/08 11:16:30 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/08 11:16:30 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/1/R/R.txt:0+1166
[INFO] 15/12/08 11:16:30 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/08 11:16:30 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/08 11:16:30 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/08 11:16:30 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/08 11:16:30 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/08 11:16:30 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/08 11:16:30 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/08 11:16:30 tupleops.TupleOpFactory: [R:0,1,2,3:0,1,2,3]
[INFO] 15/12/08 11:16:30 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/08 11:16:30 tupleops.TupleOpFactory: [R:0,1,2,3:0,1,2,3]
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: 
[INFO] 15/12/08 11:16:30 mapred.MapTask: Starting flush of map output
[INFO] 15/12/08 11:16:30 mapred.MapTask: Spilling map output
[INFO] 15/12/08 11:16:30 mapred.MapTask: bufstart = 0; bufend = 2432; bufvoid = 104857600
[INFO] 15/12/08 11:16:30 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214000(104856000); length = 397/6553600
[INFO] 15/12/08 11:16:30 mapred.MapTask: Finished spill 0
[INFO] 15/12/08 11:16:30 mapred.Task: Task:attempt_local1409108429_0005_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: map
[INFO] 15/12/08 11:16:30 mapred.Task: Task 'attempt_local1409108429_0005_m_000000_0' done.
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: Finishing task: attempt_local1409108429_0005_m_000000_0
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: Starting task: attempt_local1409108429_0005_r_000000_0
[INFO] 15/12/08 11:16:30 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/08 11:16:30 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/08 11:16:30 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e3e9259
[INFO] 15/12/08 11:16:30 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/08 11:16:30 reduce.EventFetcher: attempt_local1409108429_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/08 11:16:30 reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1409108429_0005_m_000000_0 decomp: 2634 len: 2638 to MEMORY
[INFO] 15/12/08 11:16:30 reduce.InMemoryMapOutput: Read 2634 bytes from map-output for attempt_local1409108429_0005_m_000000_0
[INFO] 15/12/08 11:16:30 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2634, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2634
[INFO] 15/12/08 11:16:30 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: 1 / 1 copied.
[INFO] 15/12/08 11:16:30 reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/08 11:16:30 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/08 11:16:30 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 2622 bytes
[INFO] 15/12/08 11:16:30 reduce.MergeManagerImpl: Merged 1 segments, 2634 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/08 11:16:30 reduce.MergeManagerImpl: Merging 1 files, 2638 bytes from disk
[INFO] 15/12/08 11:16:30 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/08 11:16:30 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/08 11:16:30 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 2622 bytes
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: 1 / 1 copied.
[INFO] 15/12/08 11:16:30 mapred.Task: Task:attempt_local1409108429_0005_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: 1 / 1 copied.
[INFO] 15/12/08 11:16:30 mapred.Task: Task attempt_local1409108429_0005_r_000000_0 is allowed to commit now
[INFO] 15/12/08 11:16:30 output.FileOutputCommitter: Saved output of task 'attempt_local1409108429_0005_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151208_111544/Out1(x0)/_temporary/0/task_local1409108429_0005_r_000000
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/08 11:16:30 mapred.Task: Task 'attempt_local1409108429_0005_r_000000_0' done.
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: Finishing task: attempt_local1409108429_0005_r_000000_0
[INFO] 15/12/08 11:16:30 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/08 11:16:35 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/08 11:16:35 converter.MultiRoundConverter: Moving files: output/EXP_029/20151208_111544/Out1(x0)/Out1-r-* output/EXP_029/20151208_111544/OUT_16_Out1
[INFO] 15/12/08 11:16:35 hadoop2.HadoopEngine2: Running time: 50715ms
[INFO] 15/12/08 11:16:35 hadoop2.HadoopEngine2: SUCCESS: all jobs (5) completed!
[INFO] 15/12/08 11:16:35 hadoop2.HadoopEngine2: Stopping job control
