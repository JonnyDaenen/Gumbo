gumbo.engine.guardAddressOptimizationOn=true
gumbo.engine.proofsymbol=#
gumbo.engine.mapOutputGroupingPolicy=ALLGROUP
gumbo.engine.simulator.classname=gumbo.engine.hadoop2.estimation.MapSimulator
gumbo.engine.guardedCombinerOptimizationOn=false
gumbo.engine.assertConstantOptimizationOn=true
gumbo.compiler.partitioner=gumbo.compiler.partitioner.HeightPartitioner
gumbo.engine.round1FiniteMemoryOptimizationOn=false
gumbo.engine.val.projection.merge=true
gumbo.engine.hadoop.reducersize_mb=1024
gumbo.engine.reduceOutputGroupingOptimizationOn=true
gumbo.engine.mapOutputGroupingOptimizationOn=true
gumbo.engine.eval.output.merge=false
gumbo.compiler.unnest=false
gumbo.engine.grouper.beststopindicator=0
gumbo.engine.requestAtomIdOptimizationOn=true
gumbo.engine.guardKeepAliveOptimizationOn=true
[INFO] 15/12/06 20:22:52 gumbo.Gumbo: Input: 
R(x0,x1,x2,x3);input/experiments/EXP_029/3/R;csv;'S(x0);input/experiments/EXP_029/3/S;csv;'T(x0,x1);input/experiments/EXP_029/3/T;csv;'U(x0);input/experiments/EXP_029/3/U;csv;'V(x0);input/experiments/EXP_029/3/V;csv;
Output: output/EXP_029
Scratch: scratch/EXP_029
Queries: 
[(Out2(x,y,z,w) : R(x,y,y,w) & T(x,x)), (Out1(x,y,z,w) : R(x,y,z,w) & (S(x) & (T(x,y) & S(y))))]

[INFO] 15/12/06 20:22:52 compiler.GFCompiler: Adding suffix to scratch and output paths: /20151206_202252
[INFO] 15/12/06 20:22:52 compiler.GFCompiler: Decomposing GFEs into basic GFEs (BGFEs)...
[INFO] 15/12/06 20:22:52 compiler.GFCompiler: Number of BGFEs: 2
[INFO] 15/12/06 20:22:52 compiler.GFCompiler: Converting BGFEs into CalculationUnits (CUs)...
[INFO] 15/12/06 20:22:52 compiler.GFCompiler: Number of CUs: 2
[INFO] 15/12/06 20:22:52 compiler.GFCompiler: Linking Calculation Units (CUs)...
[INFO] 15/12/06 20:22:52 compiler.GFCompiler: Creating initial file mapping...
[INFO] 15/12/06 20:22:52 compiler.GFCompiler: file mapping:
Out root: output/EXP_029/20151206_202252
Scratch root: scratch/EXP_029/20151206_202252
Temp root: scratch/EXP_029/20151206_202252/tmp
R(x0,x1,x2,x3) <- [input/experiments/EXP_029/3/R]
S(x0) <- [input/experiments/EXP_029/3/S]
T(x0,x1) <- [input/experiments/EXP_029/3/T]
U(x0) <- [input/experiments/EXP_029/3/U]
V(x0) <- [input/experiments/EXP_029/3/V]
Out2(x0,x1,x2,x3) -> [output/EXP_029/20151206_202252/OUT_0_Out2]
Out1(x0,x1,x2,x3) -> [output/EXP_029/20151206_202252/OUT_1_Out1]
Temp dirs: 

[INFO] 15/12/06 20:22:52 compiler.GFCompiler: Partitioning...
[INFO] 15/12/06 20:22:52 compiler.GFCompiler: Number of partitions: 1

Query:
query4.gumbo

Partitions:
-----------
Calculation Unit Partitions: {
{id : 0 Depends on: None. - (Out2(x,y,z,w) : R(x,y,y,w) & T(x,x))id : 1 Depends on: None. - (Out1(x,y,z,w) : R(x,y,z,w) & (S(x) & (T(x,y) & S(y))))}
}
Folders:
-------
Out root: output/EXP_029/20151206_202252
Scratch root: scratch/EXP_029/20151206_202252
Temp root: scratch/EXP_029/20151206_202252/tmp
R(x0,x1,x2,x3) <- [input/experiments/EXP_029/3/R]
S(x0) <- [input/experiments/EXP_029/3/S]
T(x0,x1) <- [input/experiments/EXP_029/3/T]
U(x0) <- [input/experiments/EXP_029/3/U]
V(x0) <- [input/experiments/EXP_029/3/V]
Out2(x0,x1,x2,x3) -> [output/EXP_029/20151206_202252/OUT_0_Out2]
Out1(x0,x1,x2,x3) -> [output/EXP_029/20151206_202252/OUT_1_Out1]
Temp dirs: 

[INFO] 15/12/06 20:22:52 hadoop2.HadoopEngine2: Creating Job Control for: query4.gumbo
[INFO] 15/12/06 20:22:52 hadoop2.HadoopEngine2: Starting Job-control thread: Gumbo-Workflow-Thread_query4.gumbo
[WARN] 15/12/06 20:22:52 util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 15/12/06 20:22:52 hadoop2.HadoopEngine2: Using 2-round evaluation for Calculation Unit Partitions: {
{id : 0 Depends on: None. - (Out2(x,y,z,w) : R(x,y,y,w) & T(x,x))id : 1 Depends on: None. - (Out1(x,y,z,w) : R(x,y,z,w) & (S(x) & (T(x,y) & S(y))))}
}
Adding output paths
[INFO] 15/12/06 20:22:52 sample.RelationSampler: Fetching samples for relation R(x0,x1,x2,x3)
[INFO] 15/12/06 20:22:52 sample.RelationSampler: Fetching samples for relation S(x0)
[INFO] 15/12/06 20:22:52 sample.RelationSampler: Fetching samples for relation T(x0,x1)
[INFO] 15/12/06 20:22:52 sample.RelationSampler: Fetching samples for relation U(x0)
[INFO] 15/12/06 20:22:52 sample.RelationSampler: Fetching samples for relation V(x0)
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Parsing samples for relation R(x0,x1,x2,x3)
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Small tuples: 476
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Big tuples: 1637
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Parsing samples for relation S(x0)
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Parsing samples for relation T(x0,x1)
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Parsing samples for relation U(x0)
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Parsing samples for relation V(x0)
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/12/06 20:22:53 reporter.RelationTupleSampleContainer: Big tuples: 0
Adding output paths
Adding output paths
[INFO] 15/12/06 20:22:53 grouper.GrouperFactory: Creating a grouper with policy ALLGROUP
[INFO] 15/12/06 20:22:53 grouper.Grouper: Decomposition complete: 	R(x,y,y,w) |X T(x,x)
	R(x,y,z,w) |X T(x,y)
	R(x,y,z,w) |X S(x)
	R(x,y,z,w) |X S(y)
	Guard In Bytes0
	Guarded In Bytes0
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:0.0

[INFO] 15/12/06 20:22:53 grouper.Grouper: Grouping complete: 1 group(s)
[INFO] 15/12/06 20:22:53 grouper.Grouper: Grouping: [	R(x,y,y,w) |X T(x,x)
	R(x,y,z,w) |X T(x,y)
	R(x,y,z,w) |X S(x)
	R(x,y,z,w) |X S(y)
	Guard In Bytes0
	Guarded In Bytes0
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:0.0
]
[INFO] 15/12/06 20:22:53 hadoop2.HadoopEngine2: Starting round 1 (VAL)
[INFO] 15/12/06 20:22:53 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/3/T to mapper
[INFO] 15/12/06 20:22:53 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/3/R to mapper
[INFO] 15/12/06 20:22:53 converter.MultiRoundConverter: Adding path input/experiments/EXP_029/3/S to mapper
Adding output paths
[INFO] 15/12/06 20:22:53 converter.MultiRoundConverter: Missing size estimates, sampling data.
[INFO] 15/12/06 20:22:53 estimation.MapSimulator: Simulating relation T(x0,x1)
Projections before merge:
[T:0,0:0,0:0, T:0,1:0,1:4]
Projections after merge:
[T:0,0:0,0:0, T:0,1:0,1:4]
Projections before merge:
[T:0,0:0,0:0, T:0,1:0,1:4]
Projections after merge:
[T:0,0:0,0:0, T:0,1:0,1:4]
[INFO] 15/12/06 20:22:53 estimation.MapSimulator: Map Input bytes:2
[INFO] 15/12/06 20:22:53 estimation.MapSimulator: Est. Map Output bytes: 0
[INFO] 15/12/06 20:22:53 estimation.MapSimulator: Simulating relation R(x0,x1,x2,x3)
Projections before merge:
[R:1:0,1,2,3:3, R:0:0,1,2,3:2, R:0,1:0,1,2,3:4, R:0,0:0,1,1,3:0]
Projections after merge:
[R:1:0,1,2,3:3, R:0:0,1,2,3:2, R:0,1:0,1,2,3:4, R:0,0:0,1,1,3:0]
Projections before merge:
[R:1:0,1,2,3:3, R:0,0:0,1,1,3:0, R:0:0,1,2,3:2, R:0,1:0,1,2,3:4]
Projections after merge:
[R:1:0,1,2,3:3, R:0,0:0,1,1,3:0, R:0:0,1,2,3:2, R:0,1:0,1,2,3:4]
[INFO] 15/12/06 20:22:53 estimation.MapSimulator: Map Input bytes:4000
[INFO] 15/12/06 20:22:53 estimation.MapSimulator: Est. Map Output bytes: 18507
[INFO] 15/12/06 20:22:53 estimation.MapSimulator: Simulating relation S(x0)
Projections before merge:
[S:0:0:2, S:0:0:3]
Projections after merge:
[S:0:0:2,3]
Projections before merge:
[S:0:0:2, S:0:0:3]
Projections after merge:
[S:0:0:2,3]
[INFO] 15/12/06 20:22:53 estimation.MapSimulator: Map Input bytes:2
[INFO] 15/12/06 20:22:53 estimation.MapSimulator: Est. Map Output bytes: 0
[INFO] 15/12/06 20:22:53 converter.MultiRoundConverter: Map output est.: 18507, setting VAL Reduce tasks to 1
[INFO] 15/12/06 20:22:53 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/06 20:22:57 Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO] 15/12/06 20:22:57 jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN] 15/12/06 20:22:57 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/06 20:22:57 input.FileInputFormat: Total input paths to process : 3
[INFO] 15/12/06 20:22:57 mapreduce.JobSubmitter: number of splits:3
[INFO] 15/12/06 20:22:57 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/06 20:22:57 mapreduce.JobSubmitter: Submitting tokens for job: job_local8406245_0001
[WARN] 15/12/06 20:22:57 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny8406245/.staging/job_local8406245_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/06 20:22:57 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny8406245/.staging/job_local8406245_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/06 20:22:57 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local8406245_0001/job_local8406245_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/06 20:22:57 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local8406245_0001/job_local8406245_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/06 20:22:57 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/06 20:22:57 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/06 20:22:57 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: Starting task: attempt_local8406245_0001_m_000000_0
[INFO] 15/12/06 20:22:58 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/06 20:22:58 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/06 20:22:58 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/3/R/R.txt:0+4000
[INFO] 15/12/06 20:22:58 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/06 20:22:58 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/06 20:22:58 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/06 20:22:58 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/06 20:22:58 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/06 20:22:58 mapred.MapTask: kvstart = 26214396; length = 6553600
Projections before merge:
[R:1:0,1,2,3:3, R:0,0:0,1,1,3:0, R:0:0,1,2,3:2, R:0,1:0,1,2,3:4]
Projections after merge:
[R:1:0,1,2,3:3, R:0,0:0,1,1,3:0, R:0:0,1,2,3:2, R:0,1:0,1,2,3:4]
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: 
[INFO] 15/12/06 20:22:58 mapred.MapTask: Starting flush of map output
[INFO] 15/12/06 20:22:58 mapred.MapTask: Spilling map output
[INFO] 15/12/06 20:22:58 mapred.MapTask: bufstart = 0; bufend = 11604; bufvoid = 104857600
[INFO] 15/12/06 20:22:58 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26210000(104840000); length = 4397/6553600
[INFO] 15/12/06 20:22:58 mapred.MapTask: Finished spill 0
[INFO] 15/12/06 20:22:58 mapred.Task: Task:attempt_local8406245_0001_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: map
[INFO] 15/12/06 20:22:58 mapred.Task: Task 'attempt_local8406245_0001_m_000000_0' done.
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: Finishing task: attempt_local8406245_0001_m_000000_0
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: Starting task: attempt_local8406245_0001_m_000001_0
[INFO] 15/12/06 20:22:58 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/06 20:22:58 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/06 20:22:58 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/3/T/T.txt:0+2
[INFO] 15/12/06 20:22:58 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/06 20:22:58 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/06 20:22:58 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/06 20:22:58 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/06 20:22:58 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/06 20:22:58 mapred.MapTask: kvstart = 26214396; length = 6553600
Projections before merge:
[T:0,0:0,0:0, T:0,1:0,1:4]
Projections after merge:
[T:0,0:0,0:0, T:0,1:0,1:4]
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: 
[INFO] 15/12/06 20:22:58 mapred.MapTask: Starting flush of map output
[INFO] 15/12/06 20:22:58 mapred.Task: Task:attempt_local8406245_0001_m_000001_0 is done. And is in the process of committing
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: map
[INFO] 15/12/06 20:22:58 mapred.Task: Task 'attempt_local8406245_0001_m_000001_0' done.
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: Finishing task: attempt_local8406245_0001_m_000001_0
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: Starting task: attempt_local8406245_0001_m_000002_0
[INFO] 15/12/06 20:22:58 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/06 20:22:58 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/06 20:22:58 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/3/S/S.txt:0+2
[INFO] 15/12/06 20:22:58 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/06 20:22:58 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/06 20:22:58 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/06 20:22:58 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/06 20:22:58 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/06 20:22:58 mapred.MapTask: kvstart = 26214396; length = 6553600
Projections before merge:
[S:0:0:3, S:0:0:2]
Projections after merge:
[S:0:0:3,2]
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: 
[INFO] 15/12/06 20:22:58 mapred.MapTask: Starting flush of map output
[INFO] 15/12/06 20:22:58 mapred.MapTask: Spilling map output
[INFO] 15/12/06 20:22:58 mapred.MapTask: bufstart = 0; bufend = 8; bufvoid = 104857600
[INFO] 15/12/06 20:22:58 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/12/06 20:22:58 mapred.MapTask: Finished spill 0
[INFO] 15/12/06 20:22:58 mapred.Task: Task:attempt_local8406245_0001_m_000002_0 is done. And is in the process of committing
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: map
[INFO] 15/12/06 20:22:58 mapred.Task: Task 'attempt_local8406245_0001_m_000002_0' done.
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: Finishing task: attempt_local8406245_0001_m_000002_0
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: Starting task: attempt_local8406245_0001_r_000000_0
[INFO] 15/12/06 20:22:58 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/06 20:22:58 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/06 20:22:58 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@67144e50
[INFO] 15/12/06 20:22:58 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/06 20:22:58 reduce.EventFetcher: attempt_local8406245_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/06 20:22:58 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local8406245_0001_m_000002_0 decomp: 12 len: 16 to MEMORY
[INFO] 15/12/06 20:22:58 reduce.InMemoryMapOutput: Read 12 bytes from map-output for attempt_local8406245_0001_m_000002_0
[INFO] 15/12/06 20:22:58 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12
[INFO] 15/12/06 20:22:58 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local8406245_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/06 20:22:58 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local8406245_0001_m_000001_0
[INFO] 15/12/06 20:22:58 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 12, usedMemory ->14
[INFO] 15/12/06 20:22:58 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local8406245_0001_m_000000_0 decomp: 13806 len: 13810 to MEMORY
[INFO] 15/12/06 20:22:58 reduce.InMemoryMapOutput: Read 13806 bytes from map-output for attempt_local8406245_0001_m_000000_0
[INFO] 15/12/06 20:22:58 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13806, inMemoryMapOutputs.size() -> 3, commitMemory -> 14, usedMemory ->13820
[INFO] 15/12/06 20:22:58 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/06 20:22:58 reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/06 20:22:58 mapred.Merger: Merging 3 sorted segments
[INFO] 15/12/06 20:22:58 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 13810 bytes
[INFO] 15/12/06 20:22:58 reduce.MergeManagerImpl: Merged 3 segments, 13820 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/06 20:22:58 reduce.MergeManagerImpl: Merging 1 files, 13820 bytes from disk
[INFO] 15/12/06 20:22:58 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/06 20:22:58 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/06 20:22:58 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 13812 bytes
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/06 20:22:58 Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[INFO] 15/12/06 20:22:58 mapred.Task: Task:attempt_local8406245_0001_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/12/06 20:22:58 mapred.Task: Task attempt_local8406245_0001_r_000000_0 is allowed to commit now
[INFO] 15/12/06 20:22:58 output.FileOutputCommitter: Saved output of task 'attempt_local8406245_0001_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_029/20151206_202252/tmp/TMP_2_R4T2-R4T2-R4S1-R4S1-/_temporary/0/task_local8406245_0001_r_000000
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/06 20:22:58 mapred.Task: Task 'attempt_local8406245_0001_r_000000_0' done.
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: Finishing task: attempt_local8406245_0001_r_000000_0
[INFO] 15/12/06 20:22:58 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/06 20:23:03 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/06 20:23:03 hadoop2.HadoopEngine2: Starting round 2 (EVAL)
[INFO] 15/12/06 20:23:03 converter.MultiRoundConverter: Adding guard path:input/experiments/EXP_029/3/R
[INFO] 15/12/06 20:23:03 converter.MultiRoundConverter: Adding intermediate path:scratch/EXP_029/20151206_202252/tmp/TMP_2_R4T2-R4T2-R4S1-R4S1-
[INFO] 15/12/06 20:23:03 converter.MultiRoundConverter: Adding guard path:input/experiments/EXP_029/3/R
[INFO] 15/12/06 20:23:03 converter.MultiRoundConverter: Adding intermediate path:scratch/EXP_029/20151206_202252/tmp/TMP_2_R4T2-R4T2-R4S1-R4S1-
[INFO] 15/12/06 20:23:03 converter.MultiRoundConverter: Adding intermediate path:scratch/EXP_029/20151206_202252/tmp/TMP_2_R4T2-R4T2-R4S1-R4S1-
[INFO] 15/12/06 20:23:03 converter.MultiRoundConverter: Adding intermediate path:scratch/EXP_029/20151206_202252/tmp/TMP_2_R4T2-R4T2-R4S1-R4S1-
[INFO] 15/12/06 20:23:03 converter.MultiRoundConverter: Setting EVAL Reduce tasks to 1
Adding output paths
[INFO] 15/12/06 20:23:03 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/06 20:23:07 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/12/06 20:23:07 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/06 20:23:08 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/12/06 20:23:08 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/12/06 20:23:08 mapreduce.JobSubmitter: number of splits:2
[INFO] 15/12/06 20:23:08 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/06 20:23:08 mapreduce.JobSubmitter: Submitting tokens for job: job_local1851731745_0002
[WARN] 15/12/06 20:23:08 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1851731745/.staging/job_local1851731745_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/06 20:23:08 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1851731745/.staging/job_local1851731745_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/06 20:23:08 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1851731745_0002/job_local1851731745_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/06 20:23:08 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1851731745_0002/job_local1851731745_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/06 20:23:08 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: Starting task: attempt_local1851731745_0002_m_000000_0
[INFO] 15/12/06 20:23:08 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/06 20:23:08 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/06 20:23:08 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/3/R/R.txt:0+4000
[INFO] 15/12/06 20:23:08 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/06 20:23:08 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/06 20:23:08 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/06 20:23:08 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/06 20:23:08 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/06 20:23:08 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: 
[INFO] 15/12/06 20:23:08 mapred.MapTask: Starting flush of map output
[INFO] 15/12/06 20:23:08 mapred.MapTask: Spilling map output
[INFO] 15/12/06 20:23:08 mapred.MapTask: bufstart = 0; bufend = 6952; bufvoid = 104857600
[INFO] 15/12/06 20:23:08 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26212400(104849600); length = 1997/6553600
[INFO] 15/12/06 20:23:08 mapred.MapTask: Finished spill 0
[INFO] 15/12/06 20:23:08 mapred.Task: Task:attempt_local1851731745_0002_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: map
[INFO] 15/12/06 20:23:08 mapred.Task: Task 'attempt_local1851731745_0002_m_000000_0' done.
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: Finishing task: attempt_local1851731745_0002_m_000000_0
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: Starting task: attempt_local1851731745_0002_m_000001_0
[INFO] 15/12/06 20:23:08 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/06 20:23:08 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/06 20:23:08 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_029/20151206_202252/tmp/TMP_2_R4T2-R4T2-R4S1-R4S1-/part-r-00000:0+124
[INFO] 15/12/06 20:23:08 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/06 20:23:08 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/06 20:23:08 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/06 20:23:08 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/06 20:23:08 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/06 20:23:08 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: 
[INFO] 15/12/06 20:23:08 mapred.MapTask: Starting flush of map output
[INFO] 15/12/06 20:23:08 mapred.Task: Task:attempt_local1851731745_0002_m_000001_0 is done. And is in the process of committing
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: map
[INFO] 15/12/06 20:23:08 mapred.Task: Task 'attempt_local1851731745_0002_m_000001_0' done.
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: Finishing task: attempt_local1851731745_0002_m_000001_0
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: Starting task: attempt_local1851731745_0002_r_000000_0
[INFO] 15/12/06 20:23:08 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/06 20:23:08 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/06 20:23:08 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5fa44f2f
[INFO] 15/12/06 20:23:08 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/06 20:23:08 reduce.EventFetcher: attempt_local1851731745_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/06 20:23:08 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1851731745_0002_m_000001_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/12/06 20:23:08 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1851731745_0002_m_000001_0
[INFO] 15/12/06 20:23:08 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
[INFO] 15/12/06 20:23:08 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1851731745_0002_m_000000_0 decomp: 7954 len: 7958 to MEMORY
[INFO] 15/12/06 20:23:08 reduce.InMemoryMapOutput: Read 7954 bytes from map-output for attempt_local1851731745_0002_m_000000_0
[INFO] 15/12/06 20:23:08 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 7954, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->7956
[INFO] 15/12/06 20:23:08 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/06 20:23:08 reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/06 20:23:08 mapred.Merger: Merging 2 sorted segments
[INFO] 15/12/06 20:23:08 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7949 bytes
[INFO] 15/12/06 20:23:08 reduce.MergeManagerImpl: Merged 2 segments, 7956 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/06 20:23:08 reduce.MergeManagerImpl: Merging 1 files, 7958 bytes from disk
[INFO] 15/12/06 20:23:08 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/06 20:23:08 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/06 20:23:08 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 7949 bytes
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/06 20:23:08 mapred.Task: Task:attempt_local1851731745_0002_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/06 20:23:08 mapred.Task: Task attempt_local1851731745_0002_r_000000_0 is allowed to commit now
[INFO] 15/12/06 20:23:08 output.FileOutputCommitter: Saved output of task 'attempt_local1851731745_0002_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_029/20151206_202252/Out2(x0,x1,x2,x3)Out1(x0,x1,x2,x3)/_temporary/0/task_local1851731745_0002_r_000000
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/06 20:23:08 mapred.Task: Task 'attempt_local1851731745_0002_r_000000_0' done.
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: Finishing task: attempt_local1851731745_0002_r_000000_0
[INFO] 15/12/06 20:23:08 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/06 20:23:13 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/06 20:23:13 hadoop2.HadoopEngine2: Running time: 20595ms
[INFO] 15/12/06 20:23:13 hadoop2.HadoopEngine2: SUCCESS: all jobs (2) completed!
[INFO] 15/12/06 20:23:13 hadoop2.HadoopEngine2: Stopping job control
