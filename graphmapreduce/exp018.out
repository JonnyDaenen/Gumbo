gumbo.engine.guardAddressOptimizationOn=true
gumbo.engine.proofsymbol=#
gumbo.engine.mapOutputGroupingPolicy=BESTCOSTGROUP_GUMBO
gumbo.engine.guardedCombinerOptimizationOn=false
gumbo.engine.assertConstantOptimizationOn=true
gumbo.compiler.partitioner=gumbo.compiler.partitioner.GreedyPartitioner
gumbo.engine.round1FiniteMemoryOptimizationOn=false
gumbo.engine.hadoop.reducersize_mb=1024
gumbo.engine.reduceOutputGroupingOptimizationOn=true
gumbo.engine.mapOutputGroupingOptimizationOn=true
gumbo.engine.grouper.beststopindicator=0
gumbo.engine.requestAtomIdOptimizationOn=true
gumbo.engine.guardKeepAliveOptimizationOn=true
[INFO] 15/11/14 15:50:58 gumbo.Gumbo: Input: 
R(x0,x1,x2);input/experiments/EXP_028/0/R;csv;'S(x0);input/experiments/EXP_028/0/S;csv;'T(x0);input/experiments/EXP_028/0/T;csv;'U(x0);input/experiments/EXP_028/0/U;csv;'G(x0,x1,x2);input/experiments/EXP_028/0/G;csv;'H(x0,x1,x2);input/experiments/EXP_028/0/H;csv;
Output: output/EXP_028
Scratch: scratch/EXP_028
Queries: 
[(O5(x,y,z) : O3(x,y,z) & S(z)), (O2(x,y,z) : G(x,y,z) & T(x)), (O1(x,y,z) : R(x,y,z) & S(x)), (O4(x,y,z) : O1(x,y,z) & T(z)), (O3(x,y,z) : H(x,y,z) & U(x))]

[INFO] 15/11/14 15:50:58 compiler.GFCompiler: Adding suffix to scratch and output paths: /20151114_155058
[INFO] 15/11/14 15:50:58 compiler.GFCompiler: Decomposing GFEs into basic GFEs (BGFEs)...
[INFO] 15/11/14 15:50:58 compiler.GFCompiler: Number of BGFEs: 5
[INFO] 15/11/14 15:50:58 compiler.GFCompiler: Converting BGFEs into CalculationUnits (CUs)...
[INFO] 15/11/14 15:50:58 compiler.GFCompiler: Number of CUs: 5
[INFO] 15/11/14 15:50:58 compiler.GFCompiler: Linking Calculation Units (CUs)...
[INFO] 15/11/14 15:50:58 compiler.GFCompiler: Creating initial file mapping...
[INFO] 15/11/14 15:50:58 compiler.GFCompiler: file mapping:
Out root: output/EXP_028/20151114_155058
Scratch root: scratch/EXP_028/20151114_155058
Temp root: scratch/EXP_028/20151114_155058/tmp
R(x0,x1,x2) <- [input/experiments/EXP_028/0/R]
S(x0) <- [input/experiments/EXP_028/0/S]
T(x0) <- [input/experiments/EXP_028/0/T]
U(x0) <- [input/experiments/EXP_028/0/U]
G(x0,x1,x2) <- [input/experiments/EXP_028/0/G]
H(x0,x1,x2) <- [input/experiments/EXP_028/0/H]
O1(x0,x1,x2) -> [output/EXP_028/20151114_155058/OUT_0_O1]
O2(x0,x1,x2) -> [output/EXP_028/20151114_155058/OUT_2_O2]
O3(x0,x1,x2) -> [output/EXP_028/20151114_155058/OUT_1_O3]
O4(x0,x1,x2) -> [output/EXP_028/20151114_155058/OUT_3_O4]
O5(x0,x1,x2) -> [output/EXP_028/20151114_155058/OUT_4_O5]
Temp dirs: 

[INFO] 15/11/14 15:50:58 compiler.GFCompiler: Partitioning...
[INFO] 15/11/14 15:50:58 compiler.GFCompiler: Number of partitions: 3

Query:
query1.gumbo

Partitions:
-----------
Calculation Unit Partitions: {
{id : 4 Depends on: None. - (O3(x,y,z) : H(x,y,z) & U(x))}
{id : 2 Depends on: None. - (O1(x,y,z) : R(x,y,z) & S(x))id : 3 Depends on: 4, - (O5(x,y,z) : O3(x,y,z) & S(z))}
{id : 0 Depends on: None. - (O2(x,y,z) : G(x,y,z) & T(x))id : 1 Depends on: 2, - (O4(x,y,z) : O1(x,y,z) & T(z))}
}
Folders:
-------
Out root: output/EXP_028/20151114_155058
Scratch root: scratch/EXP_028/20151114_155058
Temp root: scratch/EXP_028/20151114_155058/tmp
R(x0,x1,x2) <- [input/experiments/EXP_028/0/R]
S(x0) <- [input/experiments/EXP_028/0/S]
T(x0) <- [input/experiments/EXP_028/0/T]
U(x0) <- [input/experiments/EXP_028/0/U]
G(x0,x1,x2) <- [input/experiments/EXP_028/0/G]
H(x0,x1,x2) <- [input/experiments/EXP_028/0/H]
O1(x0,x1,x2) -> [output/EXP_028/20151114_155058/OUT_0_O1]
O2(x0,x1,x2) -> [output/EXP_028/20151114_155058/OUT_2_O2]
O3(x0,x1,x2) -> [output/EXP_028/20151114_155058/OUT_1_O3]
O4(x0,x1,x2) -> [output/EXP_028/20151114_155058/OUT_3_O4]
O5(x0,x1,x2) -> [output/EXP_028/20151114_155058/OUT_4_O5]
Temp dirs: 

[WARN] 15/11/14 15:50:58 util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 15/11/14 15:50:58 hadoop.HadoopEngine: Creating Job Control for: query1.gumbo
[INFO] 15/11/14 15:50:58 hadoop.HadoopEngine: Starting Job-control thread: Gumbo-Workflow-Thread_query1.gumbo
[INFO] 15/11/14 15:50:58 hadoop.HadoopEngine: Processing partition queue.
[INFO] 15/11/14 15:50:58 utils.PartitionQueue: Calculation group {
id : 4 Depends on: None. - (O3(x,y,z) : H(x,y,z) & U(x))
} is ready to be scheduled.
Adding output paths
[INFO] 15/11/14 15:50:58 sample.RelationSampler: Fetching samples for relation R(x0,x1,x2)
[INFO] 15/11/14 15:50:58 sample.RelationSampler: Fetching samples for relation S(x0)
[INFO] 15/11/14 15:50:58 sample.RelationSampler: Fetching samples for relation T(x0)
[INFO] 15/11/14 15:50:58 sample.RelationSampler: Fetching samples for relation U(x0)
[INFO] 15/11/14 15:50:58 sample.RelationSampler: Fetching samples for relation G(x0,x1,x2)
[INFO] 15/11/14 15:50:58 sample.RelationSampler: Fetching samples for relation H(x0,x1,x2)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Parsing samples for relation R(x0,x1,x2)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Parsing samples for relation S(x0)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Small tuples: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Big tuples: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Parsing samples for relation T(x0)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Small tuples: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Big tuples: 5
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Parsing samples for relation U(x0)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Parsing samples for relation G(x0,x1,x2)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Parsing samples for relation H(x0,x1,x2)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:50:59 grouper.GrouperFactory: Creating a grouper with policy BESTCOSTGROUP_GUMBO
[WARN] 15/11/14 15:50:59 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
Adding output paths
[INFO] 15/11/14 15:50:59 grouper.Grouper: Decomposition complete: 	H(x,y,z) |X U(x)
	Guard In Bytes0
	Guarded In Bytes0
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:0.0

[INFO] 15/11/14 15:50:59 sample.RelationSampler: Fetching samples for relation R(x0,x1,x2)
[INFO] 15/11/14 15:50:59 sample.RelationSampler: Fetching samples for relation S(x0)
[INFO] 15/11/14 15:50:59 sample.RelationSampler: Fetching samples for relation T(x0)
[INFO] 15/11/14 15:50:59 sample.RelationSampler: Fetching samples for relation U(x0)
[INFO] 15/11/14 15:50:59 sample.RelationSampler: Fetching samples for relation G(x0,x1,x2)
[INFO] 15/11/14 15:50:59 sample.RelationSampler: Fetching samples for relation H(x0,x1,x2)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Parsing samples for relation R(x0,x1,x2)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Parsing samples for relation S(x0)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Small tuples: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Big tuples: 3
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Parsing samples for relation T(x0)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Small tuples: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Big tuples: 4
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Parsing samples for relation U(x0)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Parsing samples for relation G(x0,x1,x2)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Parsing samples for relation H(x0,x1,x2)
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:50:59 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:50:59 sample.Simulator: Simulating relation H(x0,x1,x2)
[INFO] 15/11/14 15:50:59 sample.Simulator: Simulating relation U(x0)
[INFO] 15/11/14 15:50:59 sample.Simulator: Simulating relation H(x0,x1,x2)
[INFO] 15/11/14 15:50:59 sample.Simulator: Simulating relation U(x0)
[INFO] 15/11/14 15:50:59 policies.BestCostBasedGrouper: Candidate solution found! 1 NaN
[INFO] 15/11/14 15:50:59 policies.BestCostBasedGrouper: [	H(x,y,z) |X U(x)
	Guard In Bytes5
	Guarded In Bytes1
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:NaN
]
[INFO] 15/11/14 15:50:59 grouper.Grouper: Grouping complete: 1 group(s)
[INFO] 15/11/14 15:50:59 grouper.Grouper: Grouping: [	H(x,y,z) |X U(x)
	Guard In Bytes5
	Guarded In Bytes1
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:NaN
]
[WARN] 15/11/14 15:50:59 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
[INFO] 15/11/14 15:50:59 converter.GumboHadoopConverter: Intermediate data size: 0.0 MB
[INFO] 15/11/14 15:50:59 converter.GumboHadoopConverter: Num reducers: 1
[INFO] 15/11/14 15:50:59 converter.GumboHadoopConverter: R(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/R/R.txt;csv;'S(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/S/S.txt;csv;'T(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/T/T.txt;csv;'U(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/U/U.txt;csv;'G(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/G/G.txt;csv;'H(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/H/H.txt;csv;
[INFO] 15/11/14 15:50:59 converter.GumboHadoopConverter: Setting M1 guarded path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/U/U.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardedCsv
[INFO] 15/11/14 15:50:59 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/H/H.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardCsv
[INFO] 15/11/14 15:50:59 converter.GumboHadoopConverter: Setting Reduce tasks to 1
Adding output paths
[INFO] 15/11/14 15:50:59 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/H/H.txt using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardCsv
[INFO] 15/11/14 15:50:59 converter.GumboHadoopConverter: Adding M2 normal path file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_5_query1.gumbo_H+_1 using identity mapper 
[INFO] 15/11/14 15:50:59 converter.Round2ReduceJobEstimator: Output estimate 100663296
[INFO] 15/11/14 15:50:59 converter.Round2ReduceJobEstimator: Reducer estimate 1
[INFO] 15/11/14 15:51:03 Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO] 15/11/14 15:51:03 jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN] 15/11/14 15:51:03 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/14 15:51:03 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:03 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:04 mapreduce.JobSubmitter: number of splits:2
[INFO] 15/11/14 15:51:04 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/14 15:51:04 mapreduce.JobSubmitter: Submitting tokens for job: job_local1636819193_0001
[WARN] 15/11/14 15:51:04 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1636819193/.staging/job_local1636819193_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:04 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1636819193/.staging/job_local1636819193_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/14 15:51:04 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1636819193_0001/job_local1636819193_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:04 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1636819193_0001/job_local1636819193_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/14 15:51:04 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: Starting task: attempt_local1636819193_0001_m_000000_0
[INFO] 15/11/14 15:51:04 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:04 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:04 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/H/H.txt:0+5
[INFO] 15/11/14 15:51:04 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:04 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:04 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:04 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:04 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:04 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:04 mappers.GFMapper1Identity: MapperGFMapper1GuardCsv-00000-0
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:04 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:04 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:04 mapred.MapTask: bufstart = 0; bufend = 10; bufvoid = 104857600
[INFO] 15/11/14 15:51:04 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:04 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:04 mapred.Task: Task:attempt_local1636819193_0001_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:04 mapred.Task: Task 'attempt_local1636819193_0001_m_000000_0' done.
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: Finishing task: attempt_local1636819193_0001_m_000000_0
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: Starting task: attempt_local1636819193_0001_m_000001_0
[INFO] 15/11/14 15:51:04 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:04 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:04 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/U/U.txt:0+1
[INFO] 15/11/14 15:51:04 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:04 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:04 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:04 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:04 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:04 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:04 mappers.GFMapper1Identity: MapperGFMapper1GuardedCsv-00001-0
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:04 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:04 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:04 mapred.MapTask: bufstart = 0; bufend = 6; bufvoid = 104857600
[INFO] 15/11/14 15:51:04 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:04 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:04 mapred.Task: Task:attempt_local1636819193_0001_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:04 mapred.Task: Task 'attempt_local1636819193_0001_m_000001_0' done.
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: Finishing task: attempt_local1636819193_0001_m_000001_0
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: Starting task: attempt_local1636819193_0001_r_000000_0
[INFO] 15/11/14 15:51:04 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:04 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:04 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3790b6d6
[INFO] 15/11/14 15:51:04 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/14 15:51:04 reduce.EventFetcher: attempt_local1636819193_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/14 15:51:04 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1636819193_0001_m_000000_0 decomp: 14 len: 18 to MEMORY
[INFO] 15/11/14 15:51:04 reduce.InMemoryMapOutput: Read 14 bytes from map-output for attempt_local1636819193_0001_m_000000_0
[INFO] 15/11/14 15:51:04 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->14
[INFO] 15/11/14 15:51:04 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1636819193_0001_m_000001_0 decomp: 10 len: 14 to MEMORY
[INFO] 15/11/14 15:51:04 reduce.InMemoryMapOutput: Read 10 bytes from map-output for attempt_local1636819193_0001_m_000001_0
[INFO] 15/11/14 15:51:04 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 10, inMemoryMapOutputs.size() -> 2, commitMemory -> 14, usedMemory ->24
[INFO] 15/11/14 15:51:04 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:04 reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/14 15:51:04 mapred.Merger: Merging 2 sorted segments
[INFO] 15/11/14 15:51:04 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 16 bytes
[INFO] 15/11/14 15:51:04 reduce.MergeManagerImpl: Merged 2 segments, 24 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/14 15:51:04 reduce.MergeManagerImpl: Merging 1 files, 26 bytes from disk
[INFO] 15/11/14 15:51:04 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/14 15:51:04 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/14 15:51:04 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 18 bytes
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:04 Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[INFO] 15/11/14 15:51:04 reducers.GFReducer1Optimized: ReducerGFReducer1Optimized-00000-0
[INFO] 15/11/14 15:51:04 mapred.Task: Task:attempt_local1636819193_0001_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:04 mapred.Task: Task attempt_local1636819193_0001_r_000000_0 is allowed to commit now
[INFO] 15/11/14 15:51:04 output.FileOutputCommitter: Saved output of task 'attempt_local1636819193_0001_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_5_query1.gumbo_H+_1/_temporary/0/task_local1636819193_0001_r_000000
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/14 15:51:04 mapred.Task: Task 'attempt_local1636819193_0001_r_000000_0' done.
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: Finishing task: attempt_local1636819193_0001_r_000000_0
[INFO] 15/11/14 15:51:04 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/14 15:51:09 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/11/14 15:51:09 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/14 15:51:09 input.FileInputFormat: Total input paths to process : 2
[INFO] 15/11/14 15:51:09 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:09 mapreduce.JobSubmitter: number of splits:3
[INFO] 15/11/14 15:51:09 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/14 15:51:09 mapreduce.JobSubmitter: Submitting tokens for job: job_local2068327028_0002
[WARN] 15/11/14 15:51:09 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny2068327028/.staging/job_local2068327028_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:09 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny2068327028/.staging/job_local2068327028_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/14 15:51:09 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local2068327028_0002/job_local2068327028_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:09 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local2068327028_0002/job_local2068327028_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/14 15:51:09 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: Starting task: attempt_local2068327028_0002_m_000000_0
[INFO] 15/11/14 15:51:09 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:09 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:09 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_5_query1.gumbo_H+_1/round1-r-00000:0+7
[INFO] 15/11/14 15:51:09 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:09 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:09 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:09 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:09 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:09 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:09 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:09 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:09 mapred.MapTask: bufstart = 0; bufend = 7; bufvoid = 104857600
[INFO] 15/11/14 15:51:09 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:09 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:09 mapred.Task: Task:attempt_local2068327028_0002_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:09 mapred.Task: Task 'attempt_local2068327028_0002_m_000000_0' done.
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: Finishing task: attempt_local2068327028_0002_m_000000_0
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: Starting task: attempt_local2068327028_0002_m_000001_0
[INFO] 15/11/14 15:51:09 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:09 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:09 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/H/H.txt:0+5
[INFO] 15/11/14 15:51:09 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:09 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:09 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:09 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:09 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:09 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:09 mappers.GFMapper1Identity: MapperGFMapper2GuardCsv-00001-0
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:09 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:09 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:09 mapred.MapTask: bufstart = 0; bufend = 15; bufvoid = 104857600
[INFO] 15/11/14 15:51:09 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:09 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:09 mapred.Task: Task:attempt_local2068327028_0002_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:09 mapred.Task: Task 'attempt_local2068327028_0002_m_000001_0' done.
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: Finishing task: attempt_local2068327028_0002_m_000001_0
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: Starting task: attempt_local2068327028_0002_m_000002_0
[INFO] 15/11/14 15:51:09 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:09 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:09 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_5_query1.gumbo_H+_1/part-r-00000:0+0
[INFO] 15/11/14 15:51:09 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:09 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:09 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:09 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:09 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:09 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:09 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:09 mapred.Task: Task:attempt_local2068327028_0002_m_000002_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:09 mapred.Task: Task 'attempt_local2068327028_0002_m_000002_0' done.
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: Finishing task: attempt_local2068327028_0002_m_000002_0
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: Starting task: attempt_local2068327028_0002_r_000000_0
[INFO] 15/11/14 15:51:09 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:09 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:09 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59684a45
[INFO] 15/11/14 15:51:09 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/14 15:51:09 reduce.EventFetcher: attempt_local2068327028_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/14 15:51:09 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local2068327028_0002_m_000001_0 decomp: 19 len: 23 to MEMORY
[INFO] 15/11/14 15:51:09 reduce.InMemoryMapOutput: Read 19 bytes from map-output for attempt_local2068327028_0002_m_000001_0
[INFO] 15/11/14 15:51:09 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 19, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->19
[INFO] 15/11/14 15:51:09 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local2068327028_0002_m_000000_0 decomp: 11 len: 15 to MEMORY
[INFO] 15/11/14 15:51:09 reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local2068327028_0002_m_000000_0
[INFO] 15/11/14 15:51:09 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 2, commitMemory -> 19, usedMemory ->30
[INFO] 15/11/14 15:51:09 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local2068327028_0002_m_000002_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:09 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2068327028_0002_m_000002_0
[INFO] 15/11/14 15:51:09 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 30, usedMemory ->32
[INFO] 15/11/14 15:51:09 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/11/14 15:51:09 reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/14 15:51:09 mapred.Merger: Merging 3 sorted segments
[INFO] 15/11/14 15:51:09 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 16 bytes
[INFO] 15/11/14 15:51:09 reduce.MergeManagerImpl: Merged 3 segments, 32 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/14 15:51:09 reduce.MergeManagerImpl: Merging 1 files, 32 bytes from disk
[INFO] 15/11/14 15:51:09 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/14 15:51:09 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/14 15:51:09 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 21 bytes
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/11/14 15:51:09 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00000-0
[INFO] 15/11/14 15:51:09 mapred.Task: Task:attempt_local2068327028_0002_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/11/14 15:51:09 mapred.Task: Task attempt_local2068327028_0002_r_000000_0 is allowed to commit now
[INFO] 15/11/14 15:51:09 output.FileOutputCommitter: Saved output of task 'attempt_local2068327028_0002_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/query1.gumbo_O3+_2/_temporary/0/task_local2068327028_0002_r_000000
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/14 15:51:09 mapred.Task: Task 'attempt_local2068327028_0002_r_000000_0' done.
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: Finishing task: attempt_local2068327028_0002_r_000000_0
[INFO] 15/11/14 15:51:09 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/14 15:51:14 hadoop.HadoopPartitionQueue: Group is done, moving its output files{
id : 4 Depends on: None. - (O3(x,y,z) : H(x,y,z) & U(x))
}
[INFO] 15/11/14 15:51:14 hadoop.HadoopPartitionQueue: Moving O3(x0,x1,x2)
To: output/EXP_028/20151114_155058/OUT_1_O3
[INFO] 15/11/14 15:51:14 hadoop.HadoopPartitionQueue: Moving to:  output/EXP_028/20151114_155058/OUT_1_O3
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/query1.gumbo_O3+_2/O3-r-00000
[INFO] 15/11/14 15:51:14 utils.PartitionQueue: Calculation group {
id : 2 Depends on: None. - (O1(x,y,z) : R(x,y,z) & S(x))
id : 3 Depends on: 4, - (O5(x,y,z) : O3(x,y,z) & S(z))
} is ready to be scheduled.
Adding output paths
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Avoiding re-sample for R(x0,x1,x2)
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Avoiding re-sample for S(x0)
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Avoiding re-sample for T(x0)
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Fetching samples for relation O3(x0,x1,x2)
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Avoiding re-sample for U(x0)
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Avoiding re-sample for G(x0,x1,x2)
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Avoiding re-sample for H(x0,x1,x2)
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Parsing samples for relation O3(x0,x1,x2)
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:14 grouper.GrouperFactory: Creating a grouper with policy BESTCOSTGROUP_GUMBO
[WARN] 15/11/14 15:51:14 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
Adding output paths
[INFO] 15/11/14 15:51:14 grouper.Grouper: Decomposition complete: 	R(x,y,z) |X S(x)
	O3(x,y,z) |X S(z)
	Guard In Bytes0
	Guarded In Bytes0
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:0.0

[INFO] 15/11/14 15:51:14 sample.RelationSampler: Fetching samples for relation R(x0,x1,x2)
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Fetching samples for relation S(x0)
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Fetching samples for relation T(x0)
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Fetching samples for relation O3(x0,x1,x2)
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Fetching samples for relation U(x0)
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Fetching samples for relation G(x0,x1,x2)
[INFO] 15/11/14 15:51:14 sample.RelationSampler: Fetching samples for relation H(x0,x1,x2)
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Parsing samples for relation R(x0,x1,x2)
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Parsing samples for relation S(x0)
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Small tuples: 1
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Big tuples: 3
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Parsing samples for relation T(x0)
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Small tuples: 1
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Big tuples: 3
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Parsing samples for relation O3(x0,x1,x2)
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Parsing samples for relation U(x0)
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Parsing samples for relation G(x0,x1,x2)
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Parsing samples for relation H(x0,x1,x2)
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:14 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:14 sample.Simulator: Simulating relation R(x0,x1,x2)
[INFO] 15/11/14 15:51:14 sample.Simulator: Simulating relation S(x0)
[INFO] 15/11/14 15:51:14 sample.Simulator: Simulating relation O3(x0,x1,x2)
[INFO] 15/11/14 15:51:14 sample.Simulator: Simulating relation S(x0)
[INFO] 15/11/14 15:51:14 sample.Simulator: Simulating relation R(x0,x1,x2)
[INFO] 15/11/14 15:51:14 sample.Simulator: Simulating relation S(x0)
[INFO] 15/11/14 15:51:14 sample.Simulator: Simulating relation O3(x0,x1,x2)
[INFO] 15/11/14 15:51:14 sample.Simulator: Simulating relation S(x0)
[INFO] 15/11/14 15:51:14 policies.BestCostBasedGrouper: Candidate solution found! 1 NaN
[INFO] 15/11/14 15:51:14 policies.BestCostBasedGrouper: [	R(x,y,z) |X S(x)
	Guard In Bytes5
	Guarded In Bytes3
	Guard Out Bytes0
	Guarded Out Bytes12
	Cost:NaN
, 	O3(x,y,z) |X S(z)
	Guard In Bytes10
	Guarded In Bytes3
	Guard Out Bytes0
	Guarded Out Bytes12
	Cost:NaN
]
[INFO] 15/11/14 15:51:14 sample.Simulator: Simulating relation O3(x0,x1,x2)
[INFO] 15/11/14 15:51:14 sample.Simulator: Simulating relation R(x0,x1,x2)
[INFO] 15/11/14 15:51:14 sample.Simulator: Simulating relation S(x0)
[INFO] 15/11/14 15:51:14 policies.BestCostBasedGrouper: Candidate solution found! 2 NaN
[INFO] 15/11/14 15:51:14 policies.BestCostBasedGrouper: [	R(x,y,z) |X S(x)
	O3(x,y,z) |X S(z)
	Guard In Bytes15
	Guarded In Bytes3
	Guard Out Bytes0
	Guarded Out Bytes18
	Cost:NaN
]
[INFO] 15/11/14 15:51:14 grouper.Grouper: Grouping complete: 2 group(s)
[INFO] 15/11/14 15:51:14 grouper.Grouper: Grouping: [	R(x,y,z) |X S(x)
	Guard In Bytes5
	Guarded In Bytes3
	Guard Out Bytes0
	Guarded Out Bytes12
	Cost:NaN
, 	O3(x,y,z) |X S(z)
	Guard In Bytes10
	Guarded In Bytes3
	Guard Out Bytes0
	Guarded Out Bytes12
	Cost:NaN
]
[WARN] 15/11/14 15:51:14 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Intermediate data size: 1.1444091796875E-5 MB
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Num reducers: 1
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: R(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/R/R.txt;csv;'S(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/S/S.txt;csv;'T(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/T/T.txt;csv;'O3(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_1_O3/O3-r-00000;rel;'U(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/U/U.txt;csv;'G(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/G/G.txt;csv;'H(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/H/H.txt;csv;
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Setting M1 guarded path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/S/S.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardedCsv
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/R/R.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardCsv
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Setting Reduce tasks to 1
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Intermediate data size: 1.1444091796875E-5 MB
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Num reducers: 1
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: R(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/R/R.txt;csv;'S(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/S/S.txt;csv;'T(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/T/T.txt;csv;'O3(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_1_O3/O3-r-00000;rel;'U(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/U/U.txt;csv;'G(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/G/G.txt;csv;'H(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/H/H.txt;csv;
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Setting M1 guarded path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/S/S.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardedCsv
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_1_O3/O3-r-00000 using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardRelOptimized
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Setting Reduce tasks to 1
Adding output paths
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_1_O3/O3-r-00000 using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardRelOptimized
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/R/R.txt using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardCsv
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Adding M2 normal path file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_6_query1.gumbo_R+_1 using identity mapper 
[INFO] 15/11/14 15:51:14 converter.GumboHadoopConverter: Adding M2 normal path file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_7_query1.gumbo_O3+_1 using identity mapper 
[INFO] 15/11/14 15:51:14 converter.Round2ReduceJobEstimator: Output estimate 201326592
[INFO] 15/11/14 15:51:14 converter.Round2ReduceJobEstimator: Reducer estimate 2
[INFO] 15/11/14 15:51:19 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/11/14 15:51:19 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/14 15:51:19 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:19 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:19 mapreduce.JobSubmitter: number of splits:2
[INFO] 15/11/14 15:51:19 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/14 15:51:19 mapreduce.JobSubmitter: Submitting tokens for job: job_local1665880476_0003
[WARN] 15/11/14 15:51:19 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1665880476/.staging/job_local1665880476_0003/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:19 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1665880476/.staging/job_local1665880476_0003/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/14 15:51:19 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1665880476_0003/job_local1665880476_0003.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:19 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1665880476_0003/job_local1665880476_0003.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/14 15:51:19 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/14 15:51:19 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Starting task: attempt_local1665880476_0003_m_000000_0
[INFO] 15/11/14 15:51:19 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:19 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:19 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_1_O3/O3-r-00000:0+10
[INFO] 15/11/14 15:51:19 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:19 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:19 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:19 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:19 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:19 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:19 mappers.GFMapper1Identity: MapperGFMapper1GuardRelOptimized-00000-0
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:19 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:19 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:19 mapred.MapTask: bufstart = 0; bufend = 10; bufvoid = 104857600
[INFO] 15/11/14 15:51:19 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[WARN] 15/11/14 15:51:19 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/14 15:51:19 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:19 mapred.Task: Task:attempt_local1665880476_0003_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:19 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:19 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:19 mapred.Task: Task 'attempt_local1665880476_0003_m_000000_0' done.
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Finishing task: attempt_local1665880476_0003_m_000000_0
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Starting task: attempt_local1665880476_0003_m_000001_0
[INFO] 15/11/14 15:51:19 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:19 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:19 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/S/S.txt:0+3
[INFO] 15/11/14 15:51:19 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:19 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:19 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:19 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:19 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:19 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:19 mappers.GFMapper1Identity: MapperGFMapper1GuardedCsv-00001-0
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:19 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:19 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:19 mapred.MapTask: bufstart = 0; bufend = 12; bufvoid = 104857600
[INFO] 15/11/14 15:51:19 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
[INFO] 15/11/14 15:51:19 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:19 mapred.Task: Task:attempt_local1665880476_0003_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:19 mapred.Task: Task 'attempt_local1665880476_0003_m_000001_0' done.
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Finishing task: attempt_local1665880476_0003_m_000001_0
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Starting task: attempt_local1665880476_0003_r_000000_0
[INFO] 15/11/14 15:51:19 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:19 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:19 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@8690aa7
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/14 15:51:19 reduce.EventFetcher: attempt_local1665880476_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/14 15:51:19 reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1665880476_0003_m_000000_0 decomp: 14 len: 18 to MEMORY
[INFO] 15/11/14 15:51:19 reduce.InMemoryMapOutput: Read 14 bytes from map-output for attempt_local1665880476_0003_m_000000_0
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->14
[INFO] 15/11/14 15:51:19 reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1665880476_0003_m_000001_0 decomp: 18 len: 22 to MEMORY
[INFO] 15/11/14 15:51:19 reduce.InMemoryMapOutput: Read 18 bytes from map-output for attempt_local1665880476_0003_m_000001_0
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 18, inMemoryMapOutputs.size() -> 2, commitMemory -> 14, usedMemory ->32
[INFO] 15/11/14 15:51:19 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/14 15:51:19 mapreduce.JobSubmitter: number of splits:2
[INFO] 15/11/14 15:51:19 mapred.Merger: Merging 2 sorted segments
[INFO] 15/11/14 15:51:19 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 24 bytes
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: Merged 2 segments, 32 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: Merging 1 files, 34 bytes from disk
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/14 15:51:19 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/14 15:51:19 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 26 bytes
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:19 reducers.GFReducer1Optimized: ReducerGFReducer1Optimized-00000-0
[INFO] 15/11/14 15:51:19 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/14 15:51:19 mapreduce.JobSubmitter: Submitting tokens for job: job_local1910100407_0004
[INFO] 15/11/14 15:51:19 mapred.Task: Task:attempt_local1665880476_0003_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:19 mapred.Task: Task attempt_local1665880476_0003_r_000000_0 is allowed to commit now
[INFO] 15/11/14 15:51:19 output.FileOutputCommitter: Saved output of task 'attempt_local1665880476_0003_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_7_query1.gumbo_O3+_1/_temporary/0/task_local1665880476_0003_r_000000
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/14 15:51:19 mapred.Task: Task 'attempt_local1665880476_0003_r_000000_0' done.
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Finishing task: attempt_local1665880476_0003_r_000000_0
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: reduce task executor complete.
[WARN] 15/11/14 15:51:19 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1910100407/.staging/job_local1910100407_0004/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:19 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1910100407/.staging/job_local1910100407_0004/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/14 15:51:19 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1910100407_0004/job_local1910100407_0004.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:19 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1910100407_0004/job_local1910100407_0004.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/14 15:51:19 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Starting task: attempt_local1910100407_0004_m_000000_0
[INFO] 15/11/14 15:51:19 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:19 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:19 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/R/R.txt:0+5
[INFO] 15/11/14 15:51:19 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:19 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:19 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:19 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:19 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:19 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:19 mappers.GFMapper1Identity: MapperGFMapper1GuardCsv-00000-0
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:19 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:19 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:19 mapred.MapTask: bufstart = 0; bufend = 10; bufvoid = 104857600
[INFO] 15/11/14 15:51:19 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:19 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:19 mapred.Task: Task:attempt_local1910100407_0004_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:19 mapred.Task: Task 'attempt_local1910100407_0004_m_000000_0' done.
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Finishing task: attempt_local1910100407_0004_m_000000_0
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Starting task: attempt_local1910100407_0004_m_000001_0
[INFO] 15/11/14 15:51:19 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:19 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:19 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/S/S.txt:0+3
[INFO] 15/11/14 15:51:19 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:19 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:19 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:19 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:19 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:19 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:19 mappers.GFMapper1Identity: MapperGFMapper1GuardedCsv-00001-0
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:19 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:19 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:19 mapred.MapTask: bufstart = 0; bufend = 12; bufvoid = 104857600
[INFO] 15/11/14 15:51:19 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
[INFO] 15/11/14 15:51:19 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:19 mapred.Task: Task:attempt_local1910100407_0004_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:19 mapred.Task: Task 'attempt_local1910100407_0004_m_000001_0' done.
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Finishing task: attempt_local1910100407_0004_m_000001_0
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Starting task: attempt_local1910100407_0004_r_000000_0
[INFO] 15/11/14 15:51:19 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:19 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:19 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1c65c336
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/14 15:51:19 reduce.EventFetcher: attempt_local1910100407_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/14 15:51:19 reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1910100407_0004_m_000001_0 decomp: 18 len: 22 to MEMORY
[INFO] 15/11/14 15:51:19 reduce.InMemoryMapOutput: Read 18 bytes from map-output for attempt_local1910100407_0004_m_000001_0
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 18, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->18
[INFO] 15/11/14 15:51:19 reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1910100407_0004_m_000000_0 decomp: 14 len: 18 to MEMORY
[INFO] 15/11/14 15:51:19 reduce.InMemoryMapOutput: Read 14 bytes from map-output for attempt_local1910100407_0004_m_000000_0
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14, inMemoryMapOutputs.size() -> 2, commitMemory -> 18, usedMemory ->32
[INFO] 15/11/14 15:51:19 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/14 15:51:19 mapred.Merger: Merging 2 sorted segments
[INFO] 15/11/14 15:51:19 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 24 bytes
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: Merged 2 segments, 32 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: Merging 1 files, 34 bytes from disk
[INFO] 15/11/14 15:51:19 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/14 15:51:19 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/14 15:51:19 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 26 bytes
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:19 reducers.GFReducer1Optimized: ReducerGFReducer1Optimized-00000-0
[INFO] 15/11/14 15:51:19 mapred.Task: Task:attempt_local1910100407_0004_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:19 mapred.Task: Task attempt_local1910100407_0004_r_000000_0 is allowed to commit now
[INFO] 15/11/14 15:51:19 output.FileOutputCommitter: Saved output of task 'attempt_local1910100407_0004_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_6_query1.gumbo_R+_1/_temporary/0/task_local1910100407_0004_r_000000
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/14 15:51:19 mapred.Task: Task 'attempt_local1910100407_0004_r_000000_0' done.
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: Finishing task: attempt_local1910100407_0004_r_000000_0
[INFO] 15/11/14 15:51:19 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/14 15:51:24 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/11/14 15:51:24 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/14 15:51:24 input.FileInputFormat: Total input paths to process : 4
[INFO] 15/11/14 15:51:24 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:24 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:24 mapreduce.JobSubmitter: number of splits:6
[INFO] 15/11/14 15:51:24 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/14 15:51:24 mapreduce.JobSubmitter: Submitting tokens for job: job_local1095752076_0005
[WARN] 15/11/14 15:51:24 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1095752076/.staging/job_local1095752076_0005/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:24 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1095752076/.staging/job_local1095752076_0005/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/14 15:51:24 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1095752076_0005/job_local1095752076_0005.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:24 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1095752076_0005/job_local1095752076_0005.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/14 15:51:24 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Starting task: attempt_local1095752076_0005_m_000000_0
[INFO] 15/11/14 15:51:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:24 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_1_O3/O3-r-00000:0+10
[INFO] 15/11/14 15:51:24 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:24 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:24 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:24 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:24 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:24 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:24 mappers.GFMapper1Identity: MapperGFMapper2GuardRelOptimized-00000-0
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:24 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:24 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:24 mapred.MapTask: bufstart = 0; bufend = 16; bufvoid = 104857600
[INFO] 15/11/14 15:51:24 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:24 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:24 mapred.Task: Task:attempt_local1095752076_0005_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:24 mapred.Task: Task 'attempt_local1095752076_0005_m_000000_0' done.
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Finishing task: attempt_local1095752076_0005_m_000000_0
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Starting task: attempt_local1095752076_0005_m_000001_0
[INFO] 15/11/14 15:51:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:24 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_6_query1.gumbo_R+_1/round1-r-00000:0+7
[INFO] 15/11/14 15:51:24 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:24 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:24 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:24 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:24 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:24 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:24 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:24 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:24 mapred.MapTask: bufstart = 0; bufend = 7; bufvoid = 104857600
[INFO] 15/11/14 15:51:24 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:24 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:24 mapred.Task: Task:attempt_local1095752076_0005_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:24 mapred.Task: Task 'attempt_local1095752076_0005_m_000001_0' done.
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Finishing task: attempt_local1095752076_0005_m_000001_0
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Starting task: attempt_local1095752076_0005_m_000002_0
[INFO] 15/11/14 15:51:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:24 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_7_query1.gumbo_O3+_1/round1-r-00000:0+7
[INFO] 15/11/14 15:51:24 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:24 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:24 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:24 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:24 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:24 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:24 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:24 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:24 mapred.MapTask: bufstart = 0; bufend = 7; bufvoid = 104857600
[INFO] 15/11/14 15:51:24 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:24 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:24 mapred.Task: Task:attempt_local1095752076_0005_m_000002_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:24 mapred.Task: Task 'attempt_local1095752076_0005_m_000002_0' done.
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Finishing task: attempt_local1095752076_0005_m_000002_0
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Starting task: attempt_local1095752076_0005_m_000003_0
[INFO] 15/11/14 15:51:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:24 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/R/R.txt:0+5
[INFO] 15/11/14 15:51:24 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:24 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:24 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:24 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:24 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:24 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:24 mappers.GFMapper1Identity: MapperGFMapper2GuardCsv-00003-0
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:24 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:24 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:24 mapred.MapTask: bufstart = 0; bufend = 15; bufvoid = 104857600
[INFO] 15/11/14 15:51:24 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:24 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:24 mapred.Task: Task:attempt_local1095752076_0005_m_000003_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:24 mapred.Task: Task 'attempt_local1095752076_0005_m_000003_0' done.
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Finishing task: attempt_local1095752076_0005_m_000003_0
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Starting task: attempt_local1095752076_0005_m_000004_0
[INFO] 15/11/14 15:51:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:24 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_6_query1.gumbo_R+_1/part-r-00000:0+0
[INFO] 15/11/14 15:51:24 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:24 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:24 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:24 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:24 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:24 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:24 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:24 mapred.Task: Task:attempt_local1095752076_0005_m_000004_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:24 mapred.Task: Task 'attempt_local1095752076_0005_m_000004_0' done.
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Finishing task: attempt_local1095752076_0005_m_000004_0
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Starting task: attempt_local1095752076_0005_m_000005_0
[INFO] 15/11/14 15:51:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:24 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_7_query1.gumbo_O3+_1/part-r-00000:0+0
[INFO] 15/11/14 15:51:24 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:24 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:24 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:24 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:24 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:24 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:24 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:24 mapred.Task: Task:attempt_local1095752076_0005_m_000005_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:24 mapred.Task: Task 'attempt_local1095752076_0005_m_000005_0' done.
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Finishing task: attempt_local1095752076_0005_m_000005_0
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Starting task: attempt_local1095752076_0005_r_000000_0
[INFO] 15/11/14 15:51:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:24 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e21293f
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/14 15:51:24 reduce.EventFetcher: attempt_local1095752076_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/14 15:51:24 reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1095752076_0005_m_000002_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:24 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1095752076_0005_m_000002_0
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
[INFO] 15/11/14 15:51:24 reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1095752076_0005_m_000005_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:24 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1095752076_0005_m_000005_0
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
[INFO] 15/11/14 15:51:24 reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1095752076_0005_m_000000_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:24 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1095752076_0005_m_000000_0
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6
[INFO] 15/11/14 15:51:24 reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1095752076_0005_m_000003_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:24 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1095752076_0005_m_000003_0
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->8
[INFO] 15/11/14 15:51:24 reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1095752076_0005_m_000004_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:24 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1095752076_0005_m_000004_0
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 8, usedMemory ->10
[INFO] 15/11/14 15:51:24 reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1095752076_0005_m_000001_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:24 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1095752076_0005_m_000001_0
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 10, usedMemory ->12
[INFO] 15/11/14 15:51:24 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: 6 / 6 copied.
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: finalMerge called with 6 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/14 15:51:24 mapred.Merger: Merging 6 sorted segments
[INFO] 15/11/14 15:51:24 mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: Merged 6 segments, 12 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/14 15:51:24 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/14 15:51:24 mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: 6 / 6 copied.
[INFO] 15/11/14 15:51:24 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00000-0
[INFO] 15/11/14 15:51:24 mapred.Task: Task:attempt_local1095752076_0005_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: 6 / 6 copied.
[INFO] 15/11/14 15:51:24 mapred.Task: Task attempt_local1095752076_0005_r_000000_0 is allowed to commit now
[INFO] 15/11/14 15:51:24 output.FileOutputCommitter: Saved output of task 'attempt_local1095752076_0005_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/query1.gumbo_O1+O5+_2/_temporary/0/task_local1095752076_0005_r_000000
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/14 15:51:24 mapred.Task: Task 'attempt_local1095752076_0005_r_000000_0' done.
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Finishing task: attempt_local1095752076_0005_r_000000_0
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Starting task: attempt_local1095752076_0005_r_000001_0
[INFO] 15/11/14 15:51:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:24 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@64ee0df1
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/14 15:51:24 reduce.EventFetcher: attempt_local1095752076_0005_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/14 15:51:24 reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1095752076_0005_m_000002_0 decomp: 11 len: 15 to MEMORY
[INFO] 15/11/14 15:51:24 reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local1095752076_0005_m_000002_0
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
[INFO] 15/11/14 15:51:24 reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1095752076_0005_m_000005_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:24 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1095752076_0005_m_000005_0
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->13
[INFO] 15/11/14 15:51:24 reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1095752076_0005_m_000000_0 decomp: 20 len: 24 to MEMORY
[INFO] 15/11/14 15:51:24 reduce.InMemoryMapOutput: Read 20 bytes from map-output for attempt_local1095752076_0005_m_000000_0
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 3, commitMemory -> 13, usedMemory ->33
[INFO] 15/11/14 15:51:24 reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1095752076_0005_m_000003_0 decomp: 19 len: 23 to MEMORY
[INFO] 15/11/14 15:51:24 reduce.InMemoryMapOutput: Read 19 bytes from map-output for attempt_local1095752076_0005_m_000003_0
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 19, inMemoryMapOutputs.size() -> 4, commitMemory -> 33, usedMemory ->52
[INFO] 15/11/14 15:51:24 reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1095752076_0005_m_000004_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:24 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1095752076_0005_m_000004_0
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 52, usedMemory ->54
[INFO] 15/11/14 15:51:24 reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1095752076_0005_m_000001_0 decomp: 11 len: 15 to MEMORY
[INFO] 15/11/14 15:51:24 reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local1095752076_0005_m_000001_0
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 6, commitMemory -> 54, usedMemory ->65
[INFO] 15/11/14 15:51:24 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: 6 / 6 copied.
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: finalMerge called with 6 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/14 15:51:24 mapred.Merger: Merging 6 sorted segments
[INFO] 15/11/14 15:51:24 mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 33 bytes
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: Merged 6 segments, 65 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: Merging 1 files, 59 bytes from disk
[INFO] 15/11/14 15:51:24 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/14 15:51:24 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/14 15:51:24 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 48 bytes
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: 6 / 6 copied.
[INFO] 15/11/14 15:51:24 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00001-0
[INFO] 15/11/14 15:51:24 mapred.Task: Task:attempt_local1095752076_0005_r_000001_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: 6 / 6 copied.
[INFO] 15/11/14 15:51:24 mapred.Task: Task attempt_local1095752076_0005_r_000001_0 is allowed to commit now
[INFO] 15/11/14 15:51:24 output.FileOutputCommitter: Saved output of task 'attempt_local1095752076_0005_r_000001_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/query1.gumbo_O1+O5+_2/_temporary/0/task_local1095752076_0005_r_000001
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/14 15:51:24 mapred.Task: Task 'attempt_local1095752076_0005_r_000001_0' done.
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: Finishing task: attempt_local1095752076_0005_r_000001_0
[INFO] 15/11/14 15:51:24 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/14 15:51:30 hadoop.HadoopPartitionQueue: Group is done, moving its output files{
id : 2 Depends on: None. - (O1(x,y,z) : R(x,y,z) & S(x))
id : 3 Depends on: 4, - (O5(x,y,z) : O3(x,y,z) & S(z))
}
[INFO] 15/11/14 15:51:30 hadoop.HadoopPartitionQueue: Moving O1(x0,x1,x2)
To: output/EXP_028/20151114_155058/OUT_0_O1
[INFO] 15/11/14 15:51:30 hadoop.HadoopPartitionQueue: Moving to:  output/EXP_028/20151114_155058/OUT_0_O1
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/query1.gumbo_O1+O5+_2/O1-r-00001
[INFO] 15/11/14 15:51:30 hadoop.HadoopPartitionQueue: Moving O5(x0,x1,x2)
To: output/EXP_028/20151114_155058/OUT_4_O5
[INFO] 15/11/14 15:51:30 hadoop.HadoopPartitionQueue: Moving to:  output/EXP_028/20151114_155058/OUT_4_O5
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/query1.gumbo_O1+O5+_2/O5-r-00001
[INFO] 15/11/14 15:51:30 utils.PartitionQueue: Calculation group {
id : 0 Depends on: None. - (O2(x,y,z) : G(x,y,z) & T(x))
id : 1 Depends on: 2, - (O4(x,y,z) : O1(x,y,z) & T(z))
} is ready to be scheduled.
Adding output paths
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Avoiding re-sample for R(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Fetching samples for relation O1(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Avoiding re-sample for S(x0)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Avoiding re-sample for T(x0)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Avoiding re-sample for O3(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Avoiding re-sample for U(x0)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Fetching samples for relation O5(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Avoiding re-sample for G(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Avoiding re-sample for H(x0,x1,x2)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Parsing samples for relation O1(x0,x1,x2)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Parsing samples for relation O5(x0,x1,x2)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:30 grouper.GrouperFactory: Creating a grouper with policy BESTCOSTGROUP_GUMBO
[WARN] 15/11/14 15:51:30 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
Adding output paths
[INFO] 15/11/14 15:51:30 grouper.Grouper: Decomposition complete: 	G(x,y,z) |X T(x)
	O1(x,y,z) |X T(z)
	Guard In Bytes0
	Guarded In Bytes0
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:0.0

[INFO] 15/11/14 15:51:30 sample.RelationSampler: Fetching samples for relation R(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Fetching samples for relation O1(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Fetching samples for relation S(x0)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Fetching samples for relation T(x0)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Fetching samples for relation O3(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Fetching samples for relation U(x0)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Fetching samples for relation O5(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Fetching samples for relation G(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.RelationSampler: Fetching samples for relation H(x0,x1,x2)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Parsing samples for relation R(x0,x1,x2)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Parsing samples for relation O1(x0,x1,x2)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Parsing samples for relation S(x0)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Small tuples: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Big tuples: 3
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Parsing samples for relation T(x0)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Small tuples: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Big tuples: 4
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Parsing samples for relation O3(x0,x1,x2)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Parsing samples for relation U(x0)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Parsing samples for relation O5(x0,x1,x2)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Parsing samples for relation G(x0,x1,x2)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Parsing samples for relation H(x0,x1,x2)
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Small tuples: 0
[INFO] 15/11/14 15:51:30 reporter.RelationTupleSampleContainer: Big tuples: 0
[INFO] 15/11/14 15:51:30 sample.Simulator: Simulating relation T(x0)
[INFO] 15/11/14 15:51:30 sample.Simulator: Simulating relation G(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.Simulator: Simulating relation T(x0)
[INFO] 15/11/14 15:51:30 sample.Simulator: Simulating relation O1(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.Simulator: Simulating relation T(x0)
[INFO] 15/11/14 15:51:30 sample.Simulator: Simulating relation G(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.Simulator: Simulating relation T(x0)
[INFO] 15/11/14 15:51:30 sample.Simulator: Simulating relation O1(x0,x1,x2)
[INFO] 15/11/14 15:51:30 policies.BestCostBasedGrouper: Candidate solution found! 1 NaN
[INFO] 15/11/14 15:51:30 policies.BestCostBasedGrouper: [	G(x,y,z) |X T(x)
	Guard In Bytes5
	Guarded In Bytes4
	Guard Out Bytes0
	Guarded Out Bytes8
	Cost:NaN
, 	O1(x,y,z) |X T(z)
	Guard In Bytes10
	Guarded In Bytes4
	Guard Out Bytes0
	Guarded Out Bytes8
	Cost:NaN
]
[INFO] 15/11/14 15:51:30 sample.Simulator: Simulating relation T(x0)
[INFO] 15/11/14 15:51:30 sample.Simulator: Simulating relation O1(x0,x1,x2)
[INFO] 15/11/14 15:51:30 sample.Simulator: Simulating relation G(x0,x1,x2)
[INFO] 15/11/14 15:51:30 policies.BestCostBasedGrouper: Candidate solution found! 2 NaN
[INFO] 15/11/14 15:51:30 policies.BestCostBasedGrouper: [	G(x,y,z) |X T(x)
	O1(x,y,z) |X T(z)
	Guard In Bytes15
	Guarded In Bytes4
	Guard Out Bytes0
	Guarded Out Bytes12
	Cost:NaN
]
[INFO] 15/11/14 15:51:30 grouper.Grouper: Grouping complete: 2 group(s)
[INFO] 15/11/14 15:51:30 grouper.Grouper: Grouping: [	G(x,y,z) |X T(x)
	Guard In Bytes5
	Guarded In Bytes4
	Guard Out Bytes0
	Guarded Out Bytes8
	Cost:NaN
, 	O1(x,y,z) |X T(z)
	Guard In Bytes10
	Guarded In Bytes4
	Guard Out Bytes0
	Guarded Out Bytes8
	Cost:NaN
]
[WARN] 15/11/14 15:51:30 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Intermediate data size: 7.62939453125E-6 MB
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Num reducers: 1
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: R(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/R/R.txt;csv;'O1(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_0_O1/O1-r-00001;rel;'S(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/S/S.txt;csv;'T(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/T/T.txt;csv;'O3(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_1_O3/O3-r-00000;rel;'U(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/U/U.txt;csv;'O5(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_4_O5/O5-r-00001;rel;'G(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/G/G.txt;csv;'H(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/H/H.txt;csv;
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Setting M1 guarded path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/T/T.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardedCsv
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/G/G.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardCsv
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Setting Reduce tasks to 1
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Intermediate data size: 7.62939453125E-6 MB
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Num reducers: 1
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: R(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/R/R.txt;csv;'O1(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_0_O1/O1-r-00001;rel;'S(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/S/S.txt;csv;'T(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/T/T.txt;csv;'O3(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_1_O3/O3-r-00000;rel;'U(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/U/U.txt;csv;'O5(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_4_O5/O5-r-00001;rel;'G(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/G/G.txt;csv;'H(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/H/H.txt;csv;
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Setting M1 guarded path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/T/T.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardedCsv
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_0_O1/O1-r-00001 using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardRelOptimized
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Setting Reduce tasks to 1
Adding output paths
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_0_O1/O1-r-00001 using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardRelOptimized
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/G/G.txt using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardCsv
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Adding M2 normal path file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_8_query1.gumbo_G+_1 using identity mapper 
[INFO] 15/11/14 15:51:30 converter.GumboHadoopConverter: Adding M2 normal path file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_9_query1.gumbo_O1+_1 using identity mapper 
[INFO] 15/11/14 15:51:30 converter.Round2ReduceJobEstimator: Output estimate 201326592
[INFO] 15/11/14 15:51:30 converter.Round2ReduceJobEstimator: Reducer estimate 2
[INFO] 15/11/14 15:51:34 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/11/14 15:51:34 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/14 15:51:34 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:34 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:34 mapreduce.JobSubmitter: number of splits:2
[INFO] 15/11/14 15:51:34 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/14 15:51:34 mapreduce.JobSubmitter: Submitting tokens for job: job_local1933209871_0006
[WARN] 15/11/14 15:51:34 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1933209871/.staging/job_local1933209871_0006/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:34 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1933209871/.staging/job_local1933209871_0006/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/14 15:51:34 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1933209871_0006/job_local1933209871_0006.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:34 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1933209871_0006/job_local1933209871_0006.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/14 15:51:34 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/14 15:51:34 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Starting task: attempt_local1933209871_0006_m_000000_0
[INFO] 15/11/14 15:51:34 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:34 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:34 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/G/G.txt:0+5
[INFO] 15/11/14 15:51:34 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[WARN] 15/11/14 15:51:34 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/14 15:51:34 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:34 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:34 mapreduce.JobSubmitter: number of splits:2
[INFO] 15/11/14 15:51:34 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/14 15:51:34 mapreduce.JobSubmitter: Submitting tokens for job: job_local876903870_0007
[WARN] 15/11/14 15:51:34 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny876903870/.staging/job_local876903870_0007/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:34 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny876903870/.staging/job_local876903870_0007/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/14 15:51:34 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:34 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:34 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:34 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:34 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:34 mappers.GFMapper1Identity: MapperGFMapper1GuardCsv-00000-0
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:34 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:34 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:34 mapred.MapTask: bufstart = 0; bufend = 10; bufvoid = 104857600
[INFO] 15/11/14 15:51:34 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:34 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:34 mapred.Task: Task:attempt_local1933209871_0006_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:34 mapred.Task: Task 'attempt_local1933209871_0006_m_000000_0' done.
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Finishing task: attempt_local1933209871_0006_m_000000_0
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Starting task: attempt_local1933209871_0006_m_000001_0
[INFO] 15/11/14 15:51:34 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:34 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:34 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/T/T.txt:0+4
[INFO] 15/11/14 15:51:34 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[WARN] 15/11/14 15:51:34 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local876903870_0007/job_local876903870_0007.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:34 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local876903870_0007/job_local876903870_0007.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/14 15:51:34 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/14 15:51:34 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:34 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/14 15:51:34 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:34 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:34 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/14 15:51:34 mappers.GFMapper1Identity: MapperGFMapper1GuardedCsv-00001-0
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Starting task: attempt_local876903870_0007_m_000000_0
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:34 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:34 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:34 mapred.MapTask: bufstart = 0; bufend = 12; bufvoid = 104857600
[INFO] 15/11/14 15:51:34 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
[INFO] 15/11/14 15:51:34 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:34 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:34 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_0_O1/O1-r-00001:0+10
[INFO] 15/11/14 15:51:34 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:34 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:34 mapred.Task: Task:attempt_local1933209871_0006_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:34 mapred.Task: Task 'attempt_local1933209871_0006_m_000001_0' done.
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Finishing task: attempt_local1933209871_0006_m_000001_0
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Starting task: attempt_local1933209871_0006_r_000000_0
[INFO] 15/11/14 15:51:34 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:34 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:34 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:34 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:34 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:34 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:34 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:34 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@58d39cf2
[INFO] 15/11/14 15:51:34 mappers.GFMapper1Identity: MapperGFMapper1GuardRelOptimized-00000-0
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/14 15:51:34 reduce.EventFetcher: attempt_local1933209871_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:34 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:34 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:34 mapred.MapTask: bufstart = 0; bufend = 10; bufvoid = 104857600
[INFO] 15/11/14 15:51:34 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:34 reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1933209871_0006_m_000000_0 decomp: 14 len: 18 to MEMORY
[INFO] 15/11/14 15:51:34 reduce.InMemoryMapOutput: Read 14 bytes from map-output for attempt_local1933209871_0006_m_000000_0
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->14
[INFO] 15/11/14 15:51:34 reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1933209871_0006_m_000001_0 decomp: 18 len: 22 to MEMORY
[INFO] 15/11/14 15:51:34 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:34 reduce.InMemoryMapOutput: Read 18 bytes from map-output for attempt_local1933209871_0006_m_000001_0
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 18, inMemoryMapOutputs.size() -> 2, commitMemory -> 14, usedMemory ->32
[INFO] 15/11/14 15:51:34 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/14 15:51:34 mapred.Merger: Merging 2 sorted segments
[INFO] 15/11/14 15:51:34 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 24 bytes
[INFO] 15/11/14 15:51:34 mapred.Task: Task:attempt_local876903870_0007_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: Merged 2 segments, 32 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: Merging 1 files, 34 bytes from disk
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/14 15:51:34 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:34 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 26 bytes
[INFO] 15/11/14 15:51:34 mapred.Task: Task 'attempt_local876903870_0007_m_000000_0' done.
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Finishing task: attempt_local876903870_0007_m_000000_0
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Starting task: attempt_local876903870_0007_m_000001_0
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:34 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:34 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:34 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/T/T.txt:0+4
[INFO] 15/11/14 15:51:34 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:34 reducers.GFReducer1Optimized: ReducerGFReducer1Optimized-00000-0
[INFO] 15/11/14 15:51:34 mapred.Task: Task:attempt_local1933209871_0006_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:34 mapred.Task: Task attempt_local1933209871_0006_r_000000_0 is allowed to commit now
[INFO] 15/11/14 15:51:34 output.FileOutputCommitter: Saved output of task 'attempt_local1933209871_0006_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_8_query1.gumbo_G+_1/_temporary/0/task_local1933209871_0006_r_000000
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/14 15:51:34 mapred.Task: Task 'attempt_local1933209871_0006_r_000000_0' done.
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Finishing task: attempt_local1933209871_0006_r_000000_0
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/14 15:51:34 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:34 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:34 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:34 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:34 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:34 mappers.GFMapper1Identity: MapperGFMapper1GuardedCsv-00001-0
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:34 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:34 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:34 mapred.MapTask: bufstart = 0; bufend = 12; bufvoid = 104857600
[INFO] 15/11/14 15:51:34 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
[INFO] 15/11/14 15:51:34 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:34 mapred.Task: Task:attempt_local876903870_0007_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:34 mapred.Task: Task 'attempt_local876903870_0007_m_000001_0' done.
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Finishing task: attempt_local876903870_0007_m_000001_0
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Starting task: attempt_local876903870_0007_r_000000_0
[INFO] 15/11/14 15:51:34 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:34 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:34 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@f1c2843
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/14 15:51:34 reduce.EventFetcher: attempt_local876903870_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/14 15:51:34 reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local876903870_0007_m_000001_0 decomp: 18 len: 22 to MEMORY
[INFO] 15/11/14 15:51:34 reduce.InMemoryMapOutput: Read 18 bytes from map-output for attempt_local876903870_0007_m_000001_0
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 18, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->18
[INFO] 15/11/14 15:51:34 reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local876903870_0007_m_000000_0 decomp: 14 len: 18 to MEMORY
[INFO] 15/11/14 15:51:34 reduce.InMemoryMapOutput: Read 14 bytes from map-output for attempt_local876903870_0007_m_000000_0
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14, inMemoryMapOutputs.size() -> 2, commitMemory -> 18, usedMemory ->32
[INFO] 15/11/14 15:51:34 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/14 15:51:34 mapred.Merger: Merging 2 sorted segments
[INFO] 15/11/14 15:51:34 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 24 bytes
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: Merged 2 segments, 32 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: Merging 1 files, 34 bytes from disk
[INFO] 15/11/14 15:51:34 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/14 15:51:34 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/14 15:51:34 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 26 bytes
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:34 reducers.GFReducer1Optimized: ReducerGFReducer1Optimized-00000-0
[INFO] 15/11/14 15:51:34 mapred.Task: Task:attempt_local876903870_0007_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/14 15:51:34 mapred.Task: Task attempt_local876903870_0007_r_000000_0 is allowed to commit now
[INFO] 15/11/14 15:51:34 output.FileOutputCommitter: Saved output of task 'attempt_local876903870_0007_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_9_query1.gumbo_O1+_1/_temporary/0/task_local876903870_0007_r_000000
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/14 15:51:34 mapred.Task: Task 'attempt_local876903870_0007_r_000000_0' done.
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: Finishing task: attempt_local876903870_0007_r_000000_0
[INFO] 15/11/14 15:51:34 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/14 15:51:39 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/11/14 15:51:39 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/14 15:51:39 input.FileInputFormat: Total input paths to process : 4
[INFO] 15/11/14 15:51:39 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:39 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/14 15:51:39 mapreduce.JobSubmitter: number of splits:6
[INFO] 15/11/14 15:51:39 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/14 15:51:39 mapreduce.JobSubmitter: Submitting tokens for job: job_local250405341_0008
[WARN] 15/11/14 15:51:39 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny250405341/.staging/job_local250405341_0008/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:39 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny250405341/.staging/job_local250405341_0008/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/14 15:51:39 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local250405341_0008/job_local250405341_0008.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/14 15:51:39 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local250405341_0008/job_local250405341_0008.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/14 15:51:39 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: Starting task: attempt_local250405341_0008_m_000000_0
[INFO] 15/11/14 15:51:39 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:39 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:39 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/OUT_0_O1/O1-r-00001:0+10
[INFO] 15/11/14 15:51:39 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:39 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:39 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:39 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:39 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:39 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:39 mappers.GFMapper1Identity: MapperGFMapper2GuardRelOptimized-00000-0
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:39 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:39 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:39 mapred.MapTask: bufstart = 0; bufend = 16; bufvoid = 104857600
[INFO] 15/11/14 15:51:39 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:39 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:39 mapred.Task: Task:attempt_local250405341_0008_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:39 mapred.Task: Task 'attempt_local250405341_0008_m_000000_0' done.
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: Finishing task: attempt_local250405341_0008_m_000000_0
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: Starting task: attempt_local250405341_0008_m_000001_0
[INFO] 15/11/14 15:51:39 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:39 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:39 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_8_query1.gumbo_G+_1/round1-r-00000:0+7
[INFO] 15/11/14 15:51:39 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:39 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:39 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:39 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:39 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:39 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:39 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:39 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:39 mapred.MapTask: bufstart = 0; bufend = 7; bufvoid = 104857600
[INFO] 15/11/14 15:51:39 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:39 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:39 mapred.Task: Task:attempt_local250405341_0008_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:39 mapred.Task: Task 'attempt_local250405341_0008_m_000001_0' done.
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: Finishing task: attempt_local250405341_0008_m_000001_0
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: Starting task: attempt_local250405341_0008_m_000002_0
[INFO] 15/11/14 15:51:39 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:39 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:39 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_9_query1.gumbo_O1+_1/round1-r-00000:0+7
[INFO] 15/11/14 15:51:39 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:39 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:39 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:39 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:39 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:39 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:39 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:39 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:39 mapred.MapTask: bufstart = 0; bufend = 7; bufvoid = 104857600
[INFO] 15/11/14 15:51:39 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:39 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:39 mapred.Task: Task:attempt_local250405341_0008_m_000002_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:39 mapred.Task: Task 'attempt_local250405341_0008_m_000002_0' done.
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: Finishing task: attempt_local250405341_0008_m_000002_0
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: Starting task: attempt_local250405341_0008_m_000003_0
[INFO] 15/11/14 15:51:39 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:39 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:39 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/0/G/G.txt:0+5
[INFO] 15/11/14 15:51:39 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:39 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:39 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:39 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:39 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:39 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:39 mappers.GFMapper1Identity: MapperGFMapper2GuardCsv-00003-0
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:39 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:39 mapred.MapTask: Spilling map output
[INFO] 15/11/14 15:51:39 mapred.MapTask: bufstart = 0; bufend = 15; bufvoid = 104857600
[INFO] 15/11/14 15:51:39 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
[INFO] 15/11/14 15:51:39 mapred.MapTask: Finished spill 0
[INFO] 15/11/14 15:51:39 mapred.Task: Task:attempt_local250405341_0008_m_000003_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:39 mapred.Task: Task 'attempt_local250405341_0008_m_000003_0' done.
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: Finishing task: attempt_local250405341_0008_m_000003_0
[INFO] 15/11/14 15:51:39 mapred.LocalJobRunner: Starting task: attempt_local250405341_0008_m_000004_0
[INFO] 15/11/14 15:51:39 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:39 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:39 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_8_query1.gumbo_G+_1/part-r-00000:0+0
[INFO] 15/11/14 15:51:39 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:40 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:40 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:40 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:40 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:40 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:40 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:40 mapred.Task: Task:attempt_local250405341_0008_m_000004_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:40 mapred.Task: Task 'attempt_local250405341_0008_m_000004_0' done.
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: Finishing task: attempt_local250405341_0008_m_000004_0
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: Starting task: attempt_local250405341_0008_m_000005_0
[INFO] 15/11/14 15:51:40 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:40 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:40 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151114_155058/tmp/TMP_9_query1.gumbo_O1+_1/part-r-00000:0+0
[INFO] 15/11/14 15:51:40 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/14 15:51:40 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/14 15:51:40 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/14 15:51:40 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/14 15:51:40 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/14 15:51:40 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: 
[INFO] 15/11/14 15:51:40 mapred.MapTask: Starting flush of map output
[INFO] 15/11/14 15:51:40 mapred.Task: Task:attempt_local250405341_0008_m_000005_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: map
[INFO] 15/11/14 15:51:40 mapred.Task: Task 'attempt_local250405341_0008_m_000005_0' done.
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: Finishing task: attempt_local250405341_0008_m_000005_0
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: Starting task: attempt_local250405341_0008_r_000000_0
[INFO] 15/11/14 15:51:40 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:40 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:40 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@d7ea6a9
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/14 15:51:40 reduce.EventFetcher: attempt_local250405341_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/14 15:51:40 reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local250405341_0008_m_000002_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:40 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local250405341_0008_m_000002_0
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
[INFO] 15/11/14 15:51:40 reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local250405341_0008_m_000003_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:40 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local250405341_0008_m_000003_0
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
[INFO] 15/11/14 15:51:40 reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local250405341_0008_m_000000_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:40 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local250405341_0008_m_000000_0
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6
[INFO] 15/11/14 15:51:40 reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local250405341_0008_m_000004_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:40 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local250405341_0008_m_000004_0
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->8
[INFO] 15/11/14 15:51:40 reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local250405341_0008_m_000001_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:40 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local250405341_0008_m_000001_0
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 8, usedMemory ->10
[INFO] 15/11/14 15:51:40 reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local250405341_0008_m_000005_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:40 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local250405341_0008_m_000005_0
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 10, usedMemory ->12
[INFO] 15/11/14 15:51:40 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: 6 / 6 copied.
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: finalMerge called with 6 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/14 15:51:40 mapred.Merger: Merging 6 sorted segments
[INFO] 15/11/14 15:51:40 mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: Merged 6 segments, 12 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/14 15:51:40 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/14 15:51:40 mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: 6 / 6 copied.
[INFO] 15/11/14 15:51:40 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00000-0
[INFO] 15/11/14 15:51:40 mapred.Task: Task:attempt_local250405341_0008_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: 6 / 6 copied.
[INFO] 15/11/14 15:51:40 mapred.Task: Task attempt_local250405341_0008_r_000000_0 is allowed to commit now
[INFO] 15/11/14 15:51:40 output.FileOutputCommitter: Saved output of task 'attempt_local250405341_0008_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/query1.gumbo_O2+O4+_2/_temporary/0/task_local250405341_0008_r_000000
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/14 15:51:40 mapred.Task: Task 'attempt_local250405341_0008_r_000000_0' done.
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: Finishing task: attempt_local250405341_0008_r_000000_0
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: Starting task: attempt_local250405341_0008_r_000001_0
[INFO] 15/11/14 15:51:40 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/14 15:51:40 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/14 15:51:40 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@276bd333
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/14 15:51:40 reduce.EventFetcher: attempt_local250405341_0008_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/14 15:51:40 reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local250405341_0008_m_000002_0 decomp: 11 len: 15 to MEMORY
[INFO] 15/11/14 15:51:40 reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local250405341_0008_m_000002_0
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->11
[INFO] 15/11/14 15:51:40 reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local250405341_0008_m_000003_0 decomp: 19 len: 23 to MEMORY
[INFO] 15/11/14 15:51:40 reduce.InMemoryMapOutput: Read 19 bytes from map-output for attempt_local250405341_0008_m_000003_0
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 19, inMemoryMapOutputs.size() -> 2, commitMemory -> 11, usedMemory ->30
[INFO] 15/11/14 15:51:40 reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local250405341_0008_m_000000_0 decomp: 20 len: 24 to MEMORY
[INFO] 15/11/14 15:51:40 reduce.InMemoryMapOutput: Read 20 bytes from map-output for attempt_local250405341_0008_m_000000_0
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 3, commitMemory -> 30, usedMemory ->50
[INFO] 15/11/14 15:51:40 reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local250405341_0008_m_000004_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:40 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local250405341_0008_m_000004_0
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 50, usedMemory ->52
[INFO] 15/11/14 15:51:40 reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local250405341_0008_m_000001_0 decomp: 11 len: 15 to MEMORY
[INFO] 15/11/14 15:51:40 reduce.InMemoryMapOutput: Read 11 bytes from map-output for attempt_local250405341_0008_m_000001_0
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 11, inMemoryMapOutputs.size() -> 5, commitMemory -> 52, usedMemory ->63
[INFO] 15/11/14 15:51:40 reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local250405341_0008_m_000005_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/14 15:51:40 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local250405341_0008_m_000005_0
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 63, usedMemory ->65
[INFO] 15/11/14 15:51:40 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: 6 / 6 copied.
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: finalMerge called with 6 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/14 15:51:40 mapred.Merger: Merging 6 sorted segments
[INFO] 15/11/14 15:51:40 mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 33 bytes
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: Merged 6 segments, 65 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: Merging 1 files, 59 bytes from disk
[INFO] 15/11/14 15:51:40 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/14 15:51:40 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/14 15:51:40 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 48 bytes
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: 6 / 6 copied.
[INFO] 15/11/14 15:51:40 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00001-0
[INFO] 15/11/14 15:51:40 mapred.Task: Task:attempt_local250405341_0008_r_000001_0 is done. And is in the process of committing
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: 6 / 6 copied.
[INFO] 15/11/14 15:51:40 mapred.Task: Task attempt_local250405341_0008_r_000001_0 is allowed to commit now
[INFO] 15/11/14 15:51:40 output.FileOutputCommitter: Saved output of task 'attempt_local250405341_0008_r_000001_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/query1.gumbo_O2+O4+_2/_temporary/0/task_local250405341_0008_r_000001
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/14 15:51:40 mapred.Task: Task 'attempt_local250405341_0008_r_000001_0' done.
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: Finishing task: attempt_local250405341_0008_r_000001_0
[INFO] 15/11/14 15:51:40 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/14 15:51:44 hadoop.HadoopPartitionQueue: Group is done, moving its output files{
id : 0 Depends on: None. - (O2(x,y,z) : G(x,y,z) & T(x))
id : 1 Depends on: 2, - (O4(x,y,z) : O1(x,y,z) & T(z))
}
[INFO] 15/11/14 15:51:44 hadoop.HadoopPartitionQueue: Moving O2(x0,x1,x2)
To: output/EXP_028/20151114_155058/OUT_2_O2
[INFO] 15/11/14 15:51:44 hadoop.HadoopPartitionQueue: Moving to:  output/EXP_028/20151114_155058/OUT_2_O2
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/query1.gumbo_O2+O4+_2/O2-r-00001
[INFO] 15/11/14 15:51:44 hadoop.HadoopPartitionQueue: Moving O4(x0,x1,x2)
To: output/EXP_028/20151114_155058/OUT_3_O4
[INFO] 15/11/14 15:51:44 hadoop.HadoopPartitionQueue: Moving to:  output/EXP_028/20151114_155058/OUT_3_O4
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151114_155058/query1.gumbo_O2+O4+_2/O4-r-00001
[INFO] 15/11/14 15:51:45 hadoop.HadoopEngine: Partition queue exhausted.
[INFO] 15/11/14 15:51:45 hadoop.HadoopEngine: SUCCESS: all jobs (8) completed!
Running time: 46498ms
Counters for job: query1.gumbo_H+_1
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=4330
	FILE: Number of bytes written=720259
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=2
	Map output records=2
	Map output bytes=16
	Map output materialized bytes=32
	Input split bytes=646
	Combine input records=0
	Combine output records=0
	Reduce input groups=1
	Reduce shuffle bytes=32
	Reduce input records=2
	Reduce output records=0
	Spilled Records=4
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=983040000
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
	ASSERT=1
	ASSERT_BYTES=4
	KEEP_ALIVE_ASSERT=0
	KEEP_ALIVE_ASSERT_BYTES=0
	KEEP_ALIVE_REQUEST=0
	KEEP_ALIVE_REQUEST_BYTES=0
	REQUEST=1
	REQUEST_BYTES=8
	REQUEST_KEY_BYTES=7
	REQUEST_VALUE_BYTES=1
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
	RED1_BUFFEREDITEMS=1
	RED1_OUT_BYTES=5
	RED1_OUT_RECORDS=1
	RED1_PREMATURE_ABORTS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=2
	Map output records=2
	Map output bytes=16
	Map output materialized bytes=32
	Input split bytes=646
	Combine input records=0
	Combine output records=0
	Reduce input groups=1
	Reduce shuffle bytes=32
	Reduce input records=2
	Reduce output records=0
	Spilled Records=4
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=983040000
Counters for job: query1.gumbo_O3+_2
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=15634
	FILE: Number of bytes written=1922603
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=2
	Map output records=2
	Map output bytes=22
	Map output materialized bytes=44
	Input split bytes=992
	Combine input records=0
	Combine output records=0
	Reduce input groups=1
	Reduce shuffle bytes=44
	Reduce input records=2
	Reduce output records=0
	Spilled Records=4
	Shuffled Maps =3
	Failed Shuffles=0
	Merged Map outputs=3
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=2399666176
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
	ASSERT_BYTES=13
	ASSERT_RECORDS=1
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
	RED2_EVAL_FALSE=0
	RED2_EVAL_TRUE=1
	RED2_OUT_BYTES=9
	RED2_OUT_RECORDS=1
	RED2_TUPLES_FOUND=1
	RED2_TUPLE_EXCEPTIONS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=2
	Map output records=2
	Map output bytes=22
	Map output materialized bytes=44
	Input split bytes=992
	Combine input records=0
	Combine output records=0
	Reduce input groups=1
	Reduce shuffle bytes=44
	Reduce input records=2
	Reduce output records=0
	Spilled Records=4
	Shuffled Maps =3
	Failed Shuffles=0
	Merged Map outputs=3
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=2399666176
Counters for job: query1.gumbo_O3+_1
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=18060
	FILE: Number of bytes written=2249420
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=3
	Map output records=3
	Map output bytes=22
	Map output materialized bytes=40
	Input split bytes=670
	Combine input records=0
	Combine output records=0
	Reduce input groups=2
	Reduce shuffle bytes=40
	Reduce input records=3
	Reduce output records=0
	Spilled Records=6
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=2563768320
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
	ASSERT=2
	ASSERT_BYTES=8
	KEEP_ALIVE_ASSERT=0
	KEEP_ALIVE_ASSERT_BYTES=0
	KEEP_ALIVE_REQUEST=0
	KEEP_ALIVE_REQUEST_BYTES=0
	REQUEST=1
	REQUEST_BYTES=8
	REQUEST_KEY_BYTES=7
	REQUEST_VALUE_BYTES=1
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
	RED1_BUFFEREDITEMS=1
	RED1_OUT_BYTES=5
	RED1_OUT_RECORDS=1
	RED1_PREMATURE_ABORTS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=3
	Map output records=3
	Map output bytes=22
	Map output materialized bytes=40
	Input split bytes=670
	Combine input records=0
	Combine output records=0
	Reduce input groups=2
	Reduce shuffle bytes=40
	Reduce input records=3
	Reduce output records=0
	Spilled Records=6
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=2563768320
Counters for job: query1.gumbo_R+_1
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=22686
	FILE: Number of bytes written=2885050
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=3
	Map output records=3
	Map output bytes=22
	Map output materialized bytes=40
	Input split bytes=646
	Combine input records=0
	Combine output records=0
	Reduce input groups=2
	Reduce shuffle bytes=40
	Reduce input records=3
	Reduce output records=0
	Spilled Records=6
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=3180331008
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
	ASSERT=2
	ASSERT_BYTES=8
	KEEP_ALIVE_ASSERT=0
	KEEP_ALIVE_ASSERT_BYTES=0
	KEEP_ALIVE_REQUEST=0
	KEEP_ALIVE_REQUEST_BYTES=0
	REQUEST=1
	REQUEST_BYTES=8
	REQUEST_KEY_BYTES=7
	REQUEST_VALUE_BYTES=1
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
	RED1_BUFFEREDITEMS=1
	RED1_OUT_BYTES=5
	RED1_OUT_RECORDS=1
	RED1_PREMATURE_ABORTS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=3
	Map output records=3
	Map output bytes=22
	Map output materialized bytes=40
	Input split bytes=646
	Combine input records=0
	Combine output records=0
	Reduce input groups=2
	Reduce shuffle bytes=40
	Reduce input records=3
	Reduce output records=0
	Spilled Records=6
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=3180331008
Counters for job: query1.gumbo_O1+O5+_2
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=116291
	FILE: Number of bytes written=9641433
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=4
	Map output records=4
	Map output bytes=45
	Map output materialized bytes=125
	Input split bytes=2010
	Combine input records=0
	Combine output records=0
	Reduce input groups=2
	Reduce shuffle bytes=125
	Reduce input records=4
	Reduce output records=0
	Spilled Records=8
	Shuffled Maps =12
	Failed Shuffles=0
	Merged Map outputs=12
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=12239503360
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
	ASSERT_BYTES=27
	ASSERT_RECORDS=2
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
	RED2_EVAL_FALSE=0
	RED2_EVAL_TRUE=2
	RED2_OUT_BYTES=18
	RED2_OUT_RECORDS=2
	RED2_TUPLES_FOUND=2
	RED2_TUPLE_EXCEPTIONS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=16
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=4
	Map output records=4
	Map output bytes=45
	Map output materialized bytes=125
	Input split bytes=2010
	Combine input records=0
	Combine output records=0
	Reduce input groups=2
	Reduce shuffle bytes=125
	Reduce input records=4
	Reduce output records=0
	Spilled Records=8
	Shuffled Maps =12
	Failed Shuffles=0
	Merged Map outputs=12
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=12239503360
Counters for job: query1.gumbo_G+_1
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=58212
	FILE: Number of bytes written=4903426
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=3
	Map output records=3
	Map output bytes=22
	Map output materialized bytes=40
	Input split bytes=646
	Combine input records=0
	Combine output records=0
	Reduce input groups=2
	Reduce shuffle bytes=40
	Reduce input records=3
	Reduce output records=0
	Spilled Records=6
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=6025641984
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
	ASSERT=2
	ASSERT_BYTES=8
	KEEP_ALIVE_ASSERT=0
	KEEP_ALIVE_ASSERT_BYTES=0
	KEEP_ALIVE_REQUEST=0
	KEEP_ALIVE_REQUEST_BYTES=0
	REQUEST=1
	REQUEST_BYTES=8
	REQUEST_KEY_BYTES=7
	REQUEST_VALUE_BYTES=1
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
	RED1_BUFFEREDITEMS=1
	RED1_OUT_BYTES=5
	RED1_OUT_RECORDS=1
	RED1_PREMATURE_ABORTS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=3
	Map output records=3
	Map output bytes=22
	Map output materialized bytes=40
	Input split bytes=646
	Combine input records=0
	Combine output records=0
	Reduce input groups=2
	Reduce shuffle bytes=40
	Reduce input records=3
	Reduce output records=0
	Spilled Records=6
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=6025641984
Counters for job: query1.gumbo_O1+_1
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=60769
	FILE: Number of bytes written=5058065
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=3
	Map output records=3
	Map output bytes=22
	Map output materialized bytes=40
	Input split bytes=670
	Combine input records=0
	Combine output records=0
	Reduce input groups=2
	Reduce shuffle bytes=40
	Reduce input records=3
	Reduce output records=0
	Spilled Records=6
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=19
	Total committed heap usage (bytes)=6468665344
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
	ASSERT=2
	ASSERT_BYTES=8
	KEEP_ALIVE_ASSERT=0
	KEEP_ALIVE_ASSERT_BYTES=0
	KEEP_ALIVE_REQUEST=0
	KEEP_ALIVE_REQUEST_BYTES=0
	REQUEST=1
	REQUEST_BYTES=8
	REQUEST_KEY_BYTES=7
	REQUEST_VALUE_BYTES=1
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
	RED1_BUFFEREDITEMS=1
	RED1_OUT_BYTES=5
	RED1_OUT_RECORDS=1
	RED1_PREMATURE_ABORTS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=3
	Map output records=3
	Map output bytes=22
	Map output materialized bytes=40
	Input split bytes=670
	Combine input records=0
	Combine output records=0
	Reduce input groups=2
	Reduce shuffle bytes=40
	Reduce input records=3
	Reduce output records=0
	Spilled Records=6
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=19
	Total committed heap usage (bytes)=6468665344
Counters for job: query1.gumbo_O2+O4+_2
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=218003
	FILE: Number of bytes written=15429865
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=4
	Map output records=4
	Map output bytes=45
	Map output materialized bytes=125
	Input split bytes=2010
	Combine input records=0
	Combine output records=0
	Reduce input groups=2
	Reduce shuffle bytes=125
	Reduce input records=4
	Reduce output records=0
	Spilled Records=8
	Shuffled Maps =12
	Failed Shuffles=0
	Merged Map outputs=12
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=21177565184
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
	ASSERT_BYTES=27
	ASSERT_RECORDS=2
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
	RED2_EVAL_FALSE=0
	RED2_EVAL_TRUE=2
	RED2_OUT_BYTES=18
	RED2_OUT_RECORDS=2
	RED2_TUPLES_FOUND=2
	RED2_TUPLE_EXCEPTIONS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=16
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=4
	Map output records=4
	Map output bytes=45
	Map output materialized bytes=125
	Input split bytes=2010
	Combine input records=0
	Combine output records=0
	Reduce input groups=2
	Reduce shuffle bytes=125
	Reduce input records=4
	Reduce output records=0
	Spilled Records=8
	Shuffled Maps =12
	Failed Shuffles=0
	Merged Map outputs=12
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=21177565184

Overall Counters
--------------------------------------------------------------------------------
File System Counters
	FILE: Number of bytes read=513985
	FILE: Number of bytes written=42810121
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
	Map input records=48
	Map output records=48
	Map output bytes=432
	Map output materialized bytes=972
	Input split bytes=16580
	Combine input records=0
	Combine output records=0
	Reduce input groups=28
	Reduce shuffle bytes=972
	Reduce input records=48
	Reduce output records=0
	Spilled Records=96
	Shuffled Maps =74
	Failed Shuffles=0
	Merged Map outputs=74
	GC time elapsed (ms)=38
	Total committed heap usage (bytes)=110076362752
File Input Format Counters 
	Bytes Read=0
File Output Format Counters 
	Bytes Written=80

