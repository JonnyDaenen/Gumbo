gumbo.engine.guardAddressOptimizationOn=true
gumbo.engine.proofsymbol=#
gumbo.engine.mapOutputGroupingPolicy=ALLGROUP
gumbo.engine.guardedCombinerOptimizationOn=false
gumbo.engine.assertConstantOptimizationOn=true
gumbo.compiler.partitioner=gumbo.compiler.partitioner.HeightPartitioner
gumbo.engine.round1FiniteMemoryOptimizationOn=false
gumbo.engine.hadoop.reducersize_mb=1024
gumbo.engine.reduceOutputGroupingOptimizationOn=true
gumbo.engine.mapOutputGroupingOptimizationOn=true
gumbo.engine.grouper.beststopindicator=0
gumbo.engine.requestAtomIdOptimizationOn=true
gumbo.engine.guardKeepAliveOptimizationOn=true
[INFO] 15/12/03 19:53:37 gumbo.Gumbo: Input: 
R(x0,x1,x2,x3);input/experiments/EXP_029/2/R;csv;'S(x0);input/experiments/EXP_029/2/S;csv;'T(x0);input/experiments/EXP_029/2/T;csv;'U(x0);input/experiments/EXP_029/2/U;csv;'V(x0);input/experiments/EXP_029/2/V;csv;
Output: output/EXP_029
Scratch: scratch/EXP_029
Queries: 
[(Out1(x) : R(x,y,z,w) & (S(x) | (T(x) | (U(x) | V(x)))))]

[INFO] 15/12/03 19:53:37 compiler.GFCompiler: Adding suffix to scratch and output paths: /20151203_195337
[INFO] 15/12/03 19:53:37 compiler.GFCompiler: Decomposing GFEs into basic GFEs (BGFEs)...
[INFO] 15/12/03 19:53:37 compiler.GFCompiler: Number of BGFEs: 1
[INFO] 15/12/03 19:53:37 compiler.GFCompiler: Converting BGFEs into CalculationUnits (CUs)...
[INFO] 15/12/03 19:53:37 compiler.GFCompiler: Number of CUs: 1
[INFO] 15/12/03 19:53:37 compiler.GFCompiler: Linking Calculation Units (CUs)...
[INFO] 15/12/03 19:53:37 compiler.GFCompiler: Creating initial file mapping...
[INFO] 15/12/03 19:53:37 compiler.GFCompiler: file mapping:
Out root: output/EXP_029/20151203_195337
Scratch root: scratch/EXP_029/20151203_195337
Temp root: scratch/EXP_029/20151203_195337/tmp
R(x0,x1,x2,x3) <- [input/experiments/EXP_029/2/R]
S(x0) <- [input/experiments/EXP_029/2/S]
T(x0) <- [input/experiments/EXP_029/2/T]
U(x0) <- [input/experiments/EXP_029/2/U]
V(x0) <- [input/experiments/EXP_029/2/V]
Out1(x0) -> [output/EXP_029/20151203_195337/OUT_0_Out1]
Temp dirs: 

[INFO] 15/12/03 19:53:37 compiler.GFCompiler: Partitioning...
[INFO] 15/12/03 19:53:37 compiler.GFCompiler: Number of partitions: 1

Query:
query2.gumbo

Partitions:
-----------
Calculation Unit Partitions: {
{id : 0 Depends on: None. - (Out1(x) : R(x,y,z,w) & (S(x) | (T(x) | (U(x) | V(x)))))}
}
Folders:
-------
Out root: output/EXP_029/20151203_195337
Scratch root: scratch/EXP_029/20151203_195337
Temp root: scratch/EXP_029/20151203_195337/tmp
R(x0,x1,x2,x3) <- [input/experiments/EXP_029/2/R]
S(x0) <- [input/experiments/EXP_029/2/S]
T(x0) <- [input/experiments/EXP_029/2/T]
U(x0) <- [input/experiments/EXP_029/2/U]
V(x0) <- [input/experiments/EXP_029/2/V]
Out1(x0) -> [output/EXP_029/20151203_195337/OUT_0_Out1]
Temp dirs: 

[INFO] 15/12/03 19:53:37 hadoop2.HadoopEngine2: Creating Job Control for: query2.gumbo
[INFO] 15/12/03 19:53:37 hadoop2.HadoopEngine2: Starting Job-control thread: Gumbo-Workflow-Thread_query2.gumbo
[WARN] 15/12/03 19:53:37 util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 15/12/03 19:53:37 hadoop2.HadoopEngine2: Using 1-round evaluation for Calculation Unit Partitions: {
{id : 0 Depends on: None. - (Out1(x) : R(x,y,z,w) & (S(x) | (T(x) | (U(x) | V(x)))))}
}
[INFO] 15/12/03 19:53:37 hadoop2.MultiRoundConverter: Adding path input/experiments/EXP_029/2/R to mapper
[INFO] 15/12/03 19:53:37 hadoop2.MultiRoundConverter: Adding path input/experiments/EXP_029/2/S to mapper
[INFO] 15/12/03 19:53:37 hadoop2.MultiRoundConverter: Adding path input/experiments/EXP_029/2/T to mapper
[INFO] 15/12/03 19:53:37 hadoop2.MultiRoundConverter: Adding path input/experiments/EXP_029/2/U to mapper
[INFO] 15/12/03 19:53:37 hadoop2.MultiRoundConverter: Adding path input/experiments/EXP_029/2/V to mapper
[INFO] 15/12/03 19:53:37 hadoop2.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
Adding output paths
[INFO] 15/12/03 19:53:37 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/03 19:53:42 Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO] 15/12/03 19:53:42 jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN] 15/12/03 19:53:42 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/03 19:53:42 input.FileInputFormat: Total input paths to process : 5
[INFO] 15/12/03 19:53:42 mapreduce.JobSubmitter: number of splits:5
[INFO] 15/12/03 19:53:42 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/03 19:53:43 mapreduce.JobSubmitter: Submitting tokens for job: job_local1267198169_0001
[WARN] 15/12/03 19:53:43 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1267198169/.staging/job_local1267198169_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/03 19:53:43 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1267198169/.staging/job_local1267198169_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/03 19:53:43 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1267198169_0001/job_local1267198169_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/03 19:53:43 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1267198169_0001/job_local1267198169_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/03 19:53:43 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/03 19:53:43 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/03 19:53:43 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/03 19:53:43 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/03 19:53:43 mapred.LocalJobRunner: Starting task: attempt_local1267198169_0001_m_000000_0
[INFO] 15/12/03 19:53:43 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/03 19:53:43 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/03 19:53:43 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_029/2/R/R.txt:0+19
[INFO] 15/12/03 19:53:43 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/03 19:53:43 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/03 19:53:43 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/03 19:53:43 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/03 19:53:43 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/03 19:53:43 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/03 19:53:49 mapred.LocalJobRunner: map > map
[INFO] 15/12/03 19:55:28 mapred.LocalJobRunner: map > map
[INFO] 15/12/03 19:55:37 mapred.LocalJobRunner: map > map
[INFO] 15/12/03 20:03:31 mapred.LocalJobRunner: map > map
