gumbo.engine.guardAddressOptimizationOn=true
gumbo.engine.proofsymbol=#
gumbo.engine.mapOutputGroupingPolicy=COSTGROUP_GUMBO
gumbo.engine.guardedCombinerOptimizationOn=false
gumbo.engine.assertConstantOptimizationOn=true
gumbo.compiler.partitioner=gumbo.compiler.partitioner.GreedyPartitioner
gumbo.engine.round1FiniteMemoryOptimizationOn=false
gumbo.engine.hadoop.reducersize_mb=1024
gumbo.engine.reduceOutputGroupingOptimizationOn=true
gumbo.engine.mapOutputGroupingOptimizationOn=true
gumbo.engine.grouper.beststopindicator=0
gumbo.engine.requestAtomIdOptimizationOn=true
gumbo.engine.guardKeepAliveOptimizationOn=true
[INFO] 15/11/15 12:20:33 gumbo.Gumbo: Input: 
R(x0,x1,x2);input/experiments/EXP_028/1/R;csv;'S(x0);input/experiments/EXP_028/1/S;csv;'T(x0);input/experiments/EXP_028/1/T;csv;'U(x0);input/experiments/EXP_028/1/U;csv;'G(x0,x1,x2);input/experiments/EXP_028/1/G;csv;'H(x0,x1,x2);input/experiments/EXP_028/1/H;csv;
Output: output/EXP_028
Scratch: scratch/EXP_028
Queries: 
[(O11(x,y,z) : R(x,y,z) & S(x)), (O22(x,y,z) : O12(x,y,z) & U(z)), (O23(x,y,z) : O13(x,y,z) & S(z)), (O12(x,y,z) : G(x,y,z) & T(x)), (O13(x,y,z) : H(x,y,z) & U(x)), (O21(x,y,z) : O11(x,y,z) & T(z))]

[INFO] 15/11/15 12:20:33 compiler.GFCompiler: Adding suffix to scratch and output paths: /20151115_122033
[INFO] 15/11/15 12:20:33 compiler.GFCompiler: Decomposing GFEs into basic GFEs (BGFEs)...
[INFO] 15/11/15 12:20:33 compiler.GFCompiler: Number of BGFEs: 6
[INFO] 15/11/15 12:20:33 compiler.GFCompiler: Converting BGFEs into CalculationUnits (CUs)...
[INFO] 15/11/15 12:20:33 compiler.GFCompiler: Number of CUs: 6
[INFO] 15/11/15 12:20:33 compiler.GFCompiler: Linking Calculation Units (CUs)...
[INFO] 15/11/15 12:20:33 compiler.GFCompiler: Creating initial file mapping...
[INFO] 15/11/15 12:20:33 compiler.GFCompiler: file mapping:
Out root: output/EXP_028/20151115_122033
Scratch root: scratch/EXP_028/20151115_122033
Temp root: scratch/EXP_028/20151115_122033/tmp
R(x0,x1,x2) <- [input/experiments/EXP_028/1/R]
S(x0) <- [input/experiments/EXP_028/1/S]
T(x0) <- [input/experiments/EXP_028/1/T]
U(x0) <- [input/experiments/EXP_028/1/U]
G(x0,x1,x2) <- [input/experiments/EXP_028/1/G]
H(x0,x1,x2) <- [input/experiments/EXP_028/1/H]
O13(x0,x1,x2) -> [output/EXP_028/20151115_122033/OUT_0_O13]
O12(x0,x1,x2) -> [output/EXP_028/20151115_122033/OUT_1_O12]
O23(x0,x1,x2) -> [output/EXP_028/20151115_122033/OUT_3_O23]
O11(x0,x1,x2) -> [output/EXP_028/20151115_122033/OUT_2_O11]
O22(x0,x1,x2) -> [output/EXP_028/20151115_122033/OUT_4_O22]
O21(x0,x1,x2) -> [output/EXP_028/20151115_122033/OUT_5_O21]
Temp dirs: 

[INFO] 15/11/15 12:20:33 compiler.GFCompiler: Partitioning...
[INFO] 15/11/15 12:20:33 compiler.GFCompiler: Number of partitions: 4

Query:
query2.gumbo

Partitions:
-----------
Calculation Unit Partitions: {
{id : 0 Depends on: None. - (O11(x,y,z) : R(x,y,z) & S(x))}
{id : 4 Depends on: None. - (O12(x,y,z) : G(x,y,z) & T(x))id : 5 Depends on: 0, - (O21(x,y,z) : O11(x,y,z) & T(z))}
{id : 2 Depends on: None. - (O13(x,y,z) : H(x,y,z) & U(x))id : 3 Depends on: 4, - (O22(x,y,z) : O12(x,y,z) & U(z))}
{id : 1 Depends on: 2, - (O23(x,y,z) : O13(x,y,z) & S(z))}
}
Folders:
-------
Out root: output/EXP_028/20151115_122033
Scratch root: scratch/EXP_028/20151115_122033
Temp root: scratch/EXP_028/20151115_122033/tmp
R(x0,x1,x2) <- [input/experiments/EXP_028/1/R]
S(x0) <- [input/experiments/EXP_028/1/S]
T(x0) <- [input/experiments/EXP_028/1/T]
U(x0) <- [input/experiments/EXP_028/1/U]
G(x0,x1,x2) <- [input/experiments/EXP_028/1/G]
H(x0,x1,x2) <- [input/experiments/EXP_028/1/H]
O13(x0,x1,x2) -> [output/EXP_028/20151115_122033/OUT_0_O13]
O12(x0,x1,x2) -> [output/EXP_028/20151115_122033/OUT_1_O12]
O23(x0,x1,x2) -> [output/EXP_028/20151115_122033/OUT_3_O23]
O11(x0,x1,x2) -> [output/EXP_028/20151115_122033/OUT_2_O11]
O22(x0,x1,x2) -> [output/EXP_028/20151115_122033/OUT_4_O22]
O21(x0,x1,x2) -> [output/EXP_028/20151115_122033/OUT_5_O21]
Temp dirs: 

[WARN] 15/11/15 12:20:33 util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 15/11/15 12:20:33 hadoop.HadoopEngine: Creating Job Control for: query2.gumbo
[INFO] 15/11/15 12:20:33 hadoop.HadoopEngine: Starting Job-control thread: Gumbo-Workflow-Thread_query2.gumbo
[INFO] 15/11/15 12:20:33 hadoop.HadoopEngine: Processing partition queue.
[INFO] 15/11/15 12:20:33 utils.PartitionQueue: Calculation group {
id : 0 Depends on: None. - (O11(x,y,z) : R(x,y,z) & S(x))
} is ready to be scheduled.
Adding output paths
[INFO] 15/11/15 12:20:33 sample.RelationSampler: Fetching samples for relation R(x0,x1,x2)
[INFO] 15/11/15 12:20:33 sample.RelationSampler: Fetching samples for relation S(x0)
[INFO] 15/11/15 12:20:33 sample.RelationSampler: Fetching samples for relation T(x0)
[INFO] 15/11/15 12:20:33 sample.RelationSampler: Fetching samples for relation U(x0)
[INFO] 15/11/15 12:20:33 sample.RelationSampler: Fetching samples for relation G(x0,x1,x2)
[INFO] 15/11/15 12:20:33 sample.RelationSampler: Fetching samples for relation H(x0,x1,x2)
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Parsing samples for relation R(x0,x1,x2)
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Small tuples: 279
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Big tuples: 2513
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Parsing samples for relation S(x0)
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Small tuples: 837
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Big tuples: 6872
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Parsing samples for relation T(x0)
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Small tuples: 837
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Big tuples: 6481
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Parsing samples for relation U(x0)
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Small tuples: 839
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Big tuples: 7431
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Parsing samples for relation G(x0,x1,x2)
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Small tuples: 278
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Big tuples: 2512
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Parsing samples for relation H(x0,x1,x2)
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Small tuples: 279
[INFO] 15/11/15 12:20:33 reporter.RelationTupleSampleContainer: Big tuples: 2519
[INFO] 15/11/15 12:20:33 grouper.GrouperFactory: Creating a grouper with policy COSTGROUP_GUMBO
[WARN] 15/11/15 12:20:33 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
Adding output paths
[INFO] 15/11/15 12:20:33 grouper.Grouper: Decomposition complete: 	R(x,y,z) |X S(x)
	Guard In Bytes0
	Guarded In Bytes0
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:0.0

[INFO] 15/11/15 12:20:33 sample.Simulator: Simulating relation R(x0,x1,x2)
[INFO] 15/11/15 12:20:33 sample.Simulator: Simulating relation S(x0)
[INFO] 15/11/15 12:20:33 grouper.Grouper: Grouping complete: 1 group(s)
[INFO] 15/11/15 12:20:33 grouper.Grouper: Grouping: [	R(x,y,z) |X S(x)
	Guard In Bytes146610
	Guarded In Bytes48928
	Guard Out Bytes123778
	Guarded Out Bytes68946
	Cost:50.84709992744766
]
[WARN] 15/11/15 12:20:33 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
[INFO] 15/11/15 12:20:33 converter.GumboHadoopConverter: Intermediate data size: 0.18379592895507812 MB
[INFO] 15/11/15 12:20:33 converter.GumboHadoopConverter: Num reducers: 1
[INFO] 15/11/15 12:20:33 converter.GumboHadoopConverter: R(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/R/R.txt;csv;'S(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/S/S.txt;csv;'T(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/T/T.txt;csv;'U(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/U/U.txt;csv;'G(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/G/G.txt;csv;'H(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/H/H.txt;csv;
[INFO] 15/11/15 12:20:33 converter.GumboHadoopConverter: Setting M1 guarded path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/S/S.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardedCsv
[INFO] 15/11/15 12:20:33 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/R/R.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardCsv
[INFO] 15/11/15 12:20:33 converter.GumboHadoopConverter: Setting Reduce tasks to 1
Adding output paths
[INFO] 15/11/15 12:20:33 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/R/R.txt using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardCsv
[INFO] 15/11/15 12:20:33 converter.GumboHadoopConverter: Adding M2 normal path file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_6_query2.gumbo_R+_1 using identity mapper 
[INFO] 15/11/15 12:20:33 converter.Round2ReduceJobEstimator: Output estimate 100663296
[INFO] 15/11/15 12:20:33 converter.Round2ReduceJobEstimator: Reducer estimate 1
[INFO] 15/11/15 12:20:38 Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO] 15/11/15 12:20:38 jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN] 15/11/15 12:20:38 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/15 12:20:38 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/15 12:20:38 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/15 12:20:38 mapreduce.JobSubmitter: number of splits:2
[INFO] 15/11/15 12:20:38 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/15 12:20:38 mapreduce.JobSubmitter: Submitting tokens for job: job_local522607787_0001
[WARN] 15/11/15 12:20:38 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny522607787/.staging/job_local522607787_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:20:38 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny522607787/.staging/job_local522607787_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/15 12:20:38 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local522607787_0001/job_local522607787_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:20:38 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local522607787_0001/job_local522607787_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/15 12:20:38 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/15 12:20:38 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/15 12:20:38 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/15 12:20:38 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/15 12:20:38 mapred.LocalJobRunner: Starting task: attempt_local522607787_0001_m_000000_0
[INFO] 15/11/15 12:20:38 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:38 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:38 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/R/R.txt:0+146610
[INFO] 15/11/15 12:20:38 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:20:38 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:20:38 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:20:38 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:20:38 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:20:38 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:20:38 mappers.GFMapper1Identity: MapperGFMapper1GuardCsv-00000-0
[INFO] 15/11/15 12:20:38 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:20:38 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:20:38 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:20:38 mapred.MapTask: bufstart = 0; bufend = 148604; bufvoid = 104857600
[INFO] 15/11/15 12:20:38 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/11/15 12:20:38 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:20:38 mapred.Task: Task:attempt_local522607787_0001_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:38 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:20:38 mapred.Task: Task 'attempt_local522607787_0001_m_000000_0' done.
[INFO] 15/11/15 12:20:38 mapred.LocalJobRunner: Finishing task: attempt_local522607787_0001_m_000000_0
[INFO] 15/11/15 12:20:38 mapred.LocalJobRunner: Starting task: attempt_local522607787_0001_m_000001_0
[INFO] 15/11/15 12:20:38 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:38 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:38 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/S/S.txt:0+48928
[INFO] 15/11/15 12:20:38 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:20:38 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:20:38 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:20:38 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:20:38 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:20:38 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:20:38 mappers.GFMapper1Identity: MapperGFMapper1GuardedCsv-00001-0
[INFO] 15/11/15 12:20:38 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:20:38 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:20:38 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:20:38 mapred.MapTask: bufstart = 0; bufend = 88928; bufvoid = 104857600
[INFO] 15/11/15 12:20:38 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/11/15 12:20:39 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:20:39 mapred.Task: Task:attempt_local522607787_0001_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:39 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:20:39 mapred.Task: Task 'attempt_local522607787_0001_m_000001_0' done.
[INFO] 15/11/15 12:20:39 mapred.LocalJobRunner: Finishing task: attempt_local522607787_0001_m_000001_0
[INFO] 15/11/15 12:20:39 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/15 12:20:39 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/15 12:20:39 mapred.LocalJobRunner: Starting task: attempt_local522607787_0001_r_000000_0
[INFO] 15/11/15 12:20:39 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:39 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:39 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5e603c01
[INFO] 15/11/15 12:20:39 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:20:39 reduce.EventFetcher: attempt_local522607787_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:20:39 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local522607787_0001_m_000000_0 decomp: 168606 len: 168610 to MEMORY
[INFO] 15/11/15 12:20:39 reduce.InMemoryMapOutput: Read 168606 bytes from map-output for attempt_local522607787_0001_m_000000_0
[INFO] 15/11/15 12:20:39 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 168606, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->168606
[INFO] 15/11/15 12:20:39 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local522607787_0001_m_000001_0 decomp: 108930 len: 108934 to MEMORY
[INFO] 15/11/15 12:20:39 reduce.InMemoryMapOutput: Read 108930 bytes from map-output for attempt_local522607787_0001_m_000001_0
[INFO] 15/11/15 12:20:39 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 108930, inMemoryMapOutputs.size() -> 2, commitMemory -> 168606, usedMemory ->277536
[INFO] 15/11/15 12:20:39 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:20:39 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/15 12:20:39 reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:20:39 mapred.Merger: Merging 2 sorted segments
[INFO] 15/11/15 12:20:39 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 277528 bytes
[INFO] 15/11/15 12:20:39 reduce.MergeManagerImpl: Merged 2 segments, 277536 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:20:39 reduce.MergeManagerImpl: Merging 1 files, 277538 bytes from disk
[INFO] 15/11/15 12:20:39 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:20:39 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:20:39 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 277530 bytes
[INFO] 15/11/15 12:20:39 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/15 12:20:39 Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[INFO] 15/11/15 12:20:39 reducers.GFReducer1Optimized: ReducerGFReducer1Optimized-00000-0
[INFO] 15/11/15 12:20:39 mapred.Task: Task:attempt_local522607787_0001_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:39 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/11/15 12:20:39 mapred.Task: Task attempt_local522607787_0001_r_000000_0 is allowed to commit now
[INFO] 15/11/15 12:20:39 output.FileOutputCommitter: Saved output of task 'attempt_local522607787_0001_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_6_query2.gumbo_R+_1/_temporary/0/task_local522607787_0001_r_000000
[INFO] 15/11/15 12:20:39 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:20:39 mapred.Task: Task 'attempt_local522607787_0001_r_000000_0' done.
[INFO] 15/11/15 12:20:39 mapred.LocalJobRunner: Finishing task: attempt_local522607787_0001_r_000000_0
[INFO] 15/11/15 12:20:39 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/15 12:20:43 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/11/15 12:20:43 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/15 12:20:43 input.FileInputFormat: Total input paths to process : 2
[INFO] 15/11/15 12:20:43 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/15 12:20:43 mapreduce.JobSubmitter: number of splits:3
[INFO] 15/11/15 12:20:43 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/15 12:20:43 mapreduce.JobSubmitter: Submitting tokens for job: job_local1579159756_0002
[WARN] 15/11/15 12:20:43 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1579159756/.staging/job_local1579159756_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:20:43 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1579159756/.staging/job_local1579159756_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/15 12:20:43 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1579159756_0002/job_local1579159756_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:20:43 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1579159756_0002/job_local1579159756_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/15 12:20:43 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/15 12:20:43 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/15 12:20:43 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/15 12:20:43 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/15 12:20:43 mapred.LocalJobRunner: Starting task: attempt_local1579159756_0002_m_000000_0
[INFO] 15/11/15 12:20:43 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:43 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:43 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/R/R.txt:0+146610
[INFO] 15/11/15 12:20:43 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:20:43 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:20:43 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:20:43 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:20:43 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:20:43 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:20:43 mappers.GFMapper1Identity: MapperGFMapper2GuardCsv-00000-0
[INFO] 15/11/15 12:20:43 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:20:43 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:20:43 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:20:43 mapred.MapTask: bufstart = 0; bufend = 256326; bufvoid = 104857600
[INFO] 15/11/15 12:20:43 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/11/15 12:20:43 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:20:43 mapred.Task: Task:attempt_local1579159756_0002_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:43 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:20:43 mapred.Task: Task 'attempt_local1579159756_0002_m_000000_0' done.
[INFO] 15/11/15 12:20:43 mapred.LocalJobRunner: Finishing task: attempt_local1579159756_0002_m_000000_0
[INFO] 15/11/15 12:20:43 mapred.LocalJobRunner: Starting task: attempt_local1579159756_0002_m_000001_0
[INFO] 15/11/15 12:20:43 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:43 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:43 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_6_query2.gumbo_R+_1/round1-r-00000:0+56190
[INFO] 15/11/15 12:20:43 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:20:43 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:20:43 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:20:43 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:20:43 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:20:43 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:20:43 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:20:43 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:20:43 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:20:43 mapred.MapTask: bufstart = 0; bufend = 56190; bufvoid = 104857600
[INFO] 15/11/15 12:20:43 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26189352(104757408); length = 25045/6553600
[INFO] 15/11/15 12:20:43 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:20:43 mapred.Task: Task:attempt_local1579159756_0002_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:43 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:20:43 mapred.Task: Task 'attempt_local1579159756_0002_m_000001_0' done.
[INFO] 15/11/15 12:20:43 mapred.LocalJobRunner: Finishing task: attempt_local1579159756_0002_m_000001_0
[INFO] 15/11/15 12:20:43 mapred.LocalJobRunner: Starting task: attempt_local1579159756_0002_m_000002_0
[INFO] 15/11/15 12:20:43 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:43 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:43 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_6_query2.gumbo_R+_1/part-r-00000:0+0
[INFO] 15/11/15 12:20:43 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:20:44 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:20:44 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:20:44 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:20:44 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:20:44 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:20:44 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:20:44 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:20:44 mapred.Task: Task:attempt_local1579159756_0002_m_000002_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:44 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:20:44 mapred.Task: Task 'attempt_local1579159756_0002_m_000002_0' done.
[INFO] 15/11/15 12:20:44 mapred.LocalJobRunner: Finishing task: attempt_local1579159756_0002_m_000002_0
[INFO] 15/11/15 12:20:44 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/15 12:20:44 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/15 12:20:44 mapred.LocalJobRunner: Starting task: attempt_local1579159756_0002_r_000000_0
[INFO] 15/11/15 12:20:44 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:44 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:44 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5982bc88
[INFO] 15/11/15 12:20:44 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:20:44 reduce.EventFetcher: attempt_local1579159756_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:20:44 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1579159756_0002_m_000002_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/15 12:20:44 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1579159756_0002_m_000002_0
[INFO] 15/11/15 12:20:44 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
[INFO] 15/11/15 12:20:44 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1579159756_0002_m_000000_0 decomp: 276328 len: 276332 to MEMORY
[INFO] 15/11/15 12:20:44 reduce.InMemoryMapOutput: Read 276328 bytes from map-output for attempt_local1579159756_0002_m_000000_0
[INFO] 15/11/15 12:20:44 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 276328, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->276330
[INFO] 15/11/15 12:20:44 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1579159756_0002_m_000001_0 decomp: 68716 len: 68720 to MEMORY
[INFO] 15/11/15 12:20:44 reduce.InMemoryMapOutput: Read 68716 bytes from map-output for attempt_local1579159756_0002_m_000001_0
[INFO] 15/11/15 12:20:44 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 68716, inMemoryMapOutputs.size() -> 3, commitMemory -> 276330, usedMemory ->345046
[INFO] 15/11/15 12:20:44 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:20:44 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/11/15 12:20:44 reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:20:44 mapred.Merger: Merging 3 sorted segments
[INFO] 15/11/15 12:20:44 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 345028 bytes
[INFO] 15/11/15 12:20:44 reduce.MergeManagerImpl: Merged 3 segments, 345046 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:20:44 reduce.MergeManagerImpl: Merging 1 files, 345046 bytes from disk
[INFO] 15/11/15 12:20:44 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:20:44 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:20:44 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 345034 bytes
[INFO] 15/11/15 12:20:44 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/11/15 12:20:44 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00000-0
[INFO] 15/11/15 12:20:44 mapred.Task: Task:attempt_local1579159756_0002_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:44 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/11/15 12:20:44 mapred.Task: Task attempt_local1579159756_0002_r_000000_0 is allowed to commit now
[INFO] 15/11/15 12:20:44 output.FileOutputCommitter: Saved output of task 'attempt_local1579159756_0002_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O11+_2/_temporary/0/task_local1579159756_0002_r_000000
[INFO] 15/11/15 12:20:44 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:20:44 mapred.Task: Task 'attempt_local1579159756_0002_r_000000_0' done.
[INFO] 15/11/15 12:20:44 mapred.LocalJobRunner: Finishing task: attempt_local1579159756_0002_r_000000_0
[INFO] 15/11/15 12:20:44 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/15 12:20:48 hadoop.HadoopPartitionQueue: Group is done, moving its output files{
id : 0 Depends on: None. - (O11(x,y,z) : R(x,y,z) & S(x))
}
[INFO] 15/11/15 12:20:48 hadoop.HadoopPartitionQueue: Moving O11(x0,x1,x2)
To: output/EXP_028/20151115_122033/OUT_2_O11
[INFO] 15/11/15 12:20:48 hadoop.HadoopPartitionQueue: Moving to:  output/EXP_028/20151115_122033/OUT_2_O11
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O11+_2/O11-r-00000
[INFO] 15/11/15 12:20:48 utils.PartitionQueue: Calculation group {
id : 4 Depends on: None. - (O12(x,y,z) : G(x,y,z) & T(x))
id : 5 Depends on: 0, - (O21(x,y,z) : O11(x,y,z) & T(z))
} is ready to be scheduled.
Adding output paths
[INFO] 15/11/15 12:20:48 sample.RelationSampler: Avoiding re-sample for R(x0,x1,x2)
[INFO] 15/11/15 12:20:48 sample.RelationSampler: Avoiding re-sample for S(x0)
[INFO] 15/11/15 12:20:48 sample.RelationSampler: Avoiding re-sample for T(x0)
[INFO] 15/11/15 12:20:48 sample.RelationSampler: Avoiding re-sample for U(x0)
[INFO] 15/11/15 12:20:48 sample.RelationSampler: Avoiding re-sample for G(x0,x1,x2)
[INFO] 15/11/15 12:20:48 sample.RelationSampler: Avoiding re-sample for H(x0,x1,x2)
[INFO] 15/11/15 12:20:48 sample.RelationSampler: Fetching samples for relation O11(x0,x1,x2)
[INFO] 15/11/15 12:20:48 reporter.RelationTupleSampleContainer: Parsing samples for relation O11(x0,x1,x2)
[INFO] 15/11/15 12:20:48 reporter.RelationTupleSampleContainer: Number of blocks: 10
[INFO] 15/11/15 12:20:48 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 1
[INFO] 15/11/15 12:20:48 reporter.RelationTupleSampleContainer: Small tuples: 208
[INFO] 15/11/15 12:20:48 reporter.RelationTupleSampleContainer: Big tuples: 1865
[INFO] 15/11/15 12:20:48 grouper.GrouperFactory: Creating a grouper with policy COSTGROUP_GUMBO
[WARN] 15/11/15 12:20:48 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
Adding output paths
[INFO] 15/11/15 12:20:48 grouper.Grouper: Decomposition complete: 	G(x,y,z) |X T(x)
	O11(x,y,z) |X T(z)
	Guard In Bytes0
	Guarded In Bytes0
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:0.0

[INFO] 15/11/15 12:20:48 sample.Simulator: Simulating relation T(x0)
[INFO] 15/11/15 12:20:48 sample.Simulator: Simulating relation G(x0,x1,x2)
[INFO] 15/11/15 12:20:48 sample.Simulator: Simulating relation T(x0)
[INFO] 15/11/15 12:20:48 sample.Simulator: Simulating relation O11(x0,x1,x2)
[INFO] 15/11/15 12:20:48 sample.Simulator: Simulating relation T(x0)
[INFO] 15/11/15 12:20:48 sample.Simulator: Simulating relation O11(x0,x1,x2)
[INFO] 15/11/15 12:20:48 sample.Simulator: Simulating relation G(x0,x1,x2)
[INFO] 15/11/15 12:20:48 sample.Simulator: Simulating relation T(x0)
[INFO] 15/11/15 12:20:48 sample.Simulator: Simulating relation O11(x0,x1,x2)
[INFO] 15/11/15 12:20:48 sample.Simulator: Simulating relation G(x0,x1,x2)
[INFO] 15/11/15 12:20:48 grouper.Grouper: Grouping complete: 1 group(s)
[INFO] 15/11/15 12:20:48 grouper.Grouper: Grouping: [	G(x,y,z) |X T(x)
	O11(x,y,z) |X T(z)
	Guard In Bytes269891
	Guarded In Bytes48900
	Guard Out Bytes200021
	Guarded Out Bytes88901
	Cost:51.32197015041326
]
[WARN] 15/11/15 12:20:48 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
[INFO] 15/11/15 12:20:48 converter.GumboHadoopConverter: Intermediate data size: 0.27553749084472656 MB
[INFO] 15/11/15 12:20:48 converter.GumboHadoopConverter: Num reducers: 1
[INFO] 15/11/15 12:20:48 converter.GumboHadoopConverter: R(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/R/R.txt;csv;'S(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/S/S.txt;csv;'T(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/T/T.txt;csv;'U(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/U/U.txt;csv;'G(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/G/G.txt;csv;'H(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/H/H.txt;csv;'O11(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_2_O11/O11-r-00000;rel;
[INFO] 15/11/15 12:20:48 converter.GumboHadoopConverter: Setting M1 guarded path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/T/T.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardedCsv
[INFO] 15/11/15 12:20:48 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_2_O11/O11-r-00000 using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardRelOptimized
[INFO] 15/11/15 12:20:48 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/G/G.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardCsv
[INFO] 15/11/15 12:20:48 converter.GumboHadoopConverter: Setting Reduce tasks to 1
Adding output paths
[INFO] 15/11/15 12:20:48 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_2_O11/O11-r-00000 using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardRelOptimized
[INFO] 15/11/15 12:20:48 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/G/G.txt using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardCsv
[INFO] 15/11/15 12:20:48 converter.GumboHadoopConverter: Adding M2 normal path file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_7_query2.gumbo_O11+G+_1 using identity mapper 
[INFO] 15/11/15 12:20:48 converter.Round2ReduceJobEstimator: Output estimate 201326592
[INFO] 15/11/15 12:20:48 converter.Round2ReduceJobEstimator: Reducer estimate 2
[INFO] 15/11/15 12:20:53 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/11/15 12:20:53 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/15 12:20:53 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/15 12:20:53 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/15 12:20:53 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/15 12:20:53 mapreduce.JobSubmitter: number of splits:3
[INFO] 15/11/15 12:20:53 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/15 12:20:53 mapreduce.JobSubmitter: Submitting tokens for job: job_local1990435288_0003
[WARN] 15/11/15 12:20:53 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1990435288/.staging/job_local1990435288_0003/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:20:53 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1990435288/.staging/job_local1990435288_0003/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/15 12:20:53 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1990435288_0003/job_local1990435288_0003.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:20:53 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1990435288_0003/job_local1990435288_0003.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/15 12:20:53 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/15 12:20:53 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/15 12:20:53 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/15 12:20:53 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/15 12:20:53 mapred.LocalJobRunner: Starting task: attempt_local1990435288_0003_m_000000_0
[INFO] 15/11/15 12:20:53 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:53 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:53 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/G/G.txt:0+146771
[INFO] 15/11/15 12:20:53 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:20:53 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:20:53 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:20:53 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:20:53 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:20:53 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:20:53 mappers.GFMapper1Identity: MapperGFMapper1GuardCsv-00000-0
[INFO] 15/11/15 12:20:53 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:20:53 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:20:53 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:20:53 mapred.MapTask: bufstart = 0; bufend = 148598; bufvoid = 104857600
[INFO] 15/11/15 12:20:53 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/11/15 12:20:53 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:20:53 mapred.Task: Task:attempt_local1990435288_0003_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:53 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:20:53 mapred.Task: Task 'attempt_local1990435288_0003_m_000000_0' done.
[INFO] 15/11/15 12:20:53 mapred.LocalJobRunner: Finishing task: attempt_local1990435288_0003_m_000000_0
[INFO] 15/11/15 12:20:53 mapred.LocalJobRunner: Starting task: attempt_local1990435288_0003_m_000001_0
[INFO] 15/11/15 12:20:53 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:53 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:53 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_2_O11/O11-r-00000:0+123120
[INFO] 15/11/15 12:20:53 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:20:53 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:20:53 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:20:53 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:20:53 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:20:53 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:20:53 mappers.GFMapper1Identity: MapperGFMapper1GuardRelOptimized-00001-0
[INFO] 15/11/15 12:20:53 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:20:53 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:20:53 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:20:53 mapred.MapTask: bufstart = 0; bufend = 92964; bufvoid = 104857600
[INFO] 15/11/15 12:20:53 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26189352(104757408); length = 25045/6553600
[INFO] 15/11/15 12:20:53 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:20:53 mapred.Task: Task:attempt_local1990435288_0003_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:53 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:20:53 mapred.Task: Task 'attempt_local1990435288_0003_m_000001_0' done.
[INFO] 15/11/15 12:20:53 mapred.LocalJobRunner: Finishing task: attempt_local1990435288_0003_m_000001_0
[INFO] 15/11/15 12:20:53 mapred.LocalJobRunner: Starting task: attempt_local1990435288_0003_m_000002_0
[INFO] 15/11/15 12:20:54 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:54 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:54 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/T/T.txt:0+48900
[INFO] 15/11/15 12:20:54 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:20:54 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:20:54 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:20:54 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:20:54 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:20:54 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:20:54 mappers.GFMapper1Identity: MapperGFMapper1GuardedCsv-00002-0
[INFO] 15/11/15 12:20:54 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:20:54 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:20:54 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:20:54 mapred.MapTask: bufstart = 0; bufend = 108900; bufvoid = 104857600
[INFO] 15/11/15 12:20:54 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/11/15 12:20:54 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:20:54 mapred.Task: Task:attempt_local1990435288_0003_m_000002_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:54 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:20:54 mapred.Task: Task 'attempt_local1990435288_0003_m_000002_0' done.
[INFO] 15/11/15 12:20:54 mapred.LocalJobRunner: Finishing task: attempt_local1990435288_0003_m_000002_0
[INFO] 15/11/15 12:20:54 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/15 12:20:54 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/15 12:20:54 mapred.LocalJobRunner: Starting task: attempt_local1990435288_0003_r_000000_0
[INFO] 15/11/15 12:20:54 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:54 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:54 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@8690aa7
[INFO] 15/11/15 12:20:54 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:20:54 reduce.EventFetcher: attempt_local1990435288_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:20:54 reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1990435288_0003_m_000001_0 decomp: 105490 len: 105494 to MEMORY
[INFO] 15/11/15 12:20:54 reduce.InMemoryMapOutput: Read 105490 bytes from map-output for attempt_local1990435288_0003_m_000001_0
[INFO] 15/11/15 12:20:54 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 105490, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->105490
[INFO] 15/11/15 12:20:54 reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1990435288_0003_m_000000_0 decomp: 168600 len: 168604 to MEMORY
[INFO] 15/11/15 12:20:54 reduce.InMemoryMapOutput: Read 168600 bytes from map-output for attempt_local1990435288_0003_m_000000_0
[INFO] 15/11/15 12:20:54 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 168600, inMemoryMapOutputs.size() -> 2, commitMemory -> 105490, usedMemory ->274090
[INFO] 15/11/15 12:20:54 reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1990435288_0003_m_000002_0 decomp: 128902 len: 128906 to MEMORY
[INFO] 15/11/15 12:20:54 reduce.InMemoryMapOutput: Read 128902 bytes from map-output for attempt_local1990435288_0003_m_000002_0
[INFO] 15/11/15 12:20:54 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 128902, inMemoryMapOutputs.size() -> 3, commitMemory -> 274090, usedMemory ->402992
[INFO] 15/11/15 12:20:54 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:20:54 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/11/15 12:20:54 reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:20:54 mapred.Merger: Merging 3 sorted segments
[INFO] 15/11/15 12:20:54 mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 402978 bytes
[INFO] 15/11/15 12:20:54 reduce.MergeManagerImpl: Merged 3 segments, 402992 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:20:54 reduce.MergeManagerImpl: Merging 1 files, 402992 bytes from disk
[INFO] 15/11/15 12:20:54 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:20:54 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:20:54 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 402984 bytes
[INFO] 15/11/15 12:20:54 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/11/15 12:20:54 reducers.GFReducer1Optimized: ReducerGFReducer1Optimized-00000-0
[INFO] 15/11/15 12:20:54 mapred.Task: Task:attempt_local1990435288_0003_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:54 mapred.LocalJobRunner: 3 / 3 copied.
[INFO] 15/11/15 12:20:54 mapred.Task: Task attempt_local1990435288_0003_r_000000_0 is allowed to commit now
[INFO] 15/11/15 12:20:54 output.FileOutputCommitter: Saved output of task 'attempt_local1990435288_0003_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_7_query2.gumbo_O11+G+_1/_temporary/0/task_local1990435288_0003_r_000000
[INFO] 15/11/15 12:20:54 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:20:54 mapred.Task: Task 'attempt_local1990435288_0003_r_000000_0' done.
[INFO] 15/11/15 12:20:54 mapred.LocalJobRunner: Finishing task: attempt_local1990435288_0003_r_000000_0
[INFO] 15/11/15 12:20:54 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/15 12:20:58 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/11/15 12:20:58 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/15 12:20:58 input.FileInputFormat: Total input paths to process : 2
[INFO] 15/11/15 12:20:58 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/15 12:20:58 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/15 12:20:58 mapreduce.JobSubmitter: number of splits:4
[INFO] 15/11/15 12:20:58 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/15 12:20:58 mapreduce.JobSubmitter: Submitting tokens for job: job_local911957114_0004
[WARN] 15/11/15 12:20:58 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny911957114/.staging/job_local911957114_0004/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:20:58 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny911957114/.staging/job_local911957114_0004/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/15 12:20:58 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local911957114_0004/job_local911957114_0004.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:20:58 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local911957114_0004/job_local911957114_0004.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/15 12:20:58 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/15 12:20:58 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/15 12:20:58 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/15 12:20:58 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/15 12:20:58 mapred.LocalJobRunner: Starting task: attempt_local911957114_0004_m_000000_0
[INFO] 15/11/15 12:20:58 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:58 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:58 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/G/G.txt:0+146771
[INFO] 15/11/15 12:20:58 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:20:58 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:20:58 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:20:58 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:20:58 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:20:58 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:20:58 mappers.GFMapper1Identity: MapperGFMapper2GuardCsv-00000-0
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:20:59 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:20:59 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:20:59 mapred.MapTask: bufstart = 0; bufend = 256486; bufvoid = 104857600
[INFO] 15/11/15 12:20:59 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/11/15 12:20:59 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:20:59 mapred.Task: Task:attempt_local911957114_0004_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:20:59 mapred.Task: Task 'attempt_local911957114_0004_m_000000_0' done.
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: Finishing task: attempt_local911957114_0004_m_000000_0
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: Starting task: attempt_local911957114_0004_m_000001_0
[INFO] 15/11/15 12:20:59 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:59 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:59 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_2_O11/O11-r-00000:0+123120
[INFO] 15/11/15 12:20:59 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:20:59 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:20:59 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:20:59 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:20:59 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:20:59 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:20:59 mappers.GFMapper1Identity: MapperGFMapper2GuardRelOptimized-00001-0
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:20:59 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:20:59 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:20:59 mapred.MapTask: bufstart = 0; bufend = 173003; bufvoid = 104857600
[INFO] 15/11/15 12:20:59 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26189352(104757408); length = 25045/6553600
[INFO] 15/11/15 12:20:59 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:20:59 mapred.Task: Task:attempt_local911957114_0004_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:20:59 mapred.Task: Task 'attempt_local911957114_0004_m_000001_0' done.
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: Finishing task: attempt_local911957114_0004_m_000001_0
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: Starting task: attempt_local911957114_0004_m_000002_0
[INFO] 15/11/15 12:20:59 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:59 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:59 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_7_query2.gumbo_O11+G+_1/round1-r-00000:0+91057
[INFO] 15/11/15 12:20:59 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:20:59 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:20:59 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:20:59 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:20:59 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:20:59 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:20:59 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:20:59 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:20:59 mapred.MapTask: bufstart = 0; bufend = 91057; bufvoid = 104857600
[INFO] 15/11/15 12:20:59 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26173788(104695152); length = 40609/6553600
[INFO] 15/11/15 12:20:59 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:20:59 mapred.Task: Task:attempt_local911957114_0004_m_000002_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:20:59 mapred.Task: Task 'attempt_local911957114_0004_m_000002_0' done.
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: Finishing task: attempt_local911957114_0004_m_000002_0
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: Starting task: attempt_local911957114_0004_m_000003_0
[INFO] 15/11/15 12:20:59 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:59 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:59 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_7_query2.gumbo_O11+G+_1/part-r-00000:0+0
[INFO] 15/11/15 12:20:59 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:20:59 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:20:59 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:20:59 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:20:59 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:20:59 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:20:59 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:20:59 mapred.Task: Task:attempt_local911957114_0004_m_000003_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:20:59 mapred.Task: Task 'attempt_local911957114_0004_m_000003_0' done.
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: Finishing task: attempt_local911957114_0004_m_000003_0
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: Starting task: attempt_local911957114_0004_r_000000_0
[INFO] 15/11/15 12:20:59 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:59 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:59 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@474cf401
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:20:59 reduce.EventFetcher: attempt_local911957114_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:20:59 reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local911957114_0004_m_000003_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/15 12:20:59 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local911957114_0004_m_000003_0
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
[INFO] 15/11/15 12:20:59 reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local911957114_0004_m_000000_0 decomp: 137796 len: 137800 to MEMORY
[INFO] 15/11/15 12:20:59 reduce.InMemoryMapOutput: Read 137796 bytes from map-output for attempt_local911957114_0004_m_000000_0
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 137796, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->137798
[INFO] 15/11/15 12:20:59 reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local911957114_0004_m_000001_0 decomp: 93651 len: 93655 to MEMORY
[INFO] 15/11/15 12:20:59 reduce.InMemoryMapOutput: Read 93651 bytes from map-output for attempt_local911957114_0004_m_000001_0
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 93651, inMemoryMapOutputs.size() -> 3, commitMemory -> 137798, usedMemory ->231449
[INFO] 15/11/15 12:20:59 reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local911957114_0004_m_000002_0 decomp: 55965 len: 55969 to MEMORY
[INFO] 15/11/15 12:20:59 reduce.InMemoryMapOutput: Read 55965 bytes from map-output for attempt_local911957114_0004_m_000002_0
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 55965, inMemoryMapOutputs.size() -> 4, commitMemory -> 231449, usedMemory ->287414
[INFO] 15/11/15 12:20:59 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: finalMerge called with 4 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:20:59 mapred.Merger: Merging 4 sorted segments
[INFO] 15/11/15 12:20:59 mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 287385 bytes
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: Merged 4 segments, 287414 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: Merging 1 files, 287412 bytes from disk
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:20:59 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:20:59 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 287399 bytes
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/11/15 12:20:59 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00000-0
[INFO] 15/11/15 12:20:59 mapred.Task: Task:attempt_local911957114_0004_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/11/15 12:20:59 mapred.Task: Task attempt_local911957114_0004_r_000000_0 is allowed to commit now
[INFO] 15/11/15 12:20:59 output.FileOutputCommitter: Saved output of task 'attempt_local911957114_0004_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O12+O21+_2/_temporary/0/task_local911957114_0004_r_000000
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:20:59 mapred.Task: Task 'attempt_local911957114_0004_r_000000_0' done.
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: Finishing task: attempt_local911957114_0004_r_000000_0
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: Starting task: attempt_local911957114_0004_r_000001_0
[INFO] 15/11/15 12:20:59 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:20:59 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:20:59 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@26c2c46d
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:20:59 reduce.EventFetcher: attempt_local911957114_0004_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:20:59 reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local911957114_0004_m_000003_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/15 12:20:59 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local911957114_0004_m_000003_0
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
[INFO] 15/11/15 12:20:59 reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local911957114_0004_m_000000_0 decomp: 138694 len: 138698 to MEMORY
[INFO] 15/11/15 12:20:59 reduce.InMemoryMapOutput: Read 138694 bytes from map-output for attempt_local911957114_0004_m_000000_0
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 138694, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->138696
[INFO] 15/11/15 12:20:59 reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local911957114_0004_m_000001_0 decomp: 91880 len: 91884 to MEMORY
[INFO] 15/11/15 12:20:59 reduce.InMemoryMapOutput: Read 91880 bytes from map-output for attempt_local911957114_0004_m_000001_0
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 91880, inMemoryMapOutputs.size() -> 3, commitMemory -> 138696, usedMemory ->230576
[INFO] 15/11/15 12:20:59 reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local911957114_0004_m_000002_0 decomp: 55402 len: 55406 to MEMORY
[INFO] 15/11/15 12:20:59 reduce.InMemoryMapOutput: Read 55402 bytes from map-output for attempt_local911957114_0004_m_000002_0
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 55402, inMemoryMapOutputs.size() -> 4, commitMemory -> 230576, usedMemory ->285978
[INFO] 15/11/15 12:20:59 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: finalMerge called with 4 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:20:59 mapred.Merger: Merging 4 sorted segments
[INFO] 15/11/15 12:20:59 mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 285949 bytes
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: Merged 4 segments, 285978 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: Merging 1 files, 285976 bytes from disk
[INFO] 15/11/15 12:20:59 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:20:59 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:20:59 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 285963 bytes
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/11/15 12:20:59 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00001-0
[INFO] 15/11/15 12:20:59 mapred.Task: Task:attempt_local911957114_0004_r_000001_0 is done. And is in the process of committing
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/11/15 12:20:59 mapred.Task: Task attempt_local911957114_0004_r_000001_0 is allowed to commit now
[INFO] 15/11/15 12:20:59 output.FileOutputCommitter: Saved output of task 'attempt_local911957114_0004_r_000001_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O12+O21+_2/_temporary/0/task_local911957114_0004_r_000001
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:20:59 mapred.Task: Task 'attempt_local911957114_0004_r_000001_0' done.
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: Finishing task: attempt_local911957114_0004_r_000001_0
[INFO] 15/11/15 12:20:59 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/15 12:21:04 hadoop.HadoopPartitionQueue: Group is done, moving its output files{
id : 4 Depends on: None. - (O12(x,y,z) : G(x,y,z) & T(x))
id : 5 Depends on: 0, - (O21(x,y,z) : O11(x,y,z) & T(z))
}
[INFO] 15/11/15 12:21:04 hadoop.HadoopPartitionQueue: Moving O12(x0,x1,x2)
To: output/EXP_028/20151115_122033/OUT_1_O12
[INFO] 15/11/15 12:21:04 hadoop.HadoopPartitionQueue: Moving to:  output/EXP_028/20151115_122033/OUT_1_O12
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O12+O21+_2/O12-r-00000
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O12+O21+_2/O12-r-00001
[INFO] 15/11/15 12:21:04 hadoop.HadoopPartitionQueue: Moving O21(x0,x1,x2)
To: output/EXP_028/20151115_122033/OUT_5_O21
[INFO] 15/11/15 12:21:04 hadoop.HadoopPartitionQueue: Moving to:  output/EXP_028/20151115_122033/OUT_5_O21
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O12+O21+_2/O21-r-00000
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O12+O21+_2/O21-r-00001
[INFO] 15/11/15 12:21:04 utils.PartitionQueue: Calculation group {
id : 2 Depends on: None. - (O13(x,y,z) : H(x,y,z) & U(x))
id : 3 Depends on: 4, - (O22(x,y,z) : O12(x,y,z) & U(z))
} is ready to be scheduled.
Adding output paths
[INFO] 15/11/15 12:21:04 sample.RelationSampler: Fetching samples for relation O12(x0,x1,x2)
[INFO] 15/11/15 12:21:04 sample.RelationSampler: Avoiding re-sample for R(x0,x1,x2)
[INFO] 15/11/15 12:21:04 sample.RelationSampler: Avoiding re-sample for S(x0)
[INFO] 15/11/15 12:21:04 sample.RelationSampler: Avoiding re-sample for T(x0)
[INFO] 15/11/15 12:21:04 sample.RelationSampler: Avoiding re-sample for U(x0)
[INFO] 15/11/15 12:21:04 sample.RelationSampler: Avoiding re-sample for G(x0,x1,x2)
[INFO] 15/11/15 12:21:04 sample.RelationSampler: Avoiding re-sample for H(x0,x1,x2)
[INFO] 15/11/15 12:21:04 sample.RelationSampler: Avoiding re-sample for O11(x0,x1,x2)
[INFO] 15/11/15 12:21:04 sample.RelationSampler: Fetching samples for relation O21(x0,x1,x2)
[INFO] 15/11/15 12:21:04 reporter.RelationTupleSampleContainer: Parsing samples for relation O12(x0,x1,x2)
[INFO] 15/11/15 12:21:04 reporter.RelationTupleSampleContainer: Number of blocks: 20
[INFO] 15/11/15 12:21:04 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 2
[INFO] 15/11/15 12:21:04 reporter.RelationTupleSampleContainer: Small tuples: 413
[INFO] 15/11/15 12:21:04 reporter.RelationTupleSampleContainer: Big tuples: 3708
[INFO] 15/11/15 12:21:04 reporter.RelationTupleSampleContainer: Parsing samples for relation O21(x0,x1,x2)
[INFO] 15/11/15 12:21:04 reporter.RelationTupleSampleContainer: Number of blocks: 20
[INFO] 15/11/15 12:21:04 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 2
[INFO] 15/11/15 12:21:04 reporter.RelationTupleSampleContainer: Small tuples: 414
[INFO] 15/11/15 12:21:04 reporter.RelationTupleSampleContainer: Big tuples: 3535
[INFO] 15/11/15 12:21:04 grouper.GrouperFactory: Creating a grouper with policy COSTGROUP_GUMBO
[WARN] 15/11/15 12:21:04 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
Adding output paths
[INFO] 15/11/15 12:21:04 grouper.Grouper: Decomposition complete: 	O12(x,y,z) |X U(z)
	H(x,y,z) |X U(x)
	Guard In Bytes0
	Guarded In Bytes0
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:0.0

[INFO] 15/11/15 12:21:04 sample.Simulator: Simulating relation O12(x0,x1,x2)
[INFO] 15/11/15 12:21:04 sample.Simulator: Simulating relation U(x0)
[INFO] 15/11/15 12:21:04 sample.Simulator: Simulating relation H(x0,x1,x2)
[INFO] 15/11/15 12:21:04 sample.Simulator: Simulating relation U(x0)
[INFO] 15/11/15 12:21:04 sample.Simulator: Simulating relation H(x0,x1,x2)
[INFO] 15/11/15 12:21:04 sample.Simulator: Simulating relation O12(x0,x1,x2)
[INFO] 15/11/15 12:21:04 sample.Simulator: Simulating relation U(x0)
[INFO] 15/11/15 12:21:04 sample.Simulator: Simulating relation H(x0,x1,x2)
[INFO] 15/11/15 12:21:04 sample.Simulator: Simulating relation O12(x0,x1,x2)
[INFO] 15/11/15 12:21:04 sample.Simulator: Simulating relation U(x0)
[INFO] 15/11/15 12:21:04 grouper.Grouper: Grouping complete: 1 group(s)
[INFO] 15/11/15 12:21:04 grouper.Grouper: Grouping: [	O12(x,y,z) |X U(z)
	H(x,y,z) |X U(x)
	Guard In Bytes269073
	Guarded In Bytes48866
	Guard Out Bytes202110
	Guarded Out Bytes88919
	Cost:51.32978337224033
]
[WARN] 15/11/15 12:21:04 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
[INFO] 15/11/15 12:21:04 converter.GumboHadoopConverter: Intermediate data size: 0.27754688262939453 MB
[INFO] 15/11/15 12:21:04 converter.GumboHadoopConverter: Num reducers: 1
[INFO] 15/11/15 12:21:04 converter.GumboHadoopConverter: O12(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_1_O12/O12-r-00000,file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_1_O12/O12-r-00001;rel;'R(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/R/R.txt;csv;'S(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/S/S.txt;csv;'T(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/T/T.txt;csv;'U(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/U/U.txt;csv;'G(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/G/G.txt;csv;'H(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/H/H.txt;csv;'O11(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_2_O11/O11-r-00000;rel;'O21(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_5_O21/O21-r-00001,file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_5_O21/O21-r-00000;rel;
[INFO] 15/11/15 12:21:04 converter.GumboHadoopConverter: Setting M1 guarded path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/U/U.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardedCsv
[INFO] 15/11/15 12:21:04 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_1_O12/O12-r-00000 using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardRelOptimized
[INFO] 15/11/15 12:21:04 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_1_O12/O12-r-00001 using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardRelOptimized
[INFO] 15/11/15 12:21:04 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/H/H.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardCsv
[INFO] 15/11/15 12:21:04 converter.GumboHadoopConverter: Setting Reduce tasks to 1
Adding output paths
[INFO] 15/11/15 12:21:04 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_1_O12/O12-r-00000 using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardRelOptimized
[INFO] 15/11/15 12:21:04 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_1_O12/O12-r-00001 using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardRelOptimized
[INFO] 15/11/15 12:21:04 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/H/H.txt using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardCsv
[INFO] 15/11/15 12:21:04 converter.GumboHadoopConverter: Adding M2 normal path file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_8_query2.gumbo_H+O12+_1 using identity mapper 
[INFO] 15/11/15 12:21:04 converter.Round2ReduceJobEstimator: Output estimate 301989888
[INFO] 15/11/15 12:21:04 converter.Round2ReduceJobEstimator: Reducer estimate 3
[INFO] 15/11/15 12:21:08 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/11/15 12:21:08 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/15 12:21:08 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/15 12:21:08 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/15 12:21:08 input.FileInputFormat: Total input paths to process : 2
[INFO] 15/11/15 12:21:08 mapreduce.JobSubmitter: number of splits:4
[INFO] 15/11/15 12:21:08 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/15 12:21:08 mapreduce.JobSubmitter: Submitting tokens for job: job_local1710462247_0005
[WARN] 15/11/15 12:21:08 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1710462247/.staging/job_local1710462247_0005/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:21:08 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1710462247/.staging/job_local1710462247_0005/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/15 12:21:09 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1710462247_0005/job_local1710462247_0005.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:21:09 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1710462247_0005/job_local1710462247_0005.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/15 12:21:09 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: Starting task: attempt_local1710462247_0005_m_000000_0
[INFO] 15/11/15 12:21:09 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:09 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:09 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/H/H.txt:0+146641
[INFO] 15/11/15 12:21:09 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:09 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:09 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:09 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:09 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:09 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:09 mappers.GFMapper1Identity: MapperGFMapper1GuardCsv-00000-0
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:09 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:09 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:09 mapred.MapTask: bufstart = 0; bufend = 148603; bufvoid = 104857600
[INFO] 15/11/15 12:21:09 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/11/15 12:21:09 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:09 mapred.Task: Task:attempt_local1710462247_0005_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:09 mapred.Task: Task 'attempt_local1710462247_0005_m_000000_0' done.
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: Finishing task: attempt_local1710462247_0005_m_000000_0
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: Starting task: attempt_local1710462247_0005_m_000001_0
[INFO] 15/11/15 12:21:09 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:09 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:09 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_1_O12/O12-r-00000:0+61228
[INFO] 15/11/15 12:21:09 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:09 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:09 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:09 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:09 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:09 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:09 mappers.GFMapper1Identity: MapperGFMapper1GuardRelOptimized-00001-0
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:09 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:09 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:09 mapred.MapTask: bufstart = 0; bufend = 46111; bufvoid = 104857600
[INFO] 15/11/15 12:21:09 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26201964(104807856); length = 12433/6553600
[INFO] 15/11/15 12:21:09 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:09 mapred.Task: Task:attempt_local1710462247_0005_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:09 mapred.Task: Task 'attempt_local1710462247_0005_m_000001_0' done.
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: Finishing task: attempt_local1710462247_0005_m_000001_0
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: Starting task: attempt_local1710462247_0005_m_000002_0
[INFO] 15/11/15 12:21:09 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:09 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:09 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_1_O12/O12-r-00001:0+61204
[INFO] 15/11/15 12:21:09 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:09 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:09 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:09 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:09 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:09 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:09 mappers.GFMapper1Identity: MapperGFMapper1GuardRelOptimized-00002-0
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:09 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:09 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:09 mapred.MapTask: bufstart = 0; bufend = 46110; bufvoid = 104857600
[INFO] 15/11/15 12:21:09 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26201960(104807840); length = 12437/6553600
[INFO] 15/11/15 12:21:09 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:09 mapred.Task: Task:attempt_local1710462247_0005_m_000002_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:09 mapred.Task: Task 'attempt_local1710462247_0005_m_000002_0' done.
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: Finishing task: attempt_local1710462247_0005_m_000002_0
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: Starting task: attempt_local1710462247_0005_m_000003_0
[INFO] 15/11/15 12:21:09 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:09 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:09 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/U/U.txt:0+48866
[INFO] 15/11/15 12:21:09 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:09 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:09 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:09 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:09 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:09 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:09 mappers.GFMapper1Identity: MapperGFMapper1GuardedCsv-00003-0
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:09 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:09 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:09 mapred.MapTask: bufstart = 0; bufend = 108866; bufvoid = 104857600
[INFO] 15/11/15 12:21:09 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/11/15 12:21:09 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:09 mapred.Task: Task:attempt_local1710462247_0005_m_000003_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:09 mapred.Task: Task 'attempt_local1710462247_0005_m_000003_0' done.
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: Finishing task: attempt_local1710462247_0005_m_000003_0
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: Starting task: attempt_local1710462247_0005_r_000000_0
[INFO] 15/11/15 12:21:09 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:09 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:09 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@a201253
[INFO] 15/11/15 12:21:09 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:21:09 reduce.EventFetcher: attempt_local1710462247_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:21:09 reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1710462247_0005_m_000000_0 decomp: 168605 len: 168609 to MEMORY
[INFO] 15/11/15 12:21:09 reduce.InMemoryMapOutput: Read 168605 bytes from map-output for attempt_local1710462247_0005_m_000000_0
[INFO] 15/11/15 12:21:09 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 168605, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->168605
[INFO] 15/11/15 12:21:09 reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1710462247_0005_m_000003_0 decomp: 128868 len: 128872 to MEMORY
[INFO] 15/11/15 12:21:09 reduce.InMemoryMapOutput: Read 128868 bytes from map-output for attempt_local1710462247_0005_m_000003_0
[INFO] 15/11/15 12:21:09 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 128868, inMemoryMapOutputs.size() -> 2, commitMemory -> 168605, usedMemory ->297473
[INFO] 15/11/15 12:21:09 reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1710462247_0005_m_000001_0 decomp: 52331 len: 52335 to MEMORY
[INFO] 15/11/15 12:21:09 reduce.InMemoryMapOutput: Read 52331 bytes from map-output for attempt_local1710462247_0005_m_000001_0
[INFO] 15/11/15 12:21:09 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52331, inMemoryMapOutputs.size() -> 3, commitMemory -> 297473, usedMemory ->349804
[INFO] 15/11/15 12:21:09 reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local1710462247_0005_m_000002_0 decomp: 52332 len: 52336 to MEMORY
[INFO] 15/11/15 12:21:09 reduce.InMemoryMapOutput: Read 52332 bytes from map-output for attempt_local1710462247_0005_m_000002_0
[INFO] 15/11/15 12:21:09 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52332, inMemoryMapOutputs.size() -> 4, commitMemory -> 349804, usedMemory ->402136
[INFO] 15/11/15 12:21:09 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/11/15 12:21:09 reduce.MergeManagerImpl: finalMerge called with 4 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:21:09 mapred.Merger: Merging 4 sorted segments
[INFO] 15/11/15 12:21:09 mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 402115 bytes
[INFO] 15/11/15 12:21:09 reduce.MergeManagerImpl: Merged 4 segments, 402136 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:21:09 reduce.MergeManagerImpl: Merging 1 files, 402134 bytes from disk
[INFO] 15/11/15 12:21:09 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:21:09 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:21:09 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 402126 bytes
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/11/15 12:21:09 reducers.GFReducer1Optimized: ReducerGFReducer1Optimized-00000-0
[INFO] 15/11/15 12:21:09 mapred.Task: Task:attempt_local1710462247_0005_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/11/15 12:21:09 mapred.Task: Task attempt_local1710462247_0005_r_000000_0 is allowed to commit now
[INFO] 15/11/15 12:21:09 output.FileOutputCommitter: Saved output of task 'attempt_local1710462247_0005_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_8_query2.gumbo_H+O12+_1/_temporary/0/task_local1710462247_0005_r_000000
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:21:09 mapred.Task: Task 'attempt_local1710462247_0005_r_000000_0' done.
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: Finishing task: attempt_local1710462247_0005_r_000000_0
[INFO] 15/11/15 12:21:09 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/15 12:21:14 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/11/15 12:21:14 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/15 12:21:14 input.FileInputFormat: Total input paths to process : 2
[INFO] 15/11/15 12:21:14 input.FileInputFormat: Total input paths to process : 2
[INFO] 15/11/15 12:21:14 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/15 12:21:14 mapreduce.JobSubmitter: number of splits:5
[INFO] 15/11/15 12:21:14 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/15 12:21:14 mapreduce.JobSubmitter: Submitting tokens for job: job_local927715729_0006
[WARN] 15/11/15 12:21:14 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny927715729/.staging/job_local927715729_0006/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:21:14 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny927715729/.staging/job_local927715729_0006/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/15 12:21:14 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local927715729_0006/job_local927715729_0006.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:21:14 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local927715729_0006/job_local927715729_0006.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/15 12:21:14 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Starting task: attempt_local927715729_0006_m_000000_0
[INFO] 15/11/15 12:21:14 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:14 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:14 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/H/H.txt:0+146641
[INFO] 15/11/15 12:21:14 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:14 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:14 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:14 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:14 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:14 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:14 mappers.GFMapper1Identity: MapperGFMapper2GuardCsv-00000-0
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:14 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:14 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:14 mapred.MapTask: bufstart = 0; bufend = 256356; bufvoid = 104857600
[INFO] 15/11/15 12:21:14 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/11/15 12:21:14 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:14 mapred.Task: Task:attempt_local927715729_0006_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:14 mapred.Task: Task 'attempt_local927715729_0006_m_000000_0' done.
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Finishing task: attempt_local927715729_0006_m_000000_0
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Starting task: attempt_local927715729_0006_m_000001_0
[INFO] 15/11/15 12:21:14 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:14 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:14 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_8_query2.gumbo_H+O12+_1/round1-r-00000:0+92013
[INFO] 15/11/15 12:21:14 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:14 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:14 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:14 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:14 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:14 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:14 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:14 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:14 mapred.MapTask: bufstart = 0; bufend = 92013; bufvoid = 104857600
[INFO] 15/11/15 12:21:14 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26173300(104693200); length = 41097/6553600
[INFO] 15/11/15 12:21:14 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:14 mapred.Task: Task:attempt_local927715729_0006_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:14 mapred.Task: Task 'attempt_local927715729_0006_m_000001_0' done.
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Finishing task: attempt_local927715729_0006_m_000001_0
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Starting task: attempt_local927715729_0006_m_000002_0
[INFO] 15/11/15 12:21:14 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:14 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:14 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_1_O12/O12-r-00000:0+61228
[INFO] 15/11/15 12:21:14 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:14 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:14 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:14 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:14 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:14 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:14 mappers.GFMapper1Identity: MapperGFMapper2GuardRelOptimized-00002-0
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:14 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:14 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:14 mapred.MapTask: bufstart = 0; bufend = 85888; bufvoid = 104857600
[INFO] 15/11/15 12:21:14 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26201964(104807856); length = 12433/6553600
[INFO] 15/11/15 12:21:14 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:14 mapred.Task: Task:attempt_local927715729_0006_m_000002_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:14 mapred.Task: Task 'attempt_local927715729_0006_m_000002_0' done.
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Finishing task: attempt_local927715729_0006_m_000002_0
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Starting task: attempt_local927715729_0006_m_000003_0
[INFO] 15/11/15 12:21:14 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:14 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:14 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_1_O12/O12-r-00001:0+61204
[INFO] 15/11/15 12:21:14 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:14 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:14 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:14 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:14 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:14 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:14 mappers.GFMapper1Identity: MapperGFMapper2GuardRelOptimized-00003-0
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:14 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:14 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:14 mapred.MapTask: bufstart = 0; bufend = 85871; bufvoid = 104857600
[INFO] 15/11/15 12:21:14 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26201960(104807840); length = 12437/6553600
[INFO] 15/11/15 12:21:14 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:14 mapred.Task: Task:attempt_local927715729_0006_m_000003_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:14 mapred.Task: Task 'attempt_local927715729_0006_m_000003_0' done.
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Finishing task: attempt_local927715729_0006_m_000003_0
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Starting task: attempt_local927715729_0006_m_000004_0
[INFO] 15/11/15 12:21:14 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:14 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:14 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_8_query2.gumbo_H+O12+_1/part-r-00000:0+0
[INFO] 15/11/15 12:21:14 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:14 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:14 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:14 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:14 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:14 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:14 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:14 mapred.Task: Task:attempt_local927715729_0006_m_000004_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:14 mapred.Task: Task 'attempt_local927715729_0006_m_000004_0' done.
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Finishing task: attempt_local927715729_0006_m_000004_0
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Starting task: attempt_local927715729_0006_r_000000_0
[INFO] 15/11/15 12:21:14 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:14 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:14 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3e3ed4f3
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:21:14 reduce.EventFetcher: attempt_local927715729_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local927715729_0006_m_000001_0 decomp: 36037 len: 36041 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 36037 bytes from map-output for attempt_local927715729_0006_m_000001_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 36037, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->36037
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local927715729_0006_m_000004_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local927715729_0006_m_000004_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 36037, usedMemory ->36039
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local927715729_0006_m_000000_0 decomp: 86590 len: 86594 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 86590 bytes from map-output for attempt_local927715729_0006_m_000000_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 86590, inMemoryMapOutputs.size() -> 3, commitMemory -> 36039, usedMemory ->122629
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local927715729_0006_m_000003_0 decomp: 30799 len: 30803 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 30799 bytes from map-output for attempt_local927715729_0006_m_000003_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 30799, inMemoryMapOutputs.size() -> 4, commitMemory -> 122629, usedMemory ->153428
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local927715729_0006_m_000002_0 decomp: 29795 len: 29799 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 29795 bytes from map-output for attempt_local927715729_0006_m_000002_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 29795, inMemoryMapOutputs.size() -> 5, commitMemory -> 153428, usedMemory ->183223
[INFO] 15/11/15 12:21:14 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:21:14 mapred.Merger: Merging 5 sorted segments
[INFO] 15/11/15 12:21:14 mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 183185 bytes
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: Merged 5 segments, 183223 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: Merging 1 files, 183219 bytes from disk
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:21:14 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:21:14 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 183206 bytes
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:14 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00000-0
[INFO] 15/11/15 12:21:14 mapred.Task: Task:attempt_local927715729_0006_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:14 mapred.Task: Task attempt_local927715729_0006_r_000000_0 is allowed to commit now
[INFO] 15/11/15 12:21:14 output.FileOutputCommitter: Saved output of task 'attempt_local927715729_0006_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O13+O22+_2/_temporary/0/task_local927715729_0006_r_000000
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:21:14 mapred.Task: Task 'attempt_local927715729_0006_r_000000_0' done.
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Finishing task: attempt_local927715729_0006_r_000000_0
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Starting task: attempt_local927715729_0006_r_000001_0
[INFO] 15/11/15 12:21:14 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:14 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:14 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@70f84d9
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:21:14 reduce.EventFetcher: attempt_local927715729_0006_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local927715729_0006_m_000001_0 decomp: 38708 len: 38712 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 38708 bytes from map-output for attempt_local927715729_0006_m_000001_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 38708, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->38708
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local927715729_0006_m_000004_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local927715729_0006_m_000004_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 38708, usedMemory ->38710
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local927715729_0006_m_000000_0 decomp: 97908 len: 97912 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 97908 bytes from map-output for attempt_local927715729_0006_m_000000_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 97908, inMemoryMapOutputs.size() -> 3, commitMemory -> 38710, usedMemory ->136618
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local927715729_0006_m_000003_0 decomp: 31052 len: 31056 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 31052 bytes from map-output for attempt_local927715729_0006_m_000003_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31052, inMemoryMapOutputs.size() -> 4, commitMemory -> 136618, usedMemory ->167670
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local927715729_0006_m_000002_0 decomp: 30686 len: 30690 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 30686 bytes from map-output for attempt_local927715729_0006_m_000002_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 30686, inMemoryMapOutputs.size() -> 5, commitMemory -> 167670, usedMemory ->198356
[INFO] 15/11/15 12:21:14 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:21:14 mapred.Merger: Merging 5 sorted segments
[INFO] 15/11/15 12:21:14 mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 198319 bytes
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: Merged 5 segments, 198356 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: Merging 1 files, 198352 bytes from disk
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:21:14 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:21:14 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 198339 bytes
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:14 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00001-0
[INFO] 15/11/15 12:21:14 mapred.Task: Task:attempt_local927715729_0006_r_000001_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:14 mapred.Task: Task attempt_local927715729_0006_r_000001_0 is allowed to commit now
[INFO] 15/11/15 12:21:14 output.FileOutputCommitter: Saved output of task 'attempt_local927715729_0006_r_000001_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O13+O22+_2/_temporary/0/task_local927715729_0006_r_000001
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:21:14 mapred.Task: Task 'attempt_local927715729_0006_r_000001_0' done.
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Finishing task: attempt_local927715729_0006_r_000001_0
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Starting task: attempt_local927715729_0006_r_000002_0
[INFO] 15/11/15 12:21:14 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:14 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:14 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2f0fb2b5
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:21:14 reduce.EventFetcher: attempt_local927715729_0006_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local927715729_0006_m_000001_0 decomp: 37824 len: 37828 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 37824 bytes from map-output for attempt_local927715729_0006_m_000001_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 37824, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->37824
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local927715729_0006_m_000004_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local927715729_0006_m_000004_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 37824, usedMemory ->37826
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local927715729_0006_m_000000_0 decomp: 91864 len: 91868 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 91864 bytes from map-output for attempt_local927715729_0006_m_000000_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 91864, inMemoryMapOutputs.size() -> 3, commitMemory -> 37826, usedMemory ->129690
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local927715729_0006_m_000003_0 decomp: 30246 len: 30250 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 30246 bytes from map-output for attempt_local927715729_0006_m_000003_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 30246, inMemoryMapOutputs.size() -> 4, commitMemory -> 129690, usedMemory ->159936
[INFO] 15/11/15 12:21:14 reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local927715729_0006_m_000002_0 decomp: 31631 len: 31635 to MEMORY
[INFO] 15/11/15 12:21:14 reduce.InMemoryMapOutput: Read 31631 bytes from map-output for attempt_local927715729_0006_m_000002_0
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 31631, inMemoryMapOutputs.size() -> 5, commitMemory -> 159936, usedMemory ->191567
[INFO] 15/11/15 12:21:14 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:21:14 mapred.Merger: Merging 5 sorted segments
[INFO] 15/11/15 12:21:14 mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 191531 bytes
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: Merged 5 segments, 191567 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: Merging 1 files, 191563 bytes from disk
[INFO] 15/11/15 12:21:14 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:21:14 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:21:14 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 191551 bytes
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:14 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00002-0
[INFO] 15/11/15 12:21:14 mapred.Task: Task:attempt_local927715729_0006_r_000002_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:14 mapred.Task: Task attempt_local927715729_0006_r_000002_0 is allowed to commit now
[INFO] 15/11/15 12:21:14 output.FileOutputCommitter: Saved output of task 'attempt_local927715729_0006_r_000002_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O13+O22+_2/_temporary/0/task_local927715729_0006_r_000002
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:21:14 mapred.Task: Task 'attempt_local927715729_0006_r_000002_0' done.
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: Finishing task: attempt_local927715729_0006_r_000002_0
[INFO] 15/11/15 12:21:14 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/15 12:21:19 hadoop.HadoopPartitionQueue: Group is done, moving its output files{
id : 2 Depends on: None. - (O13(x,y,z) : H(x,y,z) & U(x))
id : 3 Depends on: 4, - (O22(x,y,z) : O12(x,y,z) & U(z))
}
[INFO] 15/11/15 12:21:19 hadoop.HadoopPartitionQueue: Moving O13(x0,x1,x2)
To: output/EXP_028/20151115_122033/OUT_0_O13
[INFO] 15/11/15 12:21:19 hadoop.HadoopPartitionQueue: Moving to:  output/EXP_028/20151115_122033/OUT_0_O13
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O13+O22+_2/O13-r-00000
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O13+O22+_2/O13-r-00001
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O13+O22+_2/O13-r-00002
[INFO] 15/11/15 12:21:19 hadoop.HadoopPartitionQueue: Moving O22(x0,x1,x2)
To: output/EXP_028/20151115_122033/OUT_4_O22
[INFO] 15/11/15 12:21:19 hadoop.HadoopPartitionQueue: Moving to:  output/EXP_028/20151115_122033/OUT_4_O22
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O13+O22+_2/O22-r-00000
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O13+O22+_2/O22-r-00001
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O13+O22+_2/O22-r-00002
[INFO] 15/11/15 12:21:19 utils.PartitionQueue: Calculation group {
id : 1 Depends on: 2, - (O23(x,y,z) : O13(x,y,z) & S(z))
} is ready to be scheduled.
Adding output paths
[INFO] 15/11/15 12:21:19 sample.RelationSampler: Fetching samples for relation O13(x0,x1,x2)
[INFO] 15/11/15 12:21:19 sample.RelationSampler: Avoiding re-sample for O12(x0,x1,x2)
[INFO] 15/11/15 12:21:19 sample.RelationSampler: Avoiding re-sample for R(x0,x1,x2)
[INFO] 15/11/15 12:21:19 sample.RelationSampler: Avoiding re-sample for S(x0)
[INFO] 15/11/15 12:21:19 sample.RelationSampler: Avoiding re-sample for T(x0)
[INFO] 15/11/15 12:21:19 sample.RelationSampler: Avoiding re-sample for U(x0)
[INFO] 15/11/15 12:21:19 sample.RelationSampler: Avoiding re-sample for G(x0,x1,x2)
[INFO] 15/11/15 12:21:19 sample.RelationSampler: Avoiding re-sample for H(x0,x1,x2)
[INFO] 15/11/15 12:21:19 sample.RelationSampler: Avoiding re-sample for O11(x0,x1,x2)
[INFO] 15/11/15 12:21:19 sample.RelationSampler: Fetching samples for relation O22(x0,x1,x2)
[INFO] 15/11/15 12:21:19 sample.RelationSampler: Avoiding re-sample for O21(x0,x1,x2)
[INFO] 15/11/15 12:21:19 reporter.RelationTupleSampleContainer: Parsing samples for relation O13(x0,x1,x2)
[INFO] 15/11/15 12:21:19 reporter.RelationTupleSampleContainer: Number of blocks: 30
[INFO] 15/11/15 12:21:19 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 3
[INFO] 15/11/15 12:21:19 reporter.RelationTupleSampleContainer: Small tuples: 622
[INFO] 15/11/15 12:21:19 reporter.RelationTupleSampleContainer: Big tuples: 4955
[INFO] 15/11/15 12:21:19 reporter.RelationTupleSampleContainer: Parsing samples for relation O22(x0,x1,x2)
[INFO] 15/11/15 12:21:19 reporter.RelationTupleSampleContainer: Number of blocks: 30
[INFO] 15/11/15 12:21:19 reporter.RelationTupleSampleContainer: Number of blocks used for small sample: 3
[INFO] 15/11/15 12:21:19 reporter.RelationTupleSampleContainer: Small tuples: 623
[INFO] 15/11/15 12:21:19 reporter.RelationTupleSampleContainer: Big tuples: 5072
[INFO] 15/11/15 12:21:19 grouper.GrouperFactory: Creating a grouper with policy COSTGROUP_GUMBO
[WARN] 15/11/15 12:21:19 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
Adding output paths
[INFO] 15/11/15 12:21:19 grouper.Grouper: Decomposition complete: 	O13(x,y,z) |X S(z)
	Guard In Bytes0
	Guarded In Bytes0
	Guard Out Bytes0
	Guarded Out Bytes0
	Cost:0.0

[INFO] 15/11/15 12:21:19 sample.Simulator: Simulating relation O13(x0,x1,x2)
[INFO] 15/11/15 12:21:19 sample.Simulator: Simulating relation S(x0)
[INFO] 15/11/15 12:21:19 grouper.Grouper: Grouping complete: 1 group(s)
[INFO] 15/11/15 12:21:19 grouper.Grouper: Grouping: [	O13(x,y,z) |X S(z)
	Guard In Bytes124315
	Guarded In Bytes48928
	Guard Out Bytes79886
	Guarded Out Bytes68946
	Cost:50.493064631670684
]
[WARN] 15/11/15 12:21:19 settings.AbstractExecutorSettings: Failed to find setting with key 'mapreduce.reduce.memory.mb', reverting to default value 1024.0
[INFO] 15/11/15 12:21:19 converter.GumboHadoopConverter: Intermediate data size: 0.141937255859375 MB
[INFO] 15/11/15 12:21:19 converter.GumboHadoopConverter: Num reducers: 1
[INFO] 15/11/15 12:21:19 converter.GumboHadoopConverter: O13(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00002,file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00000,file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00001;rel;'O12(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_1_O12/O12-r-00000,file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_1_O12/O12-r-00001;rel;'R(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/R/R.txt;csv;'S(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/S/S.txt;csv;'T(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/T/T.txt;csv;'U(x0);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/U/U.txt;csv;'G(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/G/G.txt;csv;'H(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/H/H.txt;csv;'O11(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_2_O11/O11-r-00000;rel;'O22(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_4_O22/O22-r-00001,file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_4_O22/O22-r-00000,file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_4_O22/O22-r-00002;rel;'O21(x0,x1,x2);file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_5_O21/O21-r-00001,file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_5_O21/O21-r-00000;rel;
[INFO] 15/11/15 12:21:19 converter.GumboHadoopConverter: Setting M1 guarded path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/S/S.txt using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardedCsv
[INFO] 15/11/15 12:21:19 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00002 using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardRelOptimized
[INFO] 15/11/15 12:21:19 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00000 using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardRelOptimized
[INFO] 15/11/15 12:21:19 converter.GumboHadoopConverter: Setting M1 guard path to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00001 using mapper gumbo.engine.hadoop.mrcomponents.round1.mappers.GFMapper1GuardRelOptimized
[INFO] 15/11/15 12:21:19 converter.GumboHadoopConverter: Setting Reduce tasks to 1
Adding output paths
[INFO] 15/11/15 12:21:19 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00002 using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardRelOptimized
[INFO] 15/11/15 12:21:19 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00000 using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardRelOptimized
[INFO] 15/11/15 12:21:19 converter.GumboHadoopConverter: Adding M2 guard path file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00001 using mapper gumbo.engine.hadoop.mrcomponents.round2.mappers.GFMapper2GuardRelOptimized
[INFO] 15/11/15 12:21:19 converter.GumboHadoopConverter: Adding M2 normal path file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_9_query2.gumbo_O13+_1 using identity mapper 
[INFO] 15/11/15 12:21:19 converter.Round2ReduceJobEstimator: Output estimate 301989888
[INFO] 15/11/15 12:21:19 converter.Round2ReduceJobEstimator: Reducer estimate 3
[INFO] 15/11/15 12:21:24 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/11/15 12:21:24 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/15 12:21:24 input.FileInputFormat: Total input paths to process : 1
[INFO] 15/11/15 12:21:24 input.FileInputFormat: Total input paths to process : 3
[INFO] 15/11/15 12:21:24 mapreduce.JobSubmitter: number of splits:4
[INFO] 15/11/15 12:21:24 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/15 12:21:24 mapreduce.JobSubmitter: Submitting tokens for job: job_local1188959567_0007
[WARN] 15/11/15 12:21:24 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1188959567/.staging/job_local1188959567_0007/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:21:24 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1188959567/.staging/job_local1188959567_0007/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/15 12:21:24 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1188959567_0007/job_local1188959567_0007.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:21:24 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1188959567_0007/job_local1188959567_0007.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/15 12:21:24 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: Starting task: attempt_local1188959567_0007_m_000000_0
[INFO] 15/11/15 12:21:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:24 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_028/1/S/S.txt:0+48928
[INFO] 15/11/15 12:21:24 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:24 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:24 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:24 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:24 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:24 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:24 mappers.GFMapper1Identity: MapperGFMapper1GuardedCsv-00000-0
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:24 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:24 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:24 mapred.MapTask: bufstart = 0; bufend = 88928; bufvoid = 104857600
[INFO] 15/11/15 12:21:24 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26174400(104697600); length = 39997/6553600
[INFO] 15/11/15 12:21:24 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:24 mapred.Task: Task:attempt_local1188959567_0007_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:24 mapred.Task: Task 'attempt_local1188959567_0007_m_000000_0' done.
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: Finishing task: attempt_local1188959567_0007_m_000000_0
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: Starting task: attempt_local1188959567_0007_m_000001_0
[INFO] 15/11/15 12:21:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:24 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00001:0+43165
[INFO] 15/11/15 12:21:24 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:24 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:24 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:24 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:24 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:24 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:24 mappers.GFMapper1Identity: MapperGFMapper1GuardRelOptimized-00001-0
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:24 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:24 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:24 mapred.MapTask: bufstart = 0; bufend = 32458; bufvoid = 104857600
[INFO] 15/11/15 12:21:24 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26205624(104822496); length = 8773/6553600
[INFO] 15/11/15 12:21:24 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:24 mapred.Task: Task:attempt_local1188959567_0007_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:24 mapred.Task: Task 'attempt_local1188959567_0007_m_000001_0' done.
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: Finishing task: attempt_local1188959567_0007_m_000001_0
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: Starting task: attempt_local1188959567_0007_m_000002_0
[INFO] 15/11/15 12:21:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:24 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00002:0+41540
[INFO] 15/11/15 12:21:24 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:24 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:24 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:24 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:24 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:24 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:24 mappers.GFMapper1Identity: MapperGFMapper1GuardRelOptimized-00002-0
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:24 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:24 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:24 mapred.MapTask: bufstart = 0; bufend = 31250; bufvoid = 104857600
[INFO] 15/11/15 12:21:24 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26205952(104823808); length = 8445/6553600
[INFO] 15/11/15 12:21:24 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:24 mapred.Task: Task:attempt_local1188959567_0007_m_000002_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:24 mapred.Task: Task 'attempt_local1188959567_0007_m_000002_0' done.
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: Finishing task: attempt_local1188959567_0007_m_000002_0
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: Starting task: attempt_local1188959567_0007_m_000003_0
[INFO] 15/11/15 12:21:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:24 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00000:0+39610
[INFO] 15/11/15 12:21:24 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:24 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:24 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:24 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:24 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:24 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:24 mappers.GFMapper1Identity: MapperGFMapper1GuardRelOptimized-00003-0
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:24 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:24 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:24 mapred.MapTask: bufstart = 0; bufend = 29786; bufvoid = 104857600
[INFO] 15/11/15 12:21:24 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26206336(104825344); length = 8061/6553600
[INFO] 15/11/15 12:21:24 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:24 mapred.Task: Task:attempt_local1188959567_0007_m_000003_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:24 mapred.Task: Task 'attempt_local1188959567_0007_m_000003_0' done.
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: Finishing task: attempt_local1188959567_0007_m_000003_0
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: Starting task: attempt_local1188959567_0007_r_000000_0
[INFO] 15/11/15 12:21:24 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:24 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:24 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5099f48
[INFO] 15/11/15 12:21:24 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:21:24 reduce.EventFetcher: attempt_local1188959567_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:21:24 reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1188959567_0007_m_000002_0 decomp: 35476 len: 35480 to MEMORY
[INFO] 15/11/15 12:21:24 reduce.InMemoryMapOutput: Read 35476 bytes from map-output for attempt_local1188959567_0007_m_000002_0
[INFO] 15/11/15 12:21:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 35476, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->35476
[INFO] 15/11/15 12:21:24 reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1188959567_0007_m_000000_0 decomp: 108930 len: 108934 to MEMORY
[INFO] 15/11/15 12:21:24 reduce.InMemoryMapOutput: Read 108930 bytes from map-output for attempt_local1188959567_0007_m_000000_0
[INFO] 15/11/15 12:21:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 108930, inMemoryMapOutputs.size() -> 2, commitMemory -> 35476, usedMemory ->144406
[INFO] 15/11/15 12:21:24 reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1188959567_0007_m_000003_0 decomp: 33820 len: 33824 to MEMORY
[INFO] 15/11/15 12:21:24 reduce.InMemoryMapOutput: Read 33820 bytes from map-output for attempt_local1188959567_0007_m_000003_0
[INFO] 15/11/15 12:21:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 33820, inMemoryMapOutputs.size() -> 3, commitMemory -> 144406, usedMemory ->178226
[INFO] 15/11/15 12:21:24 reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local1188959567_0007_m_000001_0 decomp: 36848 len: 36852 to MEMORY
[INFO] 15/11/15 12:21:24 reduce.InMemoryMapOutput: Read 36848 bytes from map-output for attempt_local1188959567_0007_m_000001_0
[INFO] 15/11/15 12:21:24 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 36848, inMemoryMapOutputs.size() -> 4, commitMemory -> 178226, usedMemory ->215074
[INFO] 15/11/15 12:21:24 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/11/15 12:21:24 reduce.MergeManagerImpl: finalMerge called with 4 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:21:24 mapred.Merger: Merging 4 sorted segments
[INFO] 15/11/15 12:21:24 mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 215054 bytes
[INFO] 15/11/15 12:21:24 reduce.MergeManagerImpl: Merged 4 segments, 215074 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:21:24 reduce.MergeManagerImpl: Merging 1 files, 215072 bytes from disk
[INFO] 15/11/15 12:21:24 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:21:24 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:21:24 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 215064 bytes
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/11/15 12:21:24 reducers.GFReducer1Optimized: ReducerGFReducer1Optimized-00000-0
[INFO] 15/11/15 12:21:24 mapred.Task: Task:attempt_local1188959567_0007_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: 4 / 4 copied.
[INFO] 15/11/15 12:21:24 mapred.Task: Task attempt_local1188959567_0007_r_000000_0 is allowed to commit now
[INFO] 15/11/15 12:21:24 output.FileOutputCommitter: Saved output of task 'attempt_local1188959567_0007_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_9_query2.gumbo_O13+_1/_temporary/0/task_local1188959567_0007_r_000000
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:21:24 mapred.Task: Task 'attempt_local1188959567_0007_r_000000_0' done.
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: Finishing task: attempt_local1188959567_0007_r_000000_0
[INFO] 15/11/15 12:21:24 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/15 12:21:29 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[WARN] 15/11/15 12:21:29 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/11/15 12:21:29 input.FileInputFormat: Total input paths to process : 2
[INFO] 15/11/15 12:21:29 input.FileInputFormat: Total input paths to process : 3
[INFO] 15/11/15 12:21:29 mapreduce.JobSubmitter: number of splits:5
[INFO] 15/11/15 12:21:29 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/11/15 12:21:29 mapreduce.JobSubmitter: Submitting tokens for job: job_local262302841_0008
[WARN] 15/11/15 12:21:29 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny262302841/.staging/job_local262302841_0008/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:21:29 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny262302841/.staging/job_local262302841_0008/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/11/15 12:21:29 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local262302841_0008/job_local262302841_0008.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/11/15 12:21:29 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local262302841_0008/job_local262302841_0008.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/11/15 12:21:29 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Starting task: attempt_local262302841_0008_m_000000_0
[INFO] 15/11/15 12:21:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00001:0+43165
[INFO] 15/11/15 12:21:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:29 mappers.GFMapper1Identity: MapperGFMapper2GuardRelOptimized-00000-0
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:29 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:29 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:29 mapred.MapTask: bufstart = 0; bufend = 60505; bufvoid = 104857600
[INFO] 15/11/15 12:21:29 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26205624(104822496); length = 8773/6553600
[INFO] 15/11/15 12:21:29 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:29 mapred.Task: Task:attempt_local262302841_0008_m_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:29 mapred.Task: Task 'attempt_local262302841_0008_m_000000_0' done.
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Finishing task: attempt_local262302841_0008_m_000000_0
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Starting task: attempt_local262302841_0008_m_000001_0
[INFO] 15/11/15 12:21:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00002:0+41540
[INFO] 15/11/15 12:21:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:29 mappers.GFMapper1Identity: MapperGFMapper2GuardRelOptimized-00001-0
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:29 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:29 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:29 mapred.MapTask: bufstart = 0; bufend = 58224; bufvoid = 104857600
[INFO] 15/11/15 12:21:29 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26205952(104823808); length = 8445/6553600
[INFO] 15/11/15 12:21:29 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:29 mapred.Task: Task:attempt_local262302841_0008_m_000001_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:29 mapred.Task: Task 'attempt_local262302841_0008_m_000001_0' done.
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Finishing task: attempt_local262302841_0008_m_000001_0
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Starting task: attempt_local262302841_0008_m_000002_0
[INFO] 15/11/15 12:21:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/OUT_0_O13/O13-r-00000:0+39610
[INFO] 15/11/15 12:21:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:29 mappers.GFMapper1Identity: MapperGFMapper2GuardRelOptimized-00002-0
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:29 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:29 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:29 mapred.MapTask: bufstart = 0; bufend = 55525; bufvoid = 104857600
[INFO] 15/11/15 12:21:29 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26206336(104825344); length = 8061/6553600
[INFO] 15/11/15 12:21:29 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:29 mapred.Task: Task:attempt_local262302841_0008_m_000002_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:29 mapred.Task: Task 'attempt_local262302841_0008_m_000002_0' done.
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Finishing task: attempt_local262302841_0008_m_000002_0
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Starting task: attempt_local262302841_0008_m_000003_0
[INFO] 15/11/15 12:21:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_9_query2.gumbo_O13+_1/round1-r-00000:0+35882
[INFO] 15/11/15 12:21:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:29 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:29 mapred.MapTask: Spilling map output
[INFO] 15/11/15 12:21:29 mapred.MapTask: bufstart = 0; bufend = 35882; bufvoid = 104857600
[INFO] 15/11/15 12:21:29 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26198272(104793088); length = 16125/6553600
[INFO] 15/11/15 12:21:29 mapred.MapTask: Finished spill 0
[INFO] 15/11/15 12:21:29 mapred.Task: Task:attempt_local262302841_0008_m_000003_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:29 mapred.Task: Task 'attempt_local262302841_0008_m_000003_0' done.
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Finishing task: attempt_local262302841_0008_m_000003_0
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Starting task: attempt_local262302841_0008_m_000004_0
[INFO] 15/11/15 12:21:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:29 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/scratch/EXP_028/20151115_122033/tmp/TMP_9_query2.gumbo_O13+_1/part-r-00000:0+0
[INFO] 15/11/15 12:21:29 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/11/15 12:21:29 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/11/15 12:21:29 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/11/15 12:21:29 mapred.MapTask: soft limit at 83886080
[INFO] 15/11/15 12:21:29 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/11/15 12:21:29 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 
[INFO] 15/11/15 12:21:29 mapred.MapTask: Starting flush of map output
[INFO] 15/11/15 12:21:29 mapred.Task: Task:attempt_local262302841_0008_m_000004_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: map
[INFO] 15/11/15 12:21:29 mapred.Task: Task 'attempt_local262302841_0008_m_000004_0' done.
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Finishing task: attempt_local262302841_0008_m_000004_0
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Starting task: attempt_local262302841_0008_r_000000_0
[INFO] 15/11/15 12:21:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:29 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b3c1be0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:21:29 reduce.EventFetcher: attempt_local262302841_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#11 about to shuffle output of map attempt_local262302841_0008_m_000001_0 decomp: 21310 len: 21314 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 21310 bytes from map-output for attempt_local262302841_0008_m_000001_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 21310, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->21310
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#11 about to shuffle output of map attempt_local262302841_0008_m_000004_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local262302841_0008_m_000004_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 21310, usedMemory ->21312
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#11 about to shuffle output of map attempt_local262302841_0008_m_000002_0 decomp: 20425 len: 20429 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 20425 bytes from map-output for attempt_local262302841_0008_m_000002_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20425, inMemoryMapOutputs.size() -> 3, commitMemory -> 21312, usedMemory ->41737
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#11 about to shuffle output of map attempt_local262302841_0008_m_000003_0 decomp: 14695 len: 14699 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 14695 bytes from map-output for attempt_local262302841_0008_m_000003_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14695, inMemoryMapOutputs.size() -> 4, commitMemory -> 41737, usedMemory ->56432
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#11 about to shuffle output of map attempt_local262302841_0008_m_000000_0 decomp: 21639 len: 21643 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 21639 bytes from map-output for attempt_local262302841_0008_m_000000_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 21639, inMemoryMapOutputs.size() -> 5, commitMemory -> 56432, usedMemory ->78071
[INFO] 15/11/15 12:21:29 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:21:29 mapred.Merger: Merging 5 sorted segments
[INFO] 15/11/15 12:21:29 mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 78034 bytes
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: Merged 5 segments, 78071 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: Merging 1 files, 78067 bytes from disk
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:21:29 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:21:29 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 78054 bytes
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:29 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00000-0
[INFO] 15/11/15 12:21:29 mapred.Task: Task:attempt_local262302841_0008_r_000000_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:29 mapred.Task: Task attempt_local262302841_0008_r_000000_0 is allowed to commit now
[INFO] 15/11/15 12:21:29 output.FileOutputCommitter: Saved output of task 'attempt_local262302841_0008_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O23+_2/_temporary/0/task_local262302841_0008_r_000000
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:21:29 mapred.Task: Task 'attempt_local262302841_0008_r_000000_0' done.
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Finishing task: attempt_local262302841_0008_r_000000_0
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Starting task: attempt_local262302841_0008_r_000001_0
[INFO] 15/11/15 12:21:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:29 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3508c3fd
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:21:29 reduce.EventFetcher: attempt_local262302841_0008_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#12 about to shuffle output of map attempt_local262302841_0008_m_000001_0 decomp: 20612 len: 20616 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 20612 bytes from map-output for attempt_local262302841_0008_m_000001_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20612, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20612
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#12 about to shuffle output of map attempt_local262302841_0008_m_000004_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local262302841_0008_m_000004_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 20612, usedMemory ->20614
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#12 about to shuffle output of map attempt_local262302841_0008_m_000002_0 decomp: 19997 len: 20001 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 19997 bytes from map-output for attempt_local262302841_0008_m_000002_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 19997, inMemoryMapOutputs.size() -> 3, commitMemory -> 20614, usedMemory ->40611
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#12 about to shuffle output of map attempt_local262302841_0008_m_000003_0 decomp: 14741 len: 14745 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 14741 bytes from map-output for attempt_local262302841_0008_m_000003_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14741, inMemoryMapOutputs.size() -> 4, commitMemory -> 40611, usedMemory ->55352
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#12 about to shuffle output of map attempt_local262302841_0008_m_000000_0 decomp: 21358 len: 21362 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 21358 bytes from map-output for attempt_local262302841_0008_m_000000_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 21358, inMemoryMapOutputs.size() -> 5, commitMemory -> 55352, usedMemory ->76710
[INFO] 15/11/15 12:21:29 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:21:29 mapred.Merger: Merging 5 sorted segments
[INFO] 15/11/15 12:21:29 mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 76672 bytes
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: Merged 5 segments, 76710 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: Merging 1 files, 76706 bytes from disk
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:21:29 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:21:29 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 76693 bytes
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:29 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00001-0
[INFO] 15/11/15 12:21:29 mapred.Task: Task:attempt_local262302841_0008_r_000001_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:29 mapred.Task: Task attempt_local262302841_0008_r_000001_0 is allowed to commit now
[INFO] 15/11/15 12:21:29 output.FileOutputCommitter: Saved output of task 'attempt_local262302841_0008_r_000001_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O23+_2/_temporary/0/task_local262302841_0008_r_000001
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:21:29 mapred.Task: Task 'attempt_local262302841_0008_r_000001_0' done.
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Finishing task: attempt_local262302841_0008_r_000001_0
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Starting task: attempt_local262302841_0008_r_000002_0
[INFO] 15/11/15 12:21:29 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/11/15 12:21:29 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/11/15 12:21:29 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4cae3cd4
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/11/15 12:21:29 reduce.EventFetcher: attempt_local262302841_0008_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#13 about to shuffle output of map attempt_local262302841_0008_m_000001_0 decomp: 20532 len: 20536 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 20532 bytes from map-output for attempt_local262302841_0008_m_000001_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20532, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20532
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#13 about to shuffle output of map attempt_local262302841_0008_m_000004_0 decomp: 2 len: 6 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local262302841_0008_m_000004_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 20532, usedMemory ->20534
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#13 about to shuffle output of map attempt_local262302841_0008_m_000002_0 decomp: 19141 len: 19145 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 19141 bytes from map-output for attempt_local262302841_0008_m_000002_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 19141, inMemoryMapOutputs.size() -> 3, commitMemory -> 20534, usedMemory ->39675
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#13 about to shuffle output of map attempt_local262302841_0008_m_000003_0 decomp: 14516 len: 14520 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 14516 bytes from map-output for attempt_local262302841_0008_m_000003_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14516, inMemoryMapOutputs.size() -> 4, commitMemory -> 39675, usedMemory ->54191
[INFO] 15/11/15 12:21:29 reduce.LocalFetcher: localfetcher#13 about to shuffle output of map attempt_local262302841_0008_m_000000_0 decomp: 21902 len: 21906 to MEMORY
[INFO] 15/11/15 12:21:29 reduce.InMemoryMapOutput: Read 21902 bytes from map-output for attempt_local262302841_0008_m_000000_0
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 21902, inMemoryMapOutputs.size() -> 5, commitMemory -> 54191, usedMemory ->76093
[INFO] 15/11/15 12:21:29 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/11/15 12:21:29 mapred.Merger: Merging 5 sorted segments
[INFO] 15/11/15 12:21:29 mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 76055 bytes
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: Merged 5 segments, 76093 bytes to disk to satisfy reduce memory limit
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: Merging 1 files, 76089 bytes from disk
[INFO] 15/11/15 12:21:29 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/11/15 12:21:29 mapred.Merger: Merging 1 sorted segments
[INFO] 15/11/15 12:21:29 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 76076 bytes
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:29 reducers.GFReducer2Optimized: ReducerGFReducer2Optimized-00002-0
[INFO] 15/11/15 12:21:29 mapred.Task: Task:attempt_local262302841_0008_r_000002_0 is done. And is in the process of committing
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: 5 / 5 copied.
[INFO] 15/11/15 12:21:29 mapred.Task: Task attempt_local262302841_0008_r_000002_0 is allowed to commit now
[INFO] 15/11/15 12:21:29 output.FileOutputCommitter: Saved output of task 'attempt_local262302841_0008_r_000002_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O23+_2/_temporary/0/task_local262302841_0008_r_000002
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/11/15 12:21:29 mapred.Task: Task 'attempt_local262302841_0008_r_000002_0' done.
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: Finishing task: attempt_local262302841_0008_r_000002_0
[INFO] 15/11/15 12:21:29 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/11/15 12:21:34 hadoop.HadoopPartitionQueue: Group is done, moving its output files{
id : 1 Depends on: 2, - (O23(x,y,z) : O13(x,y,z) & S(z))
}
[INFO] 15/11/15 12:21:34 hadoop.HadoopPartitionQueue: Moving O23(x0,x1,x2)
To: output/EXP_028/20151115_122033/OUT_3_O23
[INFO] 15/11/15 12:21:34 hadoop.HadoopPartitionQueue: Moving to:  output/EXP_028/20151115_122033/OUT_3_O23
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O23+_2/O23-r-00000
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O23+_2/O23-r-00001
From: file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_028/20151115_122033/query2.gumbo_O23+_2/O23-r-00002
[INFO] 15/11/15 12:21:35 hadoop.HadoopEngine: Partition queue exhausted.
[INFO] 15/11/15 12:21:35 hadoop.HadoopEngine: SUCCESS: all jobs (8) completed!
Running time: 61733ms
Counters for job: query2.gumbo_R+_1
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=1806766
	FILE: Number of bytes written=1774187
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=20000
	Map output records=20000
	Map output bytes=237532
	Map output materialized bytes=277544
	Input split bytes=646
	Combine input records=0
	Combine output records=0
	Reduce input groups=8665
	Reduce shuffle bytes=277544
	Reduce input records=20000
	Reduce output records=0
	Spilled Records=40000
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=9
	Total committed heap usage (bytes)=983040000
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
	ASSERT=10000
	ASSERT_BYTES=68928
	KEEP_ALIVE_ASSERT=0
	KEEP_ALIVE_ASSERT_BYTES=0
	KEEP_ALIVE_REQUEST=0
	KEEP_ALIVE_REQUEST_BYTES=0
	REQUEST=10000
	REQUEST_BYTES=128604
	REQUEST_KEY_BYTES=89716
	REQUEST_VALUE_BYTES=38888
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
	RED1_BUFFEREDITEMS=10000
	RED1_OUT_BYTES=43666
	RED1_OUT_RECORDS=6262
	RED1_PREMATURE_ABORTS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=20000
	Map output records=20000
	Map output bytes=237532
	Map output materialized bytes=277544
	Input split bytes=646
	Combine input records=0
	Combine output records=0
	Reduce input groups=8665
	Reduce shuffle bytes=277544
	Reduce input records=20000
	Reduce output records=0
	Spilled Records=40000
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=9
	Total committed heap usage (bytes)=983040000
Counters for job: query2.gumbo_O11+_2
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=5410485
	FILE: Number of bytes written=6144546
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=16262
	Map output records=16262
	Map output bytes=312516
	Map output materialized bytes=345058
	Input split bytes=992
	Combine input records=0
	Combine output records=0
	Reduce input groups=10000
	Reduce shuffle bytes=345058
	Reduce input records=16262
	Reduce output records=0
	Spilled Records=32524
	Shuffled Maps =3
	Failed Shuffles=0
	Merged Map outputs=3
	GC time elapsed (ms)=8
	Total committed heap usage (bytes)=2399666176
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
	ASSERT_BYTES=236326
	ASSERT_RECORDS=10000
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
	RED2_EVAL_FALSE=3738
	RED2_EVAL_TRUE=6262
	RED2_OUT_BYTES=116858
	RED2_OUT_RECORDS=6262
	RED2_TUPLES_FOUND=10000
	RED2_TUPLE_EXCEPTIONS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=16262
	Map output records=16262
	Map output bytes=312516
	Map output materialized bytes=345058
	Input split bytes=992
	Combine input records=0
	Combine output records=0
	Reduce input groups=10000
	Reduce shuffle bytes=345058
	Reduce input records=16262
	Reduce output records=0
	Spilled Records=32524
	Shuffled Maps =3
	Failed Shuffles=0
	Merged Map outputs=3
	GC time elapsed (ms)=8
	Total committed heap usage (bytes)=2399666176
Counters for job: query2.gumbo_O11+G+_1
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=9670265
	FILE: Number of bytes written=10330199
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=26262
	Map output records=26262
	Map output bytes=350462
	Map output materialized bytes=403004
	Input split bytes=994
	Combine input records=0
	Combine output records=0
	Reduce input groups=9275
	Reduce shuffle bytes=403004
	Reduce input records=26262
	Reduce output records=0
	Spilled Records=52524
	Shuffled Maps =3
	Failed Shuffles=0
	Merged Map outputs=3
	GC time elapsed (ms)=8
	Total committed heap usage (bytes)=3659005952
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
	ASSERT=10000
	ASSERT_BYTES=88900
	KEEP_ALIVE_ASSERT=0
	KEEP_ALIVE_ASSERT_BYTES=0
	KEEP_ALIVE_REQUEST=0
	KEEP_ALIVE_REQUEST_BYTES=0
	REQUEST=16262
	REQUEST_BYTES=209038
	REQUEST_KEY_BYTES=145860
	REQUEST_VALUE_BYTES=63178
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
	RED1_BUFFEREDITEMS=16262
	RED1_OUT_BYTES=70751
	RED1_OUT_RECORDS=10153
	RED1_PREMATURE_ABORTS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=26262
	Map output records=26262
	Map output bytes=350462
	Map output materialized bytes=403004
	Input split bytes=994
	Combine input records=0
	Combine output records=0
	Reduce input groups=9275
	Reduce shuffle bytes=403004
	Reduce input records=26262
	Reduce output records=0
	Spilled Records=52524
	Shuffled Maps =3
	Failed Shuffles=0
	Merged Map outputs=3
	GC time elapsed (ms)=8
	Total committed heap usage (bytes)=3659005952
Counters for job: query2.gumbo_O12+O21+_2
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=22105522
	FILE: Number of bytes written=23906975
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=26415
	Map output records=26415
	Map output bytes=520546
	Map output materialized bytes=573424
	Input split bytes=1348
	Combine input records=0
	Combine output records=0
	Reduce input groups=16262
	Reduce shuffle bytes=573424
	Reduce input records=26415
	Reduce output records=0
	Spilled Records=52830
	Shuffled Maps =8
	Failed Shuffles=0
	Merged Map outputs=8
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=7867465728
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
	ASSERT_BYTES=396965
	ASSERT_RECORDS=16262
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
	RED2_EVAL_FALSE=6109
	RED2_EVAL_TRUE=10153
	RED2_OUT_BYTES=189643
	RED2_OUT_RECORDS=10153
	RED2_TUPLES_FOUND=16262
	RED2_TUPLE_EXCEPTIONS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=16
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=26415
	Map output records=26415
	Map output bytes=520546
	Map output materialized bytes=573424
	Input split bytes=1348
	Combine input records=0
	Combine output records=0
	Reduce input groups=16262
	Reduce shuffle bytes=573424
	Reduce input records=26415
	Reduce output records=0
	Spilled Records=52830
	Shuffled Maps =8
	Failed Shuffles=0
	Merged Map outputs=8
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=7867465728
Counters for job: query2.gumbo_H+O12+_1
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=26443204
	FILE: Number of bytes written=26346533
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=26219
	Map output records=26219
	Map output bytes=349690
	Map output materialized bytes=402152
	Input split bytes=1342
	Combine input records=0
	Combine output records=0
	Reduce input groups=9271
	Reduce shuffle bytes=402152
	Reduce input records=26219
	Reduce output records=0
	Spilled Records=52438
	Shuffled Maps =4
	Failed Shuffles=0
	Merged Map outputs=4
	GC time elapsed (ms)=6
	Total committed heap usage (bytes)=8680636416
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
	ASSERT=10000
	ASSERT_BYTES=88866
	KEEP_ALIVE_ASSERT=0
	KEEP_ALIVE_ASSERT_BYTES=0
	KEEP_ALIVE_REQUEST=0
	KEEP_ALIVE_REQUEST_BYTES=0
	REQUEST=16219
	REQUEST_BYTES=208386
	REQUEST_KEY_BYTES=145261
	REQUEST_VALUE_BYTES=63125
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
	RED1_BUFFEREDITEMS=16219
	RED1_OUT_BYTES=71463
	RED1_OUT_RECORDS=10275
	RED1_PREMATURE_ABORTS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=26219
	Map output records=26219
	Map output bytes=349690
	Map output materialized bytes=402152
	Input split bytes=1342
	Combine input records=0
	Combine output records=0
	Reduce input groups=9271
	Reduce shuffle bytes=402152
	Reduce input records=26219
	Reduce output records=0
	Spilled Records=52438
	Shuffled Maps =4
	Failed Shuffles=0
	Merged Map outputs=4
	GC time elapsed (ms)=6
	Total committed heap usage (bytes)=8680636416
Counters for job: query2.gumbo_O13+O22+_2
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=52899089
	FILE: Number of bytes written=53688730
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=26494
	Map output records=26494
	Map output bytes=520128
	Map output materialized bytes=573206
	Input split bytes=1696
	Combine input records=0
	Combine output records=0
	Reduce input groups=16219
	Reduce shuffle bytes=573206
	Reduce input records=26494
	Reduce output records=0
	Spilled Records=52988
	Shuffled Maps =15
	Failed Shuffles=0
	Merged Map outputs=15
	GC time elapsed (ms)=8
	Total committed heap usage (bytes)=18064867328
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
	ASSERT_BYTES=395677
	ASSERT_RECORDS=16219
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
	RED2_EVAL_FALSE=5944
	RED2_EVAL_TRUE=10275
	RED2_OUT_BYTES=191849
	RED2_OUT_RECORDS=10275
	RED2_TUPLES_FOUND=16219
	RED2_TUPLE_EXCEPTIONS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=24
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=26494
	Map output records=26494
	Map output bytes=520128
	Map output materialized bytes=573206
	Input split bytes=1696
	Combine input records=0
	Combine output records=0
	Reduce input groups=16219
	Reduce shuffle bytes=573206
	Reduce input records=26494
	Reduce output records=0
	Spilled Records=52988
	Shuffled Maps =15
	Failed Shuffles=0
	Merged Map outputs=15
	GC time elapsed (ms)=8
	Total committed heap usage (bytes)=18064867328
Counters for job: query2.gumbo_O13+_1
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=40674798
	FILE: Number of bytes written=39175763
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=16322
	Map output records=16322
	Map output bytes=182422
	Map output materialized bytes=215090
	Input split bytes=1368
	Combine input records=0
	Combine output records=0
	Reduce input groups=7981
	Reduce shuffle bytes=215090
	Reduce input records=16322
	Reduce output records=0
	Spilled Records=32644
	Shuffled Maps =4
	Failed Shuffles=0
	Merged Map outputs=4
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=13452705792
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
gumbo.engine.hadoop.mrcomponents.round1.mappers.GumboMap1Counter
	ASSERT=10000
	ASSERT_BYTES=68928
	KEEP_ALIVE_ASSERT=0
	KEEP_ALIVE_ASSERT_BYTES=0
	KEEP_ALIVE_REQUEST=0
	KEEP_ALIVE_REQUEST_BYTES=0
	REQUEST=6322
	REQUEST_BYTES=80850
	REQUEST_KEY_BYTES=56261
	REQUEST_VALUE_BYTES=24589
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
gumbo.engine.hadoop.mrcomponents.round1.reducers.GumboRed1Counter
	RED1_BUFFEREDITEMS=6322
	RED1_OUT_BYTES=27818
	RED1_OUT_RECORDS=4032
	RED1_PREMATURE_ABORTS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=16322
	Map output records=16322
	Map output bytes=182422
	Map output materialized bytes=215090
	Input split bytes=1368
	Combine input records=0
	Combine output records=0
	Reduce input groups=7981
	Reduce shuffle bytes=215090
	Reduce input records=16322
	Reduce output records=0
	Spilled Records=32644
	Shuffled Maps =4
	Failed Shuffles=0
	Merged Map outputs=4
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=13452705792
Counters for job: query2.gumbo_O23+_2
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=70350424
	FILE: Number of bytes written=68734376
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=10354
	Map output records=10354
	Map output bytes=210136
	Map output materialized bytes=230934
	Input split bytes=1718
	Combine input records=0
	Combine output records=0
	Reduce input groups=6322
	Reduce shuffle bytes=230934
	Reduce input records=10354
	Reduce output records=0
	Spilled Records=20708
	Shuffled Maps =15
	Failed Shuffles=0
	Merged Map outputs=15
	GC time elapsed (ms)=206
	Total committed heap usage (bytes)=8690597888
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
gumbo.engine.hadoop.mrcomponents.round2.mappers.GumboMap2Counter
	ASSERT_BYTES=161610
	ASSERT_RECORDS=6322
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
gumbo.engine.hadoop.mrcomponents.round2.reducers.GumboRed2Counter
	RED2_EVAL_FALSE=2290
	RED2_EVAL_TRUE=4032
	RED2_OUT_BYTES=75229
	RED2_OUT_RECORDS=4032
	RED2_TUPLES_FOUND=6322
	RED2_TUPLE_EXCEPTIONS=0
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=24
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=10354
	Map output records=10354
	Map output bytes=210136
	Map output materialized bytes=230934
	Input split bytes=1718
	Combine input records=0
	Combine output records=0
	Reduce input groups=6322
	Reduce shuffle bytes=230934
	Reduce input records=10354
	Reduce output records=0
	Spilled Records=20708
	Shuffled Maps =15
	Failed Shuffles=0
	Merged Map outputs=15
	GC time elapsed (ms)=206
	Total committed heap usage (bytes)=8690597888

Overall Counters
--------------------------------------------------------------------------------
File System Counters
	FILE: Number of bytes read=229360553
	FILE: Number of bytes written=230101309
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
	Map input records=336656
	Map output records=336656
	Map output bytes=5366864
	Map output materialized bytes=6040824
	Input split bytes=20208
	Combine input records=0
	Combine output records=0
	Reduce input groups=167990
	Reduce shuffle bytes=6040824
	Reduce input records=336656
	Reduce output records=0
	Spilled Records=673312
	Shuffled Maps =108
	Failed Shuffles=0
	Merged Map outputs=108
	GC time elapsed (ms)=490
	Total committed heap usage (bytes)=127595970560
File Input Format Counters 
	Bytes Read=0
File Output Format Counters 
	Bytes Written=104

