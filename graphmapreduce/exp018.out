gumbo.engine.guardAddressOptimizationOn=true
gumbo.engine.proofsymbol=#
gumbo.engine.mapOutputGroupingPolicy=ALLGROUP
gumbo.engine.valeval.enabled=true
gumbo.engine.simulator.classname=gumbo.engine.hadoop2.estimation.MapSimulator
gumbo.engine.guardedCombinerOptimizationOn=false
gumbo.engine.assertConstantOptimizationOn=true
gumbo.compiler.partitioner=gumbo.compiler.partitioner.HeightPartitioner
gumbo.engine.valeval.projection.prepack=true
gumbo.engine.valeval.group=false
gumbo.engine.round1FiniteMemoryOptimizationOn=false
gumbo.engine.hadoop.reducersize_mb=1024
gumbo.engine.val.projection.prepack=true
gumbo.engine.reduceOutputGroupingOptimizationOn=true
gumbo.engine.mapOutputGroupingOptimizationOn=true
gumbo.engine.eval.output.merge=false
gumbo.compiler.unnest=false
gumbo.engine.grouper.beststopindicator=0
gumbo.engine.requestAtomIdOptimizationOn=true
gumbo.engine.guardKeepAliveOptimizationOn=true
[INFO] 15/12/11 17:13:22 gumbo.Gumbo: Input: 
R(x0,x1,x2);input/experiments/EXP_030/1/R;csv;'S(x0);input/experiments/EXP_030/1/S;csv;'T(x0);input/experiments/EXP_030/1/T;csv;'U(x0);input/experiments/EXP_030/1/U;csv;
Output: output/EXP_030
Scratch: scratch/EXP_030
Queries: 
[(Out1(x,y,z) : R(x,y,z) & S(x)), (Out2(x,y,z) : R(x,y,z) & S(y)), (Out3(x,y,z) : R(x,y,z) & S(z))]

[INFO] 15/12/11 17:13:22 compiler.GFCompiler: Adding suffix to scratch and output paths: /20151211_171322
[INFO] 15/12/11 17:13:22 compiler.GFCompiler: Decomposing GFEs into basic GFEs (BGFEs)...
[INFO] 15/12/11 17:13:22 compiler.GFCompiler: Number of BGFEs: 3
[INFO] 15/12/11 17:13:22 compiler.GFCompiler: Converting BGFEs into CalculationUnits (CUs)...
[INFO] 15/12/11 17:13:22 compiler.GFCompiler: Number of CUs: 3
[INFO] 15/12/11 17:13:22 compiler.GFCompiler: Linking Calculation Units (CUs)...
[INFO] 15/12/11 17:13:22 compiler.GFCompiler: Creating initial file mapping...
[INFO] 15/12/11 17:13:22 compiler.GFCompiler: file mapping:
Out root: output/EXP_030/20151211_171322
Scratch root: scratch/EXP_030/20151211_171322
Temp root: scratch/EXP_030/20151211_171322/tmp
R(x0,x1,x2) <- [input/experiments/EXP_030/1/R]
S(x0) <- [input/experiments/EXP_030/1/S]
T(x0) <- [input/experiments/EXP_030/1/T]
U(x0) <- [input/experiments/EXP_030/1/U]
Out3(x0,x1,x2) -> [output/EXP_030/20151211_171322/OUT_0_Out3]
Out2(x0,x1,x2) -> [output/EXP_030/20151211_171322/OUT_1_Out2]
Out1(x0,x1,x2) -> [output/EXP_030/20151211_171322/OUT_2_Out1]
Temp dirs: 

[INFO] 15/12/11 17:13:22 compiler.GFCompiler: Partitioning...
[INFO] 15/12/11 17:13:22 compiler.GFCompiler: Number of partitions: 1

Query:
query3a.gumbo

Partitions:
-----------
Calculation Unit Partitions: {
{id : 0 Depends on: None. - (Out1(x,y,z) : R(x,y,z) & S(x))id : 1 Depends on: None. - (Out2(x,y,z) : R(x,y,z) & S(y))id : 2 Depends on: None. - (Out3(x,y,z) : R(x,y,z) & S(z))}
}
Folders:
-------
Out root: output/EXP_030/20151211_171322
Scratch root: scratch/EXP_030/20151211_171322
Temp root: scratch/EXP_030/20151211_171322/tmp
R(x0,x1,x2) <- [input/experiments/EXP_030/1/R]
S(x0) <- [input/experiments/EXP_030/1/S]
T(x0) <- [input/experiments/EXP_030/1/T]
U(x0) <- [input/experiments/EXP_030/1/U]
Out3(x0,x1,x2) -> [output/EXP_030/20151211_171322/OUT_0_Out3]
Out2(x0,x1,x2) -> [output/EXP_030/20151211_171322/OUT_1_Out2]
Out1(x0,x1,x2) -> [output/EXP_030/20151211_171322/OUT_2_Out1]
Temp dirs: 

[INFO] 15/12/11 17:13:22 hadoop2.HadoopEngine2: Creating Job Control for: query3a.gumbo
[INFO] 15/12/11 17:13:22 hadoop2.HadoopEngine2: Starting Job-control thread: Gumbo-Workflow-Thread_query3a.gumbo
[WARN] 15/12/11 17:13:22 util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 15/12/11 17:13:22 hadoop2.HadoopEngine2: Using 1-round evaluation for Calculation Unit Partitions: {
{id : 0 Depends on: None. - (Out1(x,y,z) : R(x,y,z) & S(x))id : 1 Depends on: None. - (Out2(x,y,z) : R(x,y,z) & S(y))id : 2 Depends on: None. - (Out3(x,y,z) : R(x,y,z) & S(z))}
}
[INFO] 15/12/11 17:13:22 converter.MultiRoundConverter: Using separate jobs for all VALEVAL operations
[INFO] 15/12/11 17:13:22 converter.MultiRoundConverter: Adding path input/experiments/EXP_030/1/R to mapper
[INFO] 15/12/11 17:13:22 converter.MultiRoundConverter: Adding path input/experiments/EXP_030/1/S to mapper
[INFO] 15/12/11 17:13:22 converter.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
[INFO] 15/12/11 17:13:22 converter.MultiRoundConverter: Adding path input/experiments/EXP_030/1/R to mapper
[INFO] 15/12/11 17:13:22 converter.MultiRoundConverter: Adding path input/experiments/EXP_030/1/S to mapper
[INFO] 15/12/11 17:13:22 converter.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
[INFO] 15/12/11 17:13:22 converter.MultiRoundConverter: Adding path input/experiments/EXP_030/1/R to mapper
[INFO] 15/12/11 17:13:22 converter.MultiRoundConverter: Adding path input/experiments/EXP_030/1/S to mapper
[INFO] 15/12/11 17:13:22 converter.MultiRoundConverter: Setting VALEVAL Reduce tasks to 1
[INFO] 15/12/11 17:13:22 hadoop2.HadoopEngine2: Waiting for jobs
[INFO] 15/12/11 17:13:27 Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO] 15/12/11 17:13:27 jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN] 15/12/11 17:13:27 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/11 17:13:27 input.FileInputFormat: Total input paths to process : 2
[INFO] 15/12/11 17:13:27 mapreduce.JobSubmitter: number of splits:2
[INFO] 15/12/11 17:13:27 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/11 17:13:27 mapreduce.JobSubmitter: Submitting tokens for job: job_local1895010920_0001
[WARN] 15/12/11 17:13:27 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1895010920/.staging/job_local1895010920_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/11 17:13:27 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1895010920/.staging/job_local1895010920_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[WARN] 15/12/11 17:13:27 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1895010920_0001/job_local1895010920_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/11 17:13:27 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1895010920_0001/job_local1895010920_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/11 17:13:27 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/11 17:13:27 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[INFO] 15/12/11 17:13:27 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/11 17:13:27 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[WARN] 15/12/11 17:13:27 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/11 17:13:27 input.FileInputFormat: Total input paths to process : 2
[INFO] 15/12/11 17:13:27 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/11 17:13:27 mapred.LocalJobRunner: Starting task: attempt_local1895010920_0001_m_000000_0
[INFO] 15/12/11 17:13:27 mapreduce.JobSubmitter: number of splits:2
[INFO] 15/12/11 17:13:27 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/11 17:13:27 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 17:13:27 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 17:13:27 mapreduce.JobSubmitter: Submitting tokens for job: job_local458997781_0002
[INFO] 15/12/11 17:13:27 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_030/1/R/R.txt:0+11676
[INFO] 15/12/11 17:13:27 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[WARN] 15/12/11 17:13:27 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny458997781/.staging/job_local458997781_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/11 17:13:27 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny458997781/.staging/job_local458997781_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/11 17:13:27 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 17:13:27 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 17:13:27 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 17:13:27 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 17:13:27 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: [R:0:0,1,2:0]
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: [R:0:0,1,2:0]
[WARN] 15/12/11 17:13:28 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local458997781_0002/job_local458997781_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/11 17:13:28 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local458997781_0002/job_local458997781_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/11 17:13:28 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/11 17:13:28 jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Starting task: attempt_local458997781_0002_m_000000_0
[INFO] 15/12/11 17:13:28 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 17:13:28 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 17:13:28 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_030/1/R/R.txt:0+11676
[INFO] 15/12/11 17:13:28 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 17:13:28 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 17:13:28 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 17:13:28 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 17:13:28 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 17:13:28 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: [R:1:0,1,2:0]
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: [R:1:0,1,2:0]
[WARN] 15/12/11 17:13:28 mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 
[INFO] 15/12/11 17:13:28 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 17:13:28 mapred.MapTask: Spilling map output
[INFO] 15/12/11 17:13:28 mapred.MapTask: bufstart = 0; bufend = 18575; bufvoid = 104857600
[INFO] 15/12/11 17:13:28 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26210400(104841600); length = 3997/6553600
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 
[INFO] 15/12/11 17:13:28 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 17:13:28 mapred.MapTask: Spilling map output
[INFO] 15/12/11 17:13:28 mapred.MapTask: bufstart = 0; bufend = 18564; bufvoid = 104857600
[INFO] 15/12/11 17:13:28 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26210400(104841600); length = 3997/6553600
[INFO] 15/12/11 17:13:28 input.FileInputFormat: Total input paths to process : 2
[INFO] 15/12/11 17:13:28 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 17:13:28 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 17:13:28 mapred.Task: Task:attempt_local1895010920_0001_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/11 17:13:28 mapred.Task: Task:attempt_local458997781_0002_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/11 17:13:28 mapreduce.JobSubmitter: number of splits:2
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: map
[INFO] 15/12/11 17:13:28 mapred.Task: Task 'attempt_local458997781_0002_m_000000_0' done.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: map
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Finishing task: attempt_local458997781_0002_m_000000_0
[INFO] 15/12/11 17:13:28 mapred.Task: Task 'attempt_local1895010920_0001_m_000000_0' done.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Finishing task: attempt_local1895010920_0001_m_000000_0
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Starting task: attempt_local458997781_0002_m_000001_0
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Starting task: attempt_local1895010920_0001_m_000001_0
[INFO] 15/12/11 17:13:28 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 17:13:28 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 17:13:28 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 17:13:28 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 17:13:28 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_030/1/S/S.txt:0+3891
[INFO] 15/12/11 17:13:28 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_030/1/S/S.txt:0+3891
[INFO] 15/12/11 17:13:28 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 17:13:28 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 17:13:28 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 17:13:28 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 17:13:28 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 17:13:28 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 17:13:28 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 17:13:28 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 17:13:28 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 17:13:28 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 17:13:28 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 17:13:28 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: [S:0:0:1]
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: [S:0:0:2]
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: [S:0:0:1]
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: [S:0:0:2]
[INFO] 15/12/11 17:13:28 Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum
[INFO] 15/12/11 17:13:28 mapreduce.JobSubmitter: Submitting tokens for job: job_local1413151909_0003
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 
[INFO] 15/12/11 17:13:28 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 17:13:28 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 17:13:28 mapred.MapTask: Spilling map output
[INFO] 15/12/11 17:13:28 mapred.MapTask: bufstart = 0; bufend = 6891; bufvoid = 104857600
[INFO] 15/12/11 17:13:28 mapred.MapTask: Spilling map output
[INFO] 15/12/11 17:13:28 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26210400(104841600); length = 3997/6553600
[INFO] 15/12/11 17:13:28 mapred.MapTask: bufstart = 0; bufend = 6891; bufvoid = 104857600
[INFO] 15/12/11 17:13:28 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26210400(104841600); length = 3997/6553600
[INFO] 15/12/11 17:13:28 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 17:13:28 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 17:13:28 mapred.Task: Task:attempt_local458997781_0002_m_000001_0 is done. And is in the process of committing
[INFO] 15/12/11 17:13:28 mapred.Task: Task:attempt_local1895010920_0001_m_000001_0 is done. And is in the process of committing
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: map
[INFO] 15/12/11 17:13:28 mapred.Task: Task 'attempt_local458997781_0002_m_000001_0' done.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Finishing task: attempt_local458997781_0002_m_000001_0
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: map
[INFO] 15/12/11 17:13:28 mapred.Task: Task 'attempt_local1895010920_0001_m_000001_0' done.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Finishing task: attempt_local1895010920_0001_m_000001_0
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Starting task: attempt_local1895010920_0001_r_000000_0
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Starting task: attempt_local458997781_0002_r_000000_0
[WARN] 15/12/11 17:13:28 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1413151909/.staging/job_local1413151909_0003/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/11 17:13:28 conf.Configuration: file:/tmp/hadoop-jonny/mapred/staging/jonny1413151909/.staging/job_local1413151909_0003/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/11 17:13:28 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 17:13:28 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 17:13:28 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 17:13:28 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 17:13:28 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1912735a
[INFO] 15/12/11 17:13:28 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5cc04f16
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/11 17:13:28 reduce.EventFetcher: attempt_local458997781_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/11 17:13:28 reduce.EventFetcher: attempt_local1895010920_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[WARN] 15/12/11 17:13:28 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1413151909_0003/job_local1413151909_0003.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
[WARN] 15/12/11 17:13:28 conf.Configuration: file:/tmp/hadoop-jonny/mapred/local/localRunner/jonny/job_local1413151909_0003/job_local1413151909_0003.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
[INFO] 15/12/11 17:13:28 mapreduce.Job: The url to track the job: http://localhost:8080/
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: OutputCommitter set in config null
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO] 15/12/11 17:13:28 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1895010920_0001_m_000001_0 decomp: 8893 len: 8897 to MEMORY
[INFO] 15/12/11 17:13:28 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local458997781_0002_m_000000_0 decomp: 20566 len: 20570 to MEMORY
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Waiting for map tasks
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Starting task: attempt_local1413151909_0003_m_000000_0
[INFO] 15/12/11 17:13:28 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 17:13:28 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 17:13:28 reduce.InMemoryMapOutput: Read 20566 bytes from map-output for attempt_local458997781_0002_m_000000_0
[INFO] 15/12/11 17:13:28 reduce.InMemoryMapOutput: Read 8893 bytes from map-output for attempt_local1895010920_0001_m_000001_0
[INFO] 15/12/11 17:13:28 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_030/1/R/R.txt:0+11676
[INFO] 15/12/11 17:13:28 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 17:13:28 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 17:13:28 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 17:13:28 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 17:13:28 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 17:13:28 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: [R:2:0,1,2:0]
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: [R:2:0,1,2:0]
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 
[INFO] 15/12/11 17:13:28 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 17:13:28 mapred.MapTask: Spilling map output
[INFO] 15/12/11 17:13:28 mapred.MapTask: bufstart = 0; bufend = 18565; bufvoid = 104857600
[INFO] 15/12/11 17:13:28 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26210400(104841600); length = 3997/6553600
[INFO] 15/12/11 17:13:28 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 17:13:28 mapred.Task: Task:attempt_local1413151909_0003_m_000000_0 is done. And is in the process of committing
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: map
[INFO] 15/12/11 17:13:28 mapred.Task: Task 'attempt_local1413151909_0003_m_000000_0' done.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Finishing task: attempt_local1413151909_0003_m_000000_0
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Starting task: attempt_local1413151909_0003_m_000001_0
[INFO] 15/12/11 17:13:28 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 17:13:28 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 17:13:28 mapred.MapTask: Processing split: file:/Users/jonny/Develop/Gumbo/graphmapreduce/input/experiments/EXP_030/1/S/S.txt:0+3891
[INFO] 15/12/11 17:13:28 mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8893, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->8893
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20566, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20566
[INFO] 15/12/11 17:13:28 mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
[INFO] 15/12/11 17:13:28 mapred.MapTask: mapreduce.task.io.sort.mb: 100
[INFO] 15/12/11 17:13:28 mapred.MapTask: soft limit at 83886080
[INFO] 15/12/11 17:13:28 mapred.MapTask: bufstart = 0; bufvoid = 104857600
[INFO] 15/12/11 17:13:28 mapred.MapTask: kvstart = 26214396; length = 6553600
[INFO] 15/12/11 17:13:28 reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local458997781_0002_m_000001_0 decomp: 8893 len: 8897 to MEMORY
[INFO] 15/12/11 17:13:28 reduce.InMemoryMapOutput: Read 8893 bytes from map-output for attempt_local458997781_0002_m_000001_0
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8893, inMemoryMapOutputs.size() -> 2, commitMemory -> 20566, usedMemory ->29459
[INFO] 15/12/11 17:13:28 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/11 17:13:28 reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1895010920_0001_m_000000_0 decomp: 20577 len: 20581 to MEMORY
[INFO] 15/12/11 17:13:28 reduce.InMemoryMapOutput: Read 20577 bytes from map-output for attempt_local1895010920_0001_m_000000_0
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20577, inMemoryMapOutputs.size() -> 2, commitMemory -> 8893, usedMemory ->29470
[INFO] 15/12/11 17:13:28 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: Projections before merge:
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: [S:0:0:3]
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: Projections after merge:
[INFO] 15/12/11 17:13:28 tupleops.TupleOpFactory: [S:0:0:3]
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 
[INFO] 15/12/11 17:13:28 mapred.MapTask: Starting flush of map output
[INFO] 15/12/11 17:13:28 mapred.MapTask: Spilling map output
[INFO] 15/12/11 17:13:28 mapred.MapTask: bufstart = 0; bufend = 6891; bufvoid = 104857600
[INFO] 15/12/11 17:13:28 mapred.MapTask: kvstart = 26214396(104857584); kvend = 26210400(104841600); length = 3997/6553600
[INFO] 15/12/11 17:13:28 mapred.Merger: Merging 2 sorted segments
[INFO] 15/12/11 17:13:28 mapred.Merger: Merging 2 sorted segments
[INFO] 15/12/11 17:13:28 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 29462 bytes
[INFO] 15/12/11 17:13:28 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 29451 bytes
[INFO] 15/12/11 17:13:28 mapred.MapTask: Finished spill 0
[INFO] 15/12/11 17:13:28 mapred.Task: Task:attempt_local1413151909_0003_m_000001_0 is done. And is in the process of committing
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: map
[INFO] 15/12/11 17:13:28 mapred.Task: Task 'attempt_local1413151909_0003_m_000001_0' done.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Finishing task: attempt_local1413151909_0003_m_000001_0
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: map task executor complete.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Waiting for reduce tasks
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Starting task: attempt_local1413151909_0003_r_000000_0
[INFO] 15/12/11 17:13:28 util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
[INFO] 15/12/11 17:13:28 mapred.Task:  Using ResourceCalculatorProcessTree : null
[INFO] 15/12/11 17:13:28 mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1635c275
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO] 15/12/11 17:13:28 reduce.EventFetcher: attempt_local1413151909_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO] 15/12/11 17:13:28 reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1413151909_0003_m_000000_0 decomp: 20567 len: 20571 to MEMORY
[INFO] 15/12/11 17:13:28 reduce.InMemoryMapOutput: Read 20567 bytes from map-output for attempt_local1413151909_0003_m_000000_0
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20567, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20567
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: Merged 2 segments, 29470 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: Merging 1 files, 29472 bytes from disk
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: Merged 2 segments, 29459 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/11 17:13:28 reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1413151909_0003_m_000001_0 decomp: 8893 len: 8897 to MEMORY
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: Merging 1 files, 29461 bytes from disk
[INFO] 15/12/11 17:13:28 reduce.InMemoryMapOutput: Read 8893 bytes from map-output for attempt_local1413151909_0003_m_000001_0
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8893, inMemoryMapOutputs.size() -> 2, commitMemory -> 20567, usedMemory ->29460
[INFO] 15/12/11 17:13:28 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/11 17:13:28 reduce.EventFetcher: EventFetcher is interrupted.. Returning
[INFO] 15/12/11 17:13:28 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/11 17:13:28 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29453 bytes
[INFO] 15/12/11 17:13:28 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29464 bytes
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/11 17:13:28 mapred.Merger: Merging 2 sorted segments
[INFO] 15/12/11 17:13:28 mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 29452 bytes
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: Merged 2 segments, 29460 bytes to disk to satisfy reduce memory limit
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: Merging 1 files, 29462 bytes from disk
[INFO] 15/12/11 17:13:28 reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
[INFO] 15/12/11 17:13:28 mapred.Merger: Merging 1 sorted segments
[INFO] 15/12/11 17:13:28 mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29454 bytes
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/11 17:13:28 Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[INFO] 15/12/11 17:13:28 mapred.Task: Task:attempt_local1413151909_0003_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/11 17:13:28 mapred.Task: Task:attempt_local1895010920_0001_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/11 17:13:28 mapred.Task: Task:attempt_local458997781_0002_r_000000_0 is done. And is in the process of committing
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/11 17:13:28 mapred.Task: Task attempt_local1413151909_0003_r_000000_0 is allowed to commit now
[INFO] 15/12/11 17:13:28 mapred.Task: Task attempt_local1895010920_0001_r_000000_0 is allowed to commit now
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: 2 / 2 copied.
[INFO] 15/12/11 17:13:28 mapred.Task: Task attempt_local458997781_0002_r_000000_0 is allowed to commit now
[INFO] 15/12/11 17:13:28 output.FileOutputCommitter: Saved output of task 'attempt_local1413151909_0003_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_030/20151211_171322/Out3(x0,x1,x2)/_temporary/0/task_local1413151909_0003_r_000000
[INFO] 15/12/11 17:13:28 output.FileOutputCommitter: Saved output of task 'attempt_local458997781_0002_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_030/20151211_171322/Out2(x0,x1,x2)/_temporary/0/task_local458997781_0002_r_000000
[INFO] 15/12/11 17:13:28 output.FileOutputCommitter: Saved output of task 'attempt_local1895010920_0001_r_000000_0' to file:/Users/jonny/Develop/Gumbo/graphmapreduce/output/EXP_030/20151211_171322/Out1(x0,x1,x2)/_temporary/0/task_local1895010920_0001_r_000000
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/11 17:13:28 mapred.Task: Task 'attempt_local1413151909_0003_r_000000_0' done.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: reduce > reduce
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Finishing task: attempt_local1413151909_0003_r_000000_0
[INFO] 15/12/11 17:13:28 mapred.Task: Task 'attempt_local458997781_0002_r_000000_0' done.
[INFO] 15/12/11 17:13:28 mapred.Task: Task 'attempt_local1895010920_0001_r_000000_0' done.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Finishing task: attempt_local458997781_0002_r_000000_0
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: Finishing task: attempt_local1895010920_0001_r_000000_0
[INFO] 15/12/11 17:13:28 mapred.LocalJobRunner: reduce task executor complete.
[INFO] 15/12/11 17:13:33 hadoop2.HadoopEngine2: Jobs are done.
[INFO] 15/12/11 17:13:33 converter.MultiRoundConverter: Using separate jobs for all VALEVAL operations
[INFO] 15/12/11 17:13:33 converter.MultiRoundConverter: Moving files: output/EXP_030/20151211_171322/Out1(x0,x1,x2)/Out1-r-* output/EXP_030/20151211_171322/OUT_2_Out1
[INFO] 15/12/11 17:13:33 converter.MultiRoundConverter: Moving files: output/EXP_030/20151211_171322/Out2(x0,x1,x2)/Out2-r-* output/EXP_030/20151211_171322/OUT_1_Out2
[INFO] 15/12/11 17:13:33 converter.MultiRoundConverter: Moving files: output/EXP_030/20151211_171322/Out3(x0,x1,x2)/Out3-r-* output/EXP_030/20151211_171322/OUT_0_Out3
[INFO] 15/12/11 17:13:33 hadoop2.HadoopEngine2: Running time: 10779ms
[INFO] 15/12/11 17:13:33 hadoop2.HadoopEngine2: SUCCESS: all jobs (3) completed!
[INFO] 15/12/11 17:13:33 hadoop2.HadoopEngine2: Stopping job control
Counters for job: query3a.gumbo_VALEVAL_Out1(x0,x1,x2)
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=286425
	FILE: Number of bytes written=2101035
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=2000
	Map output records=2000
	Map output bytes=25466
	Map output materialized bytes=29478
	Input split bytes=632
	Combine input records=0
	Combine output records=0
	Reduce input groups=870
	Reduce shuffle bytes=29478
	Reduce input records=2000
	Reduce output records=0
	Spilled Records=4000
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=8
	Total committed heap usage (bytes)=1720713216
gumbo.engine.hadoop2.mapreduce.GumboCounters
gumbo.engine.hadoop2.mapreduce.GumboCounters
	ASSERT_IN=1000
	ASSERT_OUT=1000
	DATAREQUEST_IN=1000
	DATAREQUEST_OUT=1000
	RECORDS_OUT=637
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=29486
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=2000
	Map output records=2000
	Map output bytes=25466
	Map output materialized bytes=29478
	Input split bytes=632
	Combine input records=0
	Combine output records=0
	Reduce input groups=870
	Reduce shuffle bytes=29478
	Reduce input records=2000
	Reduce output records=0
	Spilled Records=4000
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=8
	Total committed heap usage (bytes)=1720713216
Counters for job: query3a.gumbo_VALEVAL_Out2(x0,x1,x2)
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=286425
	FILE: Number of bytes written=2100989
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=2000
	Map output records=2000
	Map output bytes=25455
	Map output materialized bytes=29467
	Input split bytes=632
	Combine input records=0
	Combine output records=0
	Reduce input groups=864
	Reduce shuffle bytes=29467
	Reduce input records=2000
	Reduce output records=0
	Spilled Records=4000
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=8
	Total committed heap usage (bytes)=1720713216
gumbo.engine.hadoop2.mapreduce.GumboCounters
gumbo.engine.hadoop2.mapreduce.GumboCounters
	ASSERT_IN=1000
	ASSERT_OUT=1000
	DATAREQUEST_IN=1000
	DATAREQUEST_OUT=1000
	RECORDS_OUT=648
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=29486
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=2000
	Map output records=2000
	Map output bytes=25455
	Map output materialized bytes=29467
	Input split bytes=632
	Combine input records=0
	Combine output records=0
	Reduce input groups=864
	Reduce shuffle bytes=29467
	Reduce input records=2000
	Reduce output records=0
	Spilled Records=4000
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=8
	Total committed heap usage (bytes)=1720713216
Counters for job: query3a.gumbo_VALEVAL_Out3(x0,x1,x2)
--------------------------------------------------------------------------------
File System Counters
org.apache.hadoop.mapreduce.FileSystemCounter
	FILE: Number of bytes read=413437
	FILE: Number of bytes written=2582096
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
org.apache.hadoop.mapreduce.TaskCounter
	Map input records=2000
	Map output records=2000
	Map output bytes=25456
	Map output materialized bytes=29468
	Input split bytes=632
	Combine input records=0
	Combine output records=0
	Reduce input groups=870
	Reduce shuffle bytes=29468
	Reduce input records=2000
	Reduce output records=0
	Spilled Records=4000
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=2247622656
gumbo.engine.hadoop2.mapreduce.GumboCounters
gumbo.engine.hadoop2.mapreduce.GumboCounters
	ASSERT_IN=1000
	ASSERT_OUT=1000
	DATAREQUEST_IN=1000
	DATAREQUEST_OUT=1000
	RECORDS_OUT=644
File Input Format Counters 
org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
	Bytes Read=0
File Output Format Counters 
org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
	Bytes Written=8
Map-Reduce Framework
org.apache.hadoop.mapred.Task$Counter
	Map input records=2000
	Map output records=2000
	Map output bytes=25456
	Map output materialized bytes=29468
	Input split bytes=632
	Combine input records=0
	Combine output records=0
	Reduce input groups=870
	Reduce shuffle bytes=29468
	Reduce input records=2000
	Reduce output records=0
	Spilled Records=4000
	Shuffled Maps =2
	Failed Shuffles=0
	Merged Map outputs=2
	GC time elapsed (ms)=0
	Total committed heap usage (bytes)=2247622656

Overall Counters
--------------------------------------------------------------------------------
File System Counters
	FILE: Number of bytes read=986287
	FILE: Number of bytes written=6784120
	FILE: Number of read operations=0
	FILE: Number of large read operations=0
	FILE: Number of write operations=0
Map-Reduce Framework
	Map input records=12000
	Map output records=12000
	Map output bytes=152754
	Map output materialized bytes=176826
	Input split bytes=3792
	Combine input records=0
	Combine output records=0
	Reduce input groups=5208
	Reduce shuffle bytes=176826
	Reduce input records=12000
	Reduce output records=0
	Spilled Records=24000
	Shuffled Maps =12
	Failed Shuffles=0
	Merged Map outputs=12
	GC time elapsed (ms)=32
	Total committed heap usage (bytes)=11378098176
File Input Format Counters 
	Bytes Read=0
File Output Format Counters 
	Bytes Written=58980

